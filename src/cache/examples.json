[{"layout_dets": [{"category_id": 2, "poly": [314.49432373046875, 1912.879638671875, 931.2562255859375, 1912.879638671875, 931.2562255859375, 2036.0811767578125, 314.49432373046875, 2036.0811767578125], "score": 0.9999984502792358}, {"category_id": 0, "poly": [773.4552612304688, 786.5220947265625, 928.0726318359375, 786.5220947265625, 928.0726318359375, 819.3733520507812, 773.4552612304688, 819.3733520507812], "score": 0.9999982714653015}, {"category_id": 1, "poly": [396.8823547363281, 853.379638671875, 1303.9552001953125, 853.379638671875, 1303.9552001953125, 1104.283935546875, 396.8823547363281, 1104.283935546875], "score": 0.9999933242797852}, {"category_id": 2, "poly": [43.19550704956055, 605.2767944335938, 101.85892486572266, 605.2767944335938, 101.85892486572266, 1565.4442138671875, 43.19550704956055, 1565.4442138671875], "score": 0.9999920725822449}, {"category_id": 1, "poly": [397.82745361328125, 1111.761474609375, 1303.5263671875, 1111.761474609375, 1303.5263671875, 1357.4923095703125, 397.82745361328125, 1357.4923095703125], "score": 0.9999898672103882}, {"category_id": 1, "poly": [311.61859130859375, 355.7950134277344, 1423.5926513671875, 355.7950134277344, 1423.5926513671875, 635.1243896484375, 311.61859130859375, 635.1243896484375], "score": 0.99998939037323}, {"category_id": 1, "poly": [397.6753234863281, 1369.5679931640625, 1303.717529296875, 1369.5679931640625, 1303.717529296875, 1525.708740234375, 397.6753234863281, 1525.708740234375], "score": 0.9999740123748779}, {"category_id": 0, "poly": [311.7306213378906, 674.15185546875, 662.1817016601562, 674.15185546875, 662.1817016601562, 707.615234375, 311.7306213378906, 707.615234375], "score": 0.999966025352478}, {"category_id": 0, "poly": [295.92816162109375, 221.5227813720703, 894.5770263671875, 221.5227813720703, 894.5770263671875, 268.8919372558594, 295.92816162109375, 268.8919372558594], "score": 0.9940215945243835}, {"category_id": 2, "poly": [840.5726928710938, 2089.504150390625, 856.8710327148438, 2089.504150390625, 856.8710327148438, 2112.243408203125, 840.5726928710938, 2112.243408203125], "score": 0.9853214025497437}, {"category_id": 15, "poly": [333.0, 1916.0, 871.0, 1916.0, 871.0, 1948.0, 333.0, 1948.0], "score": 1.0, "text": "* Authors are ordered alphabetically by the first name."}, {"category_id": 15, "poly": [333.0, 1943.0, 755.0, 1946.0, 755.0, 1978.0, 333.0, 1975.0], "score": 0.98, "text": "'https://huggingface.co/Qwen"}, {"category_id": 15, "poly": [333.0, 1973.0, 929.0, 1978.0, 928.0, 2010.0, 333.0, 2005.0], "score": 0.99, "text": "2https://modelscope.cn/organization/qwen"}, {"category_id": 15, "poly": [333.0, 2003.0, 808.0, 2005.0, 808.0, 2037.0, 333.0, 2035.0], "score": 1.0, "text": "3https://github.com/QwenLM/Qwen2"}, {"category_id": 15, "poly": [771.0, 786.0, 931.0, 786.0, 931.0, 827.0, 771.0, 827.0], "score": 1.0, "text": "ABSTRACT"}, {"category_id": 15, "poly": [397.0, 857.0, 1305.0, 857.0, 1305.0, 889.0, 397.0, 889.0], "score": 0.98, "text": "This report introduces the Qwen2 series, the latest addition to our large lan-"}, {"category_id": 15, "poly": [397.0, 889.0, 1305.0, 889.0, 1305.0, 921.0, 397.0, 921.0], "score": 0.99, "text": "guage models and large multimodal models. We release a comprehensive suite of"}, {"category_id": 15, "poly": [393.0, 914.0, 1307.0, 917.0, 1307.0, 956.0, 393.0, 953.0], "score": 0.98, "text": "foundational and instruction-tuned language models, encompassing a parameter"}, {"category_id": 15, "poly": [395.0, 949.0, 1303.0, 951.0, 1303.0, 983.0, 395.0, 981.0], "score": 0.99, "text": "range from 0.5 to 72 billion, featuring dense models and a Mixture-of-Experts"}, {"category_id": 15, "poly": [397.0, 981.0, 1303.0, 981.0, 1303.0, 1013.0, 397.0, 1013.0], "score": 0.99, "text": "model. Qwen2 surpasses most prior open-weight models, including its predecessor"}, {"category_id": 15, "poly": [397.0, 1011.0, 1305.0, 1011.0, 1305.0, 1043.0, 397.0, 1043.0], "score": 0.99, "text": "Qwen1.5, and exhibits competitive performance relative to proprietary models"}, {"category_id": 15, "poly": [393.0, 1036.0, 1307.0, 1038.0, 1307.0, 1077.0, 393.0, 1075.0], "score": 0.98, "text": " across diverse benchmarks on language understanding, generation, multilingual"}, {"category_id": 15, "poly": [390.0, 1068.0, 945.0, 1070.0, 945.0, 1109.0, 390.0, 1107.0], "score": 1.0, "text": " proficiency, coding, mathematics, and reasoning."}, {"category_id": 15, "poly": [395.0, 1111.0, 1305.0, 1114.0, 1305.0, 1146.0, 395.0, 1144.0], "score": 0.99, "text": "The fagship model, Qwen2-72B, showcases remarkable performance: 84.2 on"}, {"category_id": 15, "poly": [397.0, 1146.0, 1305.0, 1146.0, 1305.0, 1176.0, 397.0, 1176.0], "score": 0.98, "text": "MMLU, 37.9 on GPQA, 64.6 on HumanEval, 89.5 on GSM8K, and 82.4 on BBH as"}, {"category_id": 15, "poly": [393.0, 1173.0, 1307.0, 1171.0, 1307.0, 1210.0, 393.0, 1212.0], "score": 0.99, "text": "a base language model. The instruction-tuned variant, Qwen2-72B-Instruct, attains "}, {"category_id": 15, "poly": [395.0, 1203.0, 1305.0, 1205.0, 1305.0, 1238.0, 395.0, 1235.0], "score": 1.0, "text": "9.1 on MT-Bench, 48.1 on Arena-Hard, and 35.7 on LiveCodeBench. Moreover,"}, {"category_id": 15, "poly": [395.0, 1235.0, 1300.0, 1235.0, 1300.0, 1267.0, 395.0, 1267.0], "score": 0.99, "text": "Qwen2 demonstrates robust multilingual capabilities, proficient in approximately"}, {"category_id": 15, "poly": [393.0, 1263.0, 1305.0, 1265.0, 1305.0, 1304.0, 393.0, 1302.0], "score": 0.99, "text": " 30 languages, spanning English, Chinese, Spanish, French, German, Arabic, Rus-"}, {"category_id": 15, "poly": [397.0, 1297.0, 1300.0, 1297.0, 1300.0, 1327.0, 397.0, 1327.0], "score": 0.99, "text": "sian, Korean, Japanese, Thai, Vietnamese, and more, underscoring its versatility"}, {"category_id": 15, "poly": [395.0, 1329.0, 591.0, 1329.0, 591.0, 1361.0, 395.0, 1361.0], "score": 0.95, "text": "and global reach."}, {"category_id": 15, "poly": [314.0, 360.0, 1421.0, 360.0, 1421.0, 392.0, 314.0, 392.0], "score": 0.99, "text": "An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,"}, {"category_id": 15, "poly": [312.0, 390.0, 1421.0, 392.0, 1420.0, 424.0, 312.0, 422.0], "score": 0.99, "text": "Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang,"}, {"category_id": 15, "poly": [312.0, 422.0, 1418.0, 422.0, 1418.0, 454.0, 312.0, 454.0], "score": 0.99, "text": "Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jianxin Yang, Jin Xu, Jingren"}, {"category_id": 15, "poly": [314.0, 451.0, 1418.0, 451.0, 1418.0, 484.0, 314.0, 484.0], "score": 0.99, "text": "Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei"}, {"category_id": 15, "poly": [314.0, 481.0, 1418.0, 481.0, 1418.0, 513.0, 314.0, 513.0], "score": 0.99, "text": "Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie"}, {"category_id": 15, "poly": [312.0, 509.0, 1423.0, 513.0, 1423.0, 545.0, 312.0, 541.0], "score": 0.99, "text": "Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng,"}, {"category_id": 15, "poly": [312.0, 541.0, 1421.0, 543.0, 1420.0, 575.0, 312.0, 573.0], "score": 0.99, "text": "Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Xuejing Liu, Yang Fan,"}, {"category_id": 15, "poly": [310.0, 568.0, 1423.0, 571.0, 1423.0, 610.0, 309.0, 607.0], "score": 1.0, "text": "Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zhifang"}, {"category_id": 15, "poly": [312.0, 605.0, 557.0, 605.0, 557.0, 635.0, 312.0, 635.0], "score": 0.96, "text": "Guo, and Zhihao Fan"}, {"category_id": 15, "poly": [397.0, 1373.0, 1305.0, 1373.0, 1305.0, 1405.0, 397.0, 1405.0], "score": 0.98, "text": "To foster community innovation and accessibility, we have made the Qwen2 model"}, {"category_id": 15, "poly": [397.0, 1405.0, 1305.0, 1405.0, 1305.0, 1437.0, 397.0, 1437.0], "score": 0.99, "text": "weights openly available on Hugging Face and ModelScope?, and the supplemen-"}, {"category_id": 15, "poly": [395.0, 1435.0, 1303.0, 1432.0, 1303.0, 1464.0, 395.0, 1467.0], "score": 0.99, "text": "tary materials including example code on GitHub3. These platforms also include"}, {"category_id": 15, "poly": [393.0, 1460.0, 1305.0, 1464.0, 1305.0, 1503.0, 393.0, 1499.0], "score": 0.99, "text": "resources for quantization, fine-tuning, and deployment, facilitating a wide range"}, {"category_id": 15, "poly": [397.0, 1496.0, 834.0, 1496.0, 834.0, 1526.0, 397.0, 1526.0], "score": 1.0, "text": "of applications and research endeavors."}, {"category_id": 15, "poly": [314.0, 674.0, 661.0, 674.0, 661.0, 713.0, 314.0, 713.0], "score": 0.99, "text": "Qwen Team, Alibaba Group*"}, {"category_id": 15, "poly": [300.0, 225.0, 891.0, 222.0, 892.0, 270.0, 300.0, 273.0], "score": 1.0, "text": "QWEN2 TECHNICAL REPORT"}], "page_info": {"page_no": 0, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 2, "poly": [297.6734924316406, 227.99937438964844, 459.2312927246094, 227.99937438964844, 459.2312927246094, 259.6612243652344, 297.6734924316406, 259.6612243652344], "score": 0.9999823570251465}, {"category_id": 1, "poly": [338.50103759765625, 426.5530700683594, 1408.3629150390625, 426.5530700683594, 1408.3629150390625, 648.58740234375, 338.50103759765625, 648.58740234375], "score": 0.9998807311058044}, {"category_id": 1, "poly": [334.0255126953125, 901.6637573242188, 1407.2254638671875, 901.6637573242188, 1407.2254638671875, 1128.4696044921875, 334.0255126953125, 1128.4696044921875], "score": 0.9996749758720398}, {"category_id": 2, "poly": [841.2904663085938, 2088.013427734375, 860.8383178710938, 2088.013427734375, 860.8383178710938, 2113.9091796875, 841.2904663085938, 2113.9091796875], "score": 0.9993799924850464}, {"category_id": 0, "poly": [294.5660705566406, 376.9257507324219, 1410.77783203125, 376.9257507324219, 1410.77783203125, 412.63360595703125, 294.5660705566406, 412.63360595703125], "score": 0.9993481636047363}, {"category_id": 1, "poly": [338.4951171875, 1207.190185546875, 1411.836181640625, 1207.190185546875, 1411.836181640625, 1591.417724609375, 338.4951171875, 1591.417724609375], "score": 0.9967092275619507}, {"category_id": 1, "poly": [336.5875549316406, 725.3803100585938, 1408.1800537109375, 725.3803100585938, 1408.1800537109375, 818.2374267578125, 336.5875549316406, 818.2374267578125], "score": 0.9954625368118286}, {"category_id": 0, "poly": [296.5075378417969, 855.4736938476562, 1408.2332763671875, 855.4736938476562, 1408.2332763671875, 891.2488403320312, 296.5075378417969, 891.2488403320312], "score": 0.991872251033783}, {"category_id": 0, "poly": [297.7698974609375, 685.3760375976562, 1408.2127685546875, 685.3760375976562, 1408.2127685546875, 723.1614379882812, 297.7698974609375, 723.1614379882812], "score": 0.9880573153495789}, {"category_id": 0, "poly": [299.7178039550781, 1164.6475830078125, 1411.162353515625, 1164.6475830078125, 1411.162353515625, 1200.8607177734375, 299.7178039550781, 1200.8607177734375], "score": 0.9862799048423767}, {"category_id": 0, "poly": [299.123046875, 303.98968505859375, 496.63043212890625, 303.98968505859375, 496.63043212890625, 337.38970947265625, 299.123046875, 337.38970947265625], "score": 0.963126540184021}, {"category_id": 1, "poly": [299.07196044921875, 1618.576904296875, 1407.0181884765625, 1618.576904296875, 1407.0181884765625, 1650.8138427734375, 299.07196044921875, 1650.8138427734375], "score": 0.8613146543502808}, {"category_id": 0, "poly": [293.83111572265625, 304.23724365234375, 1414.300537109375, 304.23724365234375, 1414.300537109375, 337.7304992675781, 293.83111572265625, 337.7304992675781], "score": 0.48481354117393494}, {"category_id": 1, "poly": [340.9830017089844, 422.4791564941406, 1404.3800048828125, 422.4791564941406, 1404.3800048828125, 459.15081787109375, 340.9830017089844, 459.15081787109375], "score": 0.26471665501594543}, {"category_id": 0, "poly": [298.7261962890625, 1618.3724365234375, 1409.3260498046875, 1618.3724365234375, 1409.3260498046875, 1650.8966064453125, 298.7261962890625, 1650.8966064453125], "score": 0.20728614926338196}, {"category_id": 15, "poly": [298.0, 227.0, 460.0, 227.0, 460.0, 268.0, 298.0, 268.0], "score": 1.0, "text": "CONTENTS"}, {"category_id": 15, "poly": [335.0, 426.0, 522.0, 429.0, 522.0, 461.0, 335.0, 458.0], "score": 1.0, "text": "2.1Tokenizer"}, {"category_id": 15, "poly": [337.0, 477.0, 628.0, 477.0, 628.0, 509.0, 337.0, 509.0], "score": 0.95, "text": "2.2  Model Architecture"}, {"category_id": 15, "poly": [490.0, 522.0, 735.0, 522.0, 735.0, 555.0, 490.0, 555.0], "score": 1.0, "text": "Qwen2 Dense Model"}, {"category_id": 15, "poly": [402.0, 568.0, 487.0, 568.0, 487.0, 600.0, 402.0, 600.0], "score": 1.0, "text": "2.2.2"}, {"category_id": 15, "poly": [487.0, 571.0, 880.0, 571.0, 880.0, 603.0, 487.0, 603.0], "score": 0.98, "text": " Qwen2 Mixture-of-experts Model"}, {"category_id": 15, "poly": [404.0, 619.0, 494.0, 619.0, 494.0, 644.0, 404.0, 644.0], "score": 1.0, "text": "2.2.3"}, {"category_id": 15, "poly": [483.0, 612.0, 735.0, 617.0, 734.0, 653.0, 482.0, 648.0], "score": 0.98, "text": " Model Configuration"}, {"category_id": 15, "poly": [337.0, 908.0, 626.0, 908.0, 626.0, 940.0, 337.0, 940.0], "score": 0.95, "text": "4.1 Post-training Data ."}, {"category_id": 15, "poly": [402.0, 953.0, 841.0, 953.0, 841.0, 985.0, 402.0, 985.0], "score": 0.98, "text": "4.1.1 Collaborative Data Annotation"}, {"category_id": 15, "poly": [400.0, 999.0, 792.0, 1002.0, 792.0, 1034.0, 400.0, 1031.0], "score": 0.97, "text": "4.1.2Automated Data Synthesis"}, {"category_id": 15, "poly": [335.0, 1045.0, 672.0, 1050.0, 672.0, 1082.0, 335.0, 1077.0], "score": 0.96, "text": " 4.2Supervised Fine-tuning"}, {"category_id": 15, "poly": [335.0, 1093.0, 945.0, 1095.0, 945.0, 1128.0, 335.0, 1125.0], "score": 0.97, "text": "4.3 Reinforcement Learning from Human Feedback"}, {"category_id": 15, "poly": [1386.0, 1102.0, 1397.0, 1102.0, 1397.0, 1114.0, 1386.0, 1114.0], "score": 0.74, "text": "X"}, {"category_id": 15, "poly": [293.0, 380.0, 568.0, 380.0, 568.0, 412.0, 293.0, 412.0], "score": 0.96, "text": "2 Tokenizer & Model"}, {"category_id": 15, "poly": [337.0, 1217.0, 670.0, 1217.0, 670.0, 1249.0, 337.0, 1249.0], "score": 0.97, "text": "5.1 Base Language Models"}, {"category_id": 15, "poly": [1381.0, 1219.0, 1404.0, 1219.0, 1404.0, 1244.0, 1381.0, 1244.0], "score": 1.0, "text": "8"}, {"category_id": 15, "poly": [402.0, 1263.0, 492.0, 1263.0, 492.0, 1295.0, 402.0, 1295.0], "score": 1.0, "text": "5.1.1"}, {"category_id": 15, "poly": [483.0, 1265.0, 691.0, 1265.0, 691.0, 1297.0, 483.0, 1297.0], "score": 0.97, "text": " Core Capabilities"}, {"category_id": 15, "poly": [1381.0, 1265.0, 1404.0, 1265.0, 1404.0, 1290.0, 1381.0, 1290.0], "score": 1.0, "text": "8"}, {"category_id": 15, "poly": [337.0, 1311.0, 681.0, 1311.0, 681.0, 1343.0, 337.0, 1343.0], "score": 0.99, "text": "5.2 Instruction-tuned Model"}, {"category_id": 15, "poly": [1372.0, 1311.0, 1404.0, 1311.0, 1404.0, 1343.0, 1372.0, 1343.0], "score": 1.0, "text": "12"}, {"category_id": 15, "poly": [402.0, 1359.0, 841.0, 1359.0, 841.0, 1391.0, 402.0, 1391.0], "score": 0.97, "text": "5.2.1  Open Benchmark Evaluation ."}, {"category_id": 15, "poly": [1370.0, 1357.0, 1404.0, 1357.0, 1404.0, 1389.0, 1370.0, 1389.0], "score": 1.0, "text": "12"}, {"category_id": 15, "poly": [402.0, 1405.0, 474.0, 1405.0, 474.0, 1437.0, 402.0, 1437.0], "score": 1.0, "text": "5.2.2"}, {"category_id": 15, "poly": [481.0, 1402.0, 848.0, 1405.0, 848.0, 1437.0, 480.0, 1435.0], "score": 0.99, "text": " In-house Automatic Evaluation"}, {"category_id": 15, "poly": [1370.0, 1405.0, 1407.0, 1405.0, 1407.0, 1435.0, 1370.0, 1435.0], "score": 1.0, "text": "14"}, {"category_id": 15, "poly": [402.0, 1453.0, 474.0, 1453.0, 474.0, 1485.0, 402.0, 1485.0], "score": 1.0, "text": "5.2.3"}, {"category_id": 15, "poly": [483.0, 1453.0, 792.0, 1453.0, 792.0, 1485.0, 483.0, 1485.0], "score": 0.99, "text": " Long Context Capabilities"}, {"category_id": 15, "poly": [1370.0, 1451.0, 1404.0, 1451.0, 1404.0, 1483.0, 1370.0, 1483.0], "score": 0.79, "text": "15"}, {"category_id": 15, "poly": [404.0, 1503.0, 469.0, 1503.0, 469.0, 1529.0, 404.0, 1529.0], "score": 1.0, "text": "5.2.4"}, {"category_id": 15, "poly": [490.0, 1501.0, 762.0, 1501.0, 762.0, 1533.0, 490.0, 1533.0], "score": 1.0, "text": "Multilingual Evaluation"}, {"category_id": 15, "poly": [1370.0, 1501.0, 1404.0, 1501.0, 1404.0, 1531.0, 1370.0, 1531.0], "score": 1.0, "text": "18"}, {"category_id": 15, "poly": [400.0, 1545.0, 762.0, 1547.0, 762.0, 1581.0, 399.0, 1579.0], "score": 0.98, "text": "5.2.5 Safety & Responsibility"}, {"category_id": 15, "poly": [1372.0, 1547.0, 1404.0, 1547.0, 1404.0, 1577.0, 1372.0, 1577.0], "score": 1.0, "text": "18"}, {"category_id": 15, "poly": [337.0, 740.0, 607.0, 740.0, 607.0, 772.0, 337.0, 772.0], "score": 0.96, "text": "3.1 Pre-training Data"}, {"category_id": 15, "poly": [333.0, 781.0, 665.0, 784.0, 665.0, 823.0, 333.0, 820.0], "score": 0.96, "text": " 3.2 Long-context Training"}, {"category_id": 15, "poly": [294.0, 852.0, 502.0, 857.0, 501.0, 899.0, 293.0, 893.0], "score": 0.99, "text": "4  Post-training"}, {"category_id": 15, "poly": [292.0, 685.0, 490.0, 690.0, 489.0, 731.0, 291.0, 726.0], "score": 0.96, "text": "3  Pre-training"}, {"category_id": 15, "poly": [1384.0, 697.0, 1404.0, 697.0, 1404.0, 717.0, 1384.0, 717.0], "score": 1.0, "text": "5"}, {"category_id": 15, "poly": [293.0, 1169.0, 474.0, 1169.0, 474.0, 1208.0, 293.0, 1208.0], "score": 0.94, "text": "5 Evaluation"}, {"category_id": 15, "poly": [293.0, 305.0, 497.0, 305.0, 497.0, 344.0, 293.0, 344.0], "score": 0.95, "text": "1  Introduction"}, {"category_id": 15, "poly": [293.0, 1618.0, 480.0, 1618.0, 480.0, 1657.0, 293.0, 1657.0], "score": 1.0, "text": "6Conclusion"}, {"category_id": 15, "poly": [1370.0, 1622.0, 1404.0, 1622.0, 1404.0, 1657.0, 1370.0, 1657.0], "score": 1.0, "text": "19"}, {"category_id": 15, "poly": [291.0, 302.0, 494.0, 302.0, 494.0, 341.0, 291.0, 341.0], "score": 0.94, "text": "1  Introduction"}, {"category_id": 15, "poly": [337.0, 429.0, 524.0, 429.0, 524.0, 461.0, 337.0, 461.0], "score": 0.94, "text": "2.1 Tokenizer "}, {"category_id": 15, "poly": [293.0, 1618.0, 480.0, 1618.0, 480.0, 1657.0, 293.0, 1657.0], "score": 1.0, "text": "6Conclusion"}, {"category_id": 15, "poly": [1370.0, 1622.0, 1404.0, 1622.0, 1404.0, 1657.0, 1370.0, 1657.0], "score": 1.0, "text": "19"}], "page_info": {"page_no": 1, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [298.44537353515625, 1091.326904296875, 1404.9818115234375, 1091.326904296875, 1404.9818115234375, 1304.5870361328125, 298.44537353515625, 1304.5870361328125], "score": 0.9999939203262329}, {"category_id": 1, "poly": [298.67962646484375, 647.7058715820312, 1403.969482421875, 647.7058715820312, 1403.969482421875, 1074.523193359375, 298.67962646484375, 1074.523193359375], "score": 0.9999898672103882}, {"category_id": 0, "poly": [298.98638916015625, 1609.3212890625, 671.1273803710938, 1609.3212890625, 671.1273803710938, 1643.9671630859375, 298.98638916015625, 1643.9671630859375], "score": 0.9999890327453613}, {"category_id": 1, "poly": [298.37896728515625, 1318.0174560546875, 1404.470947265625, 1318.0174560546875, 1404.470947265625, 1564.59814453125, 298.37896728515625, 1564.59814453125], "score": 0.9999885559082031}, {"category_id": 0, "poly": [299.1402893066406, 1776.70166015625, 507.4900207519531, 1776.70166015625, 507.4900207519531, 1807.3350830078125, 299.1402893066406, 1807.3350830078125], "score": 0.9999811053276062}, {"category_id": 1, "poly": [299.12786865234375, 296.0213928222656, 1403.5953369140625, 296.0213928222656, 1403.5953369140625, 632.5955200195312, 299.12786865234375, 632.5955200195312], "score": 0.999980628490448}, {"category_id": 1, "poly": [299.49334716796875, 1678.100341796875, 1401.832763671875, 1678.100341796875, 1401.832763671875, 1739.22021484375, 299.49334716796875, 1739.22021484375], "score": 0.9999741315841675}, {"category_id": 1, "poly": [298.8036804199219, 1943.06103515625, 1402.5767822265625, 1943.06103515625, 1402.5767822265625, 2033.9215087890625, 298.8036804199219, 2033.9215087890625], "score": 0.9999474287033081}, {"category_id": 1, "poly": [298.83123779296875, 1835.6717529296875, 1403.95654296875, 1835.6717529296875, 1403.95654296875, 1925.2830810546875, 298.83123779296875, 1925.2830810546875], "score": 0.9998385906219482}, {"category_id": 2, "poly": [301.8505859375, 229.2705535888672, 574.9265747070312, 229.2705535888672, 574.9265747070312, 260.745849609375, 301.8505859375, 260.745849609375], "score": 0.999521017074585}, {"category_id": 2, "poly": [842.3745727539062, 2088.33447265625, 858.0833740234375, 2088.33447265625, 858.0833740234375, 2111.231689453125, 842.3745727539062, 2111.231689453125], "score": 0.9987949132919312}, {"category_id": 15, "poly": [298.0, 1093.0, 1402.0, 1093.0, 1402.0, 1125.0, 298.0, 1125.0], "score": 0.99, "text": "All models were pre-trained on a high-quality, large-scale dataset comprising over 7 trillion tokens,"}, {"category_id": 15, "poly": [298.0, 1125.0, 1404.0, 1125.0, 1404.0, 1155.0, 298.0, 1155.0], "score": 1.0, "text": "covering a wide range of domains and languages. Compared to previous editions of Qwen, Qwen2"}, {"category_id": 15, "poly": [296.0, 1155.0, 1402.0, 1155.0, 1402.0, 1187.0, 296.0, 1187.0], "score": 0.99, "text": "includes a broader spectrum of linguistic data, enhancing the quantity and quality of code and mathe-"}, {"category_id": 15, "poly": [298.0, 1185.0, 1404.0, 1185.0, 1404.0, 1217.0, 298.0, 1217.0], "score": 0.99, "text": "matics content. This enrichment is hypothesized to improve reasoning abilities of LLMs. Regarding"}, {"category_id": 15, "poly": [296.0, 1215.0, 1402.0, 1215.0, 1402.0, 1247.0, 296.0, 1247.0], "score": 1.0, "text": "post-training, all models underwent supervised fine-tuning and direct preference optimization (DPO,"}, {"category_id": 15, "poly": [296.0, 1242.0, 1404.0, 1244.0, 1404.0, 1276.0, 296.0, 1274.0], "score": 0.99, "text": "Rafailov et al., 2023), aligning them with human preferences through learning from human feedback."}, {"category_id": 15, "poly": [296.0, 1272.0, 1240.0, 1274.0, 1240.0, 1306.0, 296.0, 1304.0], "score": 0.99, "text": "This process endows the models with the capability to follow instructions effectively."}, {"category_id": 15, "poly": [298.0, 649.0, 1402.0, 649.0, 1402.0, 681.0, 298.0, 681.0], "score": 1.0, "text": "Over recent months, we have successively introduced the Qwen series (Bai et al., 2023a) and"}, {"category_id": 15, "poly": [293.0, 676.0, 1404.0, 676.0, 1404.0, 715.0, 293.0, 715.0], "score": 0.99, "text": " progressed to Qwen1.5 (Qwen Team, 2024a). In the meantime, we have unveiled the vision-language"}, {"category_id": 15, "poly": [298.0, 710.0, 1402.0, 710.0, 1402.0, 742.0, 298.0, 742.0], "score": 0.99, "text": "model Qwen-VL (Bai et al., 2023b), and launched the audio-language model Qwen-Audio (Chu"}, {"category_id": 15, "poly": [291.0, 733.0, 1407.0, 738.0, 1407.0, 777.0, 291.0, 772.0], "score": 0.98, "text": " et al., 2023). In this work, we introduce the newest addition to the Qwen family of large language"}, {"category_id": 15, "poly": [298.0, 770.0, 1404.0, 770.0, 1404.0, 802.0, 298.0, 802.0], "score": 0.99, "text": "models and large multimodal modles: Qwen2. Qwen2 is a series of LLMs, grounded in the"}, {"category_id": 15, "poly": [298.0, 802.0, 1402.0, 802.0, 1402.0, 834.0, 298.0, 834.0], "score": 0.99, "text": "Transformer architecture (Vaswani et al., 2017), trained using next-token prediction. The model"}, {"category_id": 15, "poly": [296.0, 830.0, 1402.0, 830.0, 1402.0, 862.0, 296.0, 862.0], "score": 0.99, "text": "series encompasses foundational, i.e., base language models, pre-trained but unaligned to human"}, {"category_id": 15, "poly": [293.0, 864.0, 1404.0, 862.0, 1404.0, 894.0, 293.0, 896.0], "score": 1.0, "text": " preferences, and instruction-tuned models, fine-tuned with single-turn and multi-turn instruction-"}, {"category_id": 15, "poly": [293.0, 887.0, 1404.0, 889.0, 1404.0, 928.0, 293.0, 926.0], "score": 0.98, "text": "following datasets suitable for chat and agent purposes. Our release comprises four dense models"}, {"category_id": 15, "poly": [298.0, 924.0, 1402.0, 924.0, 1402.0, 956.0, 298.0, 956.0], "score": 0.99, "text": "with parameter counts of 0.5 billion, 1.5 billion, 7 billion, and 72 billion, plus a Mixture-of-Experts"}, {"category_id": 15, "poly": [296.0, 953.0, 1400.0, 953.0, 1400.0, 985.0, 296.0, 985.0], "score": 1.0, "text": "(MoE) model with 57 billion parameters, of which 14 billion are activated for each token. The smaller"}, {"category_id": 15, "poly": [296.0, 985.0, 1402.0, 985.0, 1402.0, 1018.0, 296.0, 1018.0], "score": 0.99, "text": "models, specifically Qwen2-0.5B and Qwen2-1.5B, are designed for easy deployment on portable"}, {"category_id": 15, "poly": [296.0, 1015.0, 1402.0, 1015.0, 1402.0, 1047.0, 296.0, 1047.0], "score": 0.99, "text": "devices such as smartphones, earphones, and smart glasses. Conversely, the larger models cater to"}, {"category_id": 15, "poly": [298.0, 1045.0, 783.0, 1045.0, 783.0, 1077.0, 298.0, 1077.0], "score": 0.99, "text": "deployment across GPUs of varying scales."}, {"category_id": 15, "poly": [296.0, 1611.0, 672.0, 1611.0, 672.0, 1650.0, 296.0, 1650.0], "score": 0.94, "text": "2TOKENIZER & MODEL"}, {"category_id": 15, "poly": [293.0, 1315.0, 1407.0, 1318.0, 1407.0, 1357.0, 293.0, 1354.0], "score": 0.98, "text": "We have conducted a thorough evaluation of Qwen2, alongside a selection of baseline models includ-"}, {"category_id": 15, "poly": [291.0, 1347.0, 1404.0, 1350.0, 1404.0, 1389.0, 291.0, 1386.0], "score": 0.99, "text": " ing both open-weight and proprietary models accessible via API. Qwen2 outperforms competing"}, {"category_id": 15, "poly": [296.0, 1380.0, 1404.0, 1380.0, 1404.0, 1419.0, 296.0, 1419.0], "score": 0.98, "text": "models in evaluations of both fundamental language capabilities and instruction-tuned functionalities"}, {"category_id": 15, "poly": [298.0, 1414.0, 1402.0, 1414.0, 1402.0, 1446.0, 298.0, 1446.0], "score": 1.0, "text": "Specifically, Qwen2-72B-Instruct, our instruction-tuned variant, scores 9.1 on MT-Bench (Zheng"}, {"category_id": 15, "poly": [296.0, 1444.0, 1404.0, 1444.0, 1404.0, 1476.0, 296.0, 1476.0], "score": 0.99, "text": "et al., 2023), 48.1 on Arena-Hard (Chiang et al., 2024), and 35.7 on LiveCodeBench (Jain et al.,"}, {"category_id": 15, "poly": [296.0, 1474.0, 1402.0, 1474.0, 1402.0, 1506.0, 296.0, 1506.0], "score": 0.99, "text": "2024). Meanwhile, Qwen2-72B, the base language model, achieves 84.2 on MMLU (Hendrycks"}, {"category_id": 15, "poly": [298.0, 1503.0, 1407.0, 1503.0, 1407.0, 1535.0, 298.0, 1535.0], "score": 0.99, "text": "et al., 2021a), 37.9 on GPQA (Rein et al., 2023), 64.6 on HumanEval (Chen et al., 2021), 89.5 on"}, {"category_id": 15, "poly": [296.0, 1535.0, 1074.0, 1535.0, 1074.0, 1568.0, 296.0, 1568.0], "score": 0.99, "text": "GSM8K (Cobbe et al., 2021), and 82.4 on BBH (Suzgun et al., 2023)."}, {"category_id": 15, "poly": [293.0, 1776.0, 510.0, 1776.0, 510.0, 1815.0, 293.0, 1815.0], "score": 1.0, "text": "2.1TOKENIZER"}, {"category_id": 15, "poly": [298.0, 298.0, 1402.0, 298.0, 1402.0, 330.0, 298.0, 330.0], "score": 1.0, "text": "Following the emergence of ChatGPT (OpenAI, 2022), enthusiasm for large language models"}, {"category_id": 15, "poly": [298.0, 328.0, 1402.0, 328.0, 1402.0, 360.0, 298.0, 360.0], "score": 0.99, "text": "(LLMs) has escalated globally. The release of the Llama series (Touvron et al., 2023) has further"}, {"category_id": 15, "poly": [296.0, 355.0, 1407.0, 355.0, 1407.0, 394.0, 296.0, 394.0], "score": 0.98, "text": "ignited interests within the open-source community, particularly regarding GPT-level local LLMs."}, {"category_id": 15, "poly": [296.0, 387.0, 1402.0, 387.0, 1402.0, 419.0, 296.0, 419.0], "score": 0.99, "text": "Recently, Claude-3 Opus (Anthropic, 2024) and GPT-4o (omni) (OpenAI, 2024), the updated model"}, {"category_id": 15, "poly": [296.0, 419.0, 1404.0, 419.0, 1404.0, 451.0, 296.0, 451.0], "score": 0.99, "text": "for ChatGPT, have ascended to the pinnacle of the Chatbot Arena (Chiang et al., 2024) in quick"}, {"category_id": 15, "poly": [298.0, 449.0, 1404.0, 449.0, 1404.0, 481.0, 298.0, 481.0], "score": 0.99, "text": "succession. This platform is well-regarded for its human evaluations of LLMs. Moreover, Llama-"}, {"category_id": 15, "poly": [293.0, 474.0, 1407.0, 477.0, 1407.0, 516.0, 293.0, 513.0], "score": 0.99, "text": " 3 (AI@ Meta, 2024) has emerged as the state-of-the-art open-weight model series, narrowing the"}, {"category_id": 15, "poly": [291.0, 509.0, 1407.0, 504.0, 1407.0, 543.0, 291.0, 548.0], "score": 0.98, "text": " performance gap with leading proprietary models and widely acknowledged as GPT-4-level. An"}, {"category_id": 15, "poly": [291.0, 539.0, 1407.0, 534.0, 1407.0, 573.0, 291.0, 578.0], "score": 0.99, "text": " increasing number of competitive LLMs are now pursuing advancements similar to those made by the"}, {"category_id": 15, "poly": [293.0, 568.0, 1402.0, 573.0, 1402.0, 605.0, 293.0, 600.0], "score": 0.98, "text": " GPT series from OpenAI. Many of these models, including Qwen (Bai et al., 2023a), Mistral (Jiang"}, {"category_id": 15, "poly": [296.0, 603.0, 1377.0, 603.0, 1377.0, 635.0, 296.0, 635.0], "score": 0.99, "text": "et al., 2023a), Gemma (Mesnard et al., 2024), etc., have been released in an open-weight manner."}, {"category_id": 15, "poly": [298.0, 1677.0, 1402.0, 1680.0, 1402.0, 1712.0, 298.0, 1710.0], "score": 1.0, "text": "This section introduces the tokenizer and model design of Qwen2. We detail the model architecture"}, {"category_id": 15, "poly": [298.0, 1710.0, 788.0, 1712.0, 788.0, 1744.0, 298.0, 1742.0], "score": 0.99, "text": "and configurations for different model sizes."}, {"category_id": 15, "poly": [298.0, 1946.0, 1402.0, 1946.0, 1402.0, 1978.0, 298.0, 1978.0], "score": 0.99, "text": "Models of all sizes employ a common vocabulary consisting of 151,643 regular tokens and 3 control"}, {"category_id": 15, "poly": [293.0, 1968.0, 1404.0, 1973.0, 1404.0, 2012.0, 293.0, 2007.0], "score": 0.98, "text": "tokens. For more information, please refer to Bai et al. (2023a). It should be noted that, owing to"}, {"category_id": 15, "poly": [296.0, 2003.0, 1229.0, 2008.0, 1229.0, 2040.0, 296.0, 2035.0], "score": 0.99, "text": "considerations in distributed training, the effective size for the embeddings is larger."}, {"category_id": 15, "poly": [298.0, 1838.0, 1402.0, 1838.0, 1402.0, 1870.0, 298.0, 1870.0], "score": 0.99, "text": "Following Qwen (Bai et al., 2023a), we employ the identical tokenizer based on byte-level byte-"}, {"category_id": 15, "poly": [298.0, 1870.0, 1402.0, 1870.0, 1402.0, 1900.0, 298.0, 1900.0], "score": 0.98, "text": "pair encoding. Notably, this tokenizer exhibits high encoding efficiency, as evidenced by its better"}, {"category_id": 15, "poly": [298.0, 1898.0, 1310.0, 1898.0, 1310.0, 1930.0, 298.0, 1930.0], "score": 0.99, "text": "compression rate relative to alternatives, facilitating the multilingual capabilities of Qwen2."}, {"category_id": 15, "poly": [340.0, 227.0, 575.0, 227.0, 575.0, 266.0, 340.0, 266.0], "score": 1.0, "text": "INTRODUCTION"}], "page_info": {"page_no": 2, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [297.38690185546875, 1486.63134765625, 1405.2266845703125, 1486.63134765625, 1405.2266845703125, 1825.604736328125, 297.38690185546875, 1825.604736328125], "score": 0.9999914169311523}, {"category_id": 2, "poly": [297.78338623046875, 233.29901123046875, 654.5283813476562, 233.29901123046875, 654.5283813476562, 261.361328125, 297.78338623046875, 261.361328125], "score": 0.9999901652336121}, {"category_id": 1, "poly": [298.2479248046875, 509.3873291015625, 1402.8421630859375, 509.3873291015625, 1402.8421630859375, 601.4878540039062, 298.2479248046875, 601.4878540039062], "score": 0.9999884366989136}, {"category_id": 1, "poly": [297.7044677734375, 1850.447265625, 1404.41748046875, 1850.447265625, 1404.41748046875, 2034.886474609375, 297.7044677734375, 2034.886474609375], "score": 0.9999870657920837}, {"category_id": 1, "poly": [298.2664489746094, 292.0135803222656, 1405.194091796875, 292.0135803222656, 1405.194091796875, 413.85601806640625, 298.2664489746094, 413.85601806640625], "score": 0.9999858736991882}, {"category_id": 1, "poly": [298.60614013671875, 1164.8658447265625, 1403.0992431640625, 1164.8658447265625, 1403.0992431640625, 1289.1566162109375, 298.60614013671875, 1289.1566162109375], "score": 0.9999799728393555}, {"category_id": 0, "poly": [299.8476867675781, 454.1148376464844, 665.5665893554688, 454.1148376464844, 665.5665893554688, 486.5317077636719, 299.8476867675781, 486.5317077636719], "score": 0.9999772906303406}, {"category_id": 1, "poly": [297.5326232910156, 628.505615234375, 1403.4315185546875, 628.505615234375, 1403.4315185546875, 750.1558227539062, 297.5326232910156, 750.1558227539062], "score": 0.9999748468399048}, {"category_id": 1, "poly": [298.5597229003906, 977.1300659179688, 1402.538330078125, 977.1300659179688, 1402.538330078125, 1069.5216064453125, 298.5597229003906, 1069.5216064453125], "score": 0.9999747276306152}, {"category_id": 9, "poly": [1369.125244140625, 1313.154541015625, 1401.7369384765625, 1313.154541015625, 1401.7369384765625, 1341.3262939453125, 1369.125244140625, 1341.3262939453125], "score": 0.9999635219573975}, {"category_id": 8, "poly": [698.9192504882812, 1310.2327880859375, 995.9324951171875, 1310.2327880859375, 995.9324951171875, 1411.615966796875, 698.9192504882812, 1411.615966796875], "score": 0.9999620318412781}, {"category_id": 1, "poly": [298.38116455078125, 777.2661743164062, 1403.0140380859375, 777.2661743164062, 1403.0140380859375, 963.0607299804688, 298.38116455078125, 963.0607299804688], "score": 0.999957263469696}, {"category_id": 1, "poly": [297.5003662109375, 1430.3001708984375, 1128.1302490234375, 1430.3001708984375, 1128.1302490234375, 1463.0145263671875, 297.5003662109375, 1463.0145263671875], "score": 0.9999169707298279}, {"category_id": 9, "poly": [1368.81005859375, 1363.2022705078125, 1401.7235107421875, 1363.2022705078125, 1401.7235107421875, 1391.310791015625, 1368.81005859375, 1391.310791015625], "score": 0.9999082088470459}, {"category_id": 2, "poly": [841.1625366210938, 2089.691162109375, 858.59326171875, 2089.691162109375, 858.59326171875, 2111.345703125, 841.1625366210938, 2111.345703125], "score": 0.9994621276855469}, {"category_id": 0, "poly": [297.8567199707031, 1108.89111328125, 858.581298828125, 1108.89111328125, 858.581298828125, 1141.7598876953125, 297.8567199707031, 1141.7598876953125], "score": 0.998943030834198}, {"category_id": 14, "poly": [697, 1306, 999, 1306, 999, 1416, 697, 1416], "score": 0.9, "latex": "\\begin{array}{l}{{\\displaystyle{\\bf p}=\\mathrm{softmax}\\left(G\\left({\\bf x}\\right)\\right),}}\\\\ {{\\displaystyle{\\bf y}=\\sum_{i\\in\\mathrm{top}_{k}\\left({\\bf p}\\right)}{\\bf p}_{i}E_{i}({\\bf x}).}}\\end{array}"}, {"category_id": 13, "poly": [925, 1228, 957, 1228, 957, 1257, 925, 1257], "score": 0.89, "latex": "E_{i}"}, {"category_id": 13, "poly": [618, 1258, 642, 1258, 642, 1284, 618, 1284], "score": 0.83, "latex": "G"}, {"category_id": 13, "poly": [1053, 1201, 1072, 1201, 1072, 1223, 1053, 1223], "score": 0.78, "latex": "n"}, {"category_id": 15, "poly": [293.0, 1487.0, 1400.0, 1487.0, 1400.0, 1519.0, 293.0, 1519.0], "score": 0.99, "text": "Expert Granularity The key structural difference between MoE models and dense models is"}, {"category_id": 15, "poly": [296.0, 1522.0, 1404.0, 1522.0, 1404.0, 1554.0, 296.0, 1554.0], "score": 1.0, "text": "that MoE layers incorporate multiple FFNs, each serving as an individual expert. Consequently,"}, {"category_id": 15, "poly": [298.0, 1551.0, 1404.0, 1551.0, 1404.0, 1584.0, 298.0, 1584.0], "score": 0.99, "text": "one straightforward strategy to transition from a dense architecture to an MoE architecture is to set"}, {"category_id": 15, "poly": [293.0, 1579.0, 1407.0, 1579.0, 1407.0, 1618.0, 293.0, 1618.0], "score": 0.98, "text": " the parameters of each expert equal to those of a single FFN from the original dense model. For"}, {"category_id": 15, "poly": [293.0, 1609.0, 1407.0, 1606.0, 1407.0, 1645.0, 293.0, 1648.0], "score": 0.99, "text": " example, transitioning from Mistral-7B (Jiang et al., 2023a) to Mixtral 8x7B (Jiang et al., 2024),"}, {"category_id": 15, "poly": [296.0, 1643.0, 1402.0, 1643.0, 1402.0, 1675.0, 296.0, 1675.0], "score": 0.99, "text": "involves activating two of the eight experts at a time. Differently, our model employs fine-grained"}, {"category_id": 15, "poly": [298.0, 1673.0, 1404.0, 1673.0, 1404.0, 1705.0, 298.0, 1705.0], "score": 0.99, "text": "experts (Dai et al., 2024), creating smaller-scale experts while activating a greater number of experts"}, {"category_id": 15, "poly": [298.0, 1705.0, 1404.0, 1705.0, 1404.0, 1737.0, 298.0, 1737.0], "score": 0.98, "text": "simultaneously. Given an equal total number of expert parameters and activated parameters, fine-"}, {"category_id": 15, "poly": [296.0, 1735.0, 1402.0, 1735.0, 1402.0, 1767.0, 296.0, 1767.0], "score": 0.98, "text": " grained experts offer a richer set of expert combinations. By leveraging these fine-grained experts,"}, {"category_id": 15, "poly": [296.0, 1765.0, 1404.0, 1765.0, 1404.0, 1797.0, 296.0, 1797.0], "score": 0.98, "text": "Qwen2 MoE facilitates more diverse and dynamic expert utilization, thereby enhancing overall"}, {"category_id": 15, "poly": [296.0, 1797.0, 631.0, 1797.0, 631.0, 1829.0, 296.0, 1829.0], "score": 0.99, "text": "performance and adaptability."}, {"category_id": 15, "poly": [296.0, 229.0, 658.0, 229.0, 658.0, 268.0, 296.0, 268.0], "score": 0.98, "text": "2.2 MODEL ARCHITECTURE"}, {"category_id": 15, "poly": [296.0, 509.0, 1400.0, 511.0, 1400.0, 543.0, 296.0, 541.0], "score": 0.99, "text": "The architecture of the Qwen2 dense models comprises multiple Transformer layers, each equipped"}, {"category_id": 15, "poly": [298.0, 543.0, 1402.0, 543.0, 1402.0, 573.0, 298.0, 573.0], "score": 0.99, "text": "with causal attention mechanisms and feed-forward neural networks (FFNs). Key differences from"}, {"category_id": 15, "poly": [298.0, 573.0, 605.0, 573.0, 605.0, 603.0, 298.0, 603.0], "score": 0.99, "text": "Qwen are described below:"}, {"category_id": 15, "poly": [293.0, 1847.0, 1404.0, 1849.0, 1404.0, 1888.0, 293.0, 1886.0], "score": 0.98, "text": "Expert Routing  The design of expert routing mechanisms is crucial for enhancing the performance"}, {"category_id": 15, "poly": [298.0, 1884.0, 1402.0, 1884.0, 1402.0, 1914.0, 298.0, 1914.0], "score": 0.98, "text": "of MoE models. Recently, there has been a notable trend towards integrating both shared and"}, {"category_id": 15, "poly": [293.0, 1911.0, 1404.0, 1909.0, 1404.0, 1948.0, 293.0, 1950.0], "score": 0.98, "text": "routing-specific experts within MoE layers (Rajbhandari et al., 2022; Dai et al., 2024). We adopt this"}, {"category_id": 15, "poly": [291.0, 1939.0, 1407.0, 1936.0, 1407.0, 1982.0, 291.0, 1985.0], "score": 0.97, "text": " approach, as it facilitates the application of shared experts across various tasks while reserving others"}, {"category_id": 15, "poly": [298.0, 1975.0, 1402.0, 1975.0, 1402.0, 2008.0, 298.0, 2008.0], "score": 0.99, "text": "for selective use in specific routing scenarios. The introduction of shared and specialized experts"}, {"category_id": 15, "poly": [296.0, 2003.0, 1263.0, 2003.0, 1263.0, 2042.0, 296.0, 2042.0], "score": 0.99, "text": "offers a more adaptable and efficient method for developing MoE routing mechanisms."}, {"category_id": 15, "poly": [296.0, 291.0, 1404.0, 291.0, 1404.0, 330.0, 296.0, 330.0], "score": 0.99, "text": "The Qwen2 series fundamentally constitute large language models based on the Transformer ar-"}, {"category_id": 15, "poly": [298.0, 323.0, 1402.0, 323.0, 1402.0, 355.0, 298.0, 355.0], "score": 0.99, "text": "chitecture, featuring self-attention with causal masks (Vaswani et al., 2017). Specifically, this"}, {"category_id": 15, "poly": [296.0, 353.0, 1402.0, 351.0, 1402.0, 383.0, 296.0, 385.0], "score": 0.99, "text": "series encompasses dense language models of 4 scales and a Mixture-of-Experts (MoE) model. We"}, {"category_id": 15, "poly": [298.0, 385.0, 1404.0, 385.0, 1404.0, 417.0, 298.0, 417.0], "score": 0.99, "text": "introduce the specifics of the dense models before delving into the MoE model's distinctive attributes."}, {"category_id": 15, "poly": [298.0, 1169.0, 1402.0, 1169.0, 1402.0, 1199.0, 298.0, 1199.0], "score": 0.99, "text": "The architecture of Qwen2 MoE models closely mirrors that of Qwen1.5-MoE-A2.7B (Qwen Team,"}, {"category_id": 15, "poly": [298.0, 1263.0, 651.0, 1263.0, 651.0, 1292.0, 298.0, 1292.0], "score": 0.98, "text": "assigned by a gated network G:"}, {"category_id": 15, "poly": [298.0, 1228.0, 924.0, 1228.0, 924.0, 1267.0, 298.0, 1267.0], "score": 0.98, "text": "as an expert. Each token is directed to a specific expert"}, {"category_id": 15, "poly": [958.0, 1228.0, 1404.0, 1228.0, 1404.0, 1267.0, 958.0, 1267.0], "score": 1.0, "text": "for computation based on probabilities"}, {"category_id": 15, "poly": [296.0, 1196.0, 1052.0, 1201.0, 1052.0, 1233.0, 296.0, 1228.0], "score": 0.98, "text": "2024c). As a substitute for the original FFN, the MoE FFN consists of"}, {"category_id": 15, "poly": [1073.0, 1196.0, 1402.0, 1201.0, 1402.0, 1233.0, 1073.0, 1228.0], "score": 0.97, "text": "individual FFNs, each serving"}, {"category_id": 15, "poly": [298.0, 456.0, 668.0, 456.0, 668.0, 488.0, 298.0, 488.0], "score": 0.99, "text": "2.2.1 QWEN2 DENSE MODEL"}, {"category_id": 15, "poly": [300.0, 632.0, 1402.0, 632.0, 1402.0, 662.0, 300.0, 662.0], "score": 0.98, "text": "Grouped Query Attention We adopt Grouped Query Attention (GQA, Ainslie et al., 2023) instead"}, {"category_id": 15, "poly": [300.0, 662.0, 1402.0, 662.0, 1402.0, 694.0, 300.0, 694.0], "score": 0.99, "text": "of conventional multi-head attention (MHA). GQA optimizes KV cache usage during inference,"}, {"category_id": 15, "poly": [298.0, 692.0, 1404.0, 692.0, 1404.0, 724.0, 298.0, 724.0], "score": 0.99, "text": "significantly enhancing throughput. Detailed KV head configurations for various model sizes are"}, {"category_id": 15, "poly": [296.0, 722.0, 580.0, 722.0, 580.0, 754.0, 296.0, 754.0], "score": 0.96, "text": "reported in Section 2.2.3."}, {"category_id": 15, "poly": [293.0, 974.0, 1404.0, 976.0, 1404.0, 1015.0, 293.0, 1013.0], "score": 0.98, "text": "Moreover, we follow Qwen with the usage of SwiGLU (Dauphin et al., 2017) for activation, Rotary"}, {"category_id": 15, "poly": [298.0, 1011.0, 1404.0, 1011.0, 1404.0, 1043.0, 298.0, 1043.0], "score": 0.99, "text": "Positional Embeddings (RoPE, Su et al., 2024) for positional embedding, QKV bias (Su, 2023) for"}, {"category_id": 15, "poly": [293.0, 1036.0, 1250.0, 1038.0, 1250.0, 1077.0, 293.0, 1075.0], "score": 0.98, "text": " attention, RMSNorm (Jiang et al., 2023b) and pre-normalization for training stability."}, {"category_id": 15, "poly": [296.0, 777.0, 1400.0, 777.0, 1400.0, 809.0, 296.0, 809.0], "score": 0.99, "text": "Dual Chunk Attention with YARN To expand the context window of Qwen2, we implement Dual"}, {"category_id": 15, "poly": [296.0, 809.0, 1400.0, 809.0, 1400.0, 841.0, 296.0, 841.0], "score": 0.99, "text": "Chunk Attention (DCA, An et al., 2024), which segments long sequences into chunks of manageable"}, {"category_id": 15, "poly": [293.0, 839.0, 1402.0, 839.0, 1402.0, 871.0, 293.0, 871.0], "score": 0.99, "text": "lengths. If the input can be handled in a chunk, DCA produces the same result as the original"}, {"category_id": 15, "poly": [296.0, 871.0, 1404.0, 871.0, 1404.0, 903.0, 296.0, 903.0], "score": 1.0, "text": "attention. Otherwise, DCA facilitates effective capture of relative positional information between"}, {"category_id": 15, "poly": [296.0, 903.0, 1404.0, 903.0, 1404.0, 935.0, 296.0, 935.0], "score": 0.99, "text": "tokens within and across chunks, thereby improving long context performance. Moreover, we also"}, {"category_id": 15, "poly": [298.0, 933.0, 1372.0, 933.0, 1372.0, 965.0, 298.0, 965.0], "score": 0.99, "text": "employ YARN (Peng et al., 2023) to rescale the attention weights for better length extrapolation."}, {"category_id": 15, "poly": [298.0, 1432.0, 1125.0, 1432.0, 1125.0, 1464.0, 298.0, 1464.0], "score": 1.0, "text": "In the following, we present critical design considerations of Qwen2 MoE."}, {"category_id": 15, "poly": [296.0, 1111.0, 855.0, 1111.0, 855.0, 1144.0, 296.0, 1144.0], "score": 0.97, "text": "2.2.2 QWEN2 MIXTURE-OF-EXPERTS MODEL"}], "page_info": {"page_no": 3, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [296.6400146484375, 830.5936279296875, 1406.853515625, 830.5936279296875, 1406.853515625, 1201.47998046875, 296.6400146484375, 1201.47998046875], "score": 0.9999818801879883}, {"category_id": 5, "poly": [410.47186279296875, 339.7839050292969, 1287.5169677734375, 339.7839050292969, 1287.5169677734375, 775.6900634765625, 410.47186279296875, 775.6900634765625], "score": 0.9999755620956421}, {"category_id": 1, "poly": [297.36846923828125, 1333.315673828125, 1405.9971923828125, 1333.315673828125, 1405.9971923828125, 1520.0927734375, 297.36846923828125, 1520.0927734375], "score": 0.9999537467956543}, {"category_id": 1, "poly": [297.50091552734375, 1792.53515625, 1405.154296875, 1792.53515625, 1405.154296875, 1917.298828125, 297.50091552734375, 1917.298828125], "score": 0.9999504089355469}, {"category_id": 0, "poly": [299.07415771484375, 1564.724609375, 570.1680908203125, 1564.724609375, 570.1680908203125, 1600.429931640625, 299.07415771484375, 1600.429931640625], "score": 0.9998644590377808}, {"category_id": 1, "poly": [296.9307556152344, 1941.2841796875, 1406.0069580078125, 1941.2841796875, 1406.0069580078125, 2036.2515869140625, 296.9307556152344, 2036.2515869140625], "score": 0.9996733665466309}, {"category_id": 1, "poly": [298.78533935546875, 1635.007080078125, 1404.8907470703125, 1635.007080078125, 1404.8907470703125, 1698.0052490234375, 298.78533935546875, 1698.0052490234375], "score": 0.9996215105056763}, {"category_id": 0, "poly": [298.5316162109375, 1735.3238525390625, 619.8598022460938, 1735.3238525390625, 619.8598022460938, 1767.0618896484375, 298.5316162109375, 1767.0618896484375], "score": 0.9993805885314941}, {"category_id": 2, "poly": [840.1156005859375, 2087.18359375, 859.3706665039062, 2087.18359375, 859.3706665039062, 2112.149658203125, 840.1156005859375, 2112.149658203125], "score": 0.9993516802787781}, {"category_id": 1, "poly": [298.1369934082031, 1286.379150390625, 1286.993408203125, 1286.379150390625, 1286.993408203125, 1319.27880859375, 298.1369934082031, 1319.27880859375], "score": 0.9975940585136414}, {"category_id": 0, "poly": [298.3127746582031, 1231.6239013671875, 693.8899536132812, 1231.6239013671875, 693.8899536132812, 1266.8165283203125, 298.3127746582031, 1266.8165283203125], "score": 0.9963635802268982}, {"category_id": 6, "poly": [295.50653076171875, 221.38624572753906, 1407.439697265625, 221.38624572753906, 1407.439697265625, 319.4903869628906, 295.50653076171875, 319.4903869628906], "score": 0.996086597442627}, {"category_id": 13, "poly": [495, 954, 621, 954, 621, 988, 495, 988], "score": 0.92, "latex": "\\lceil n\\!\\times\\!h_{\\mathrm{E}}\\big/h_{\\mathrm{FN}}\\big]"}, {"category_id": 13, "poly": [1298, 924, 1354, 924, 1354, 954, 1298, 954], "score": 0.89, "latex": "h_{\\mathrm{FFN}}"}, {"category_id": 13, "poly": [580, 1107, 635, 1107, 635, 1136, 580, 1136], "score": 0.87, "latex": "50\\%"}, {"category_id": 13, "poly": [561, 924, 594, 924, 594, 953, 561, 953], "score": 0.86, "latex": "h_{\\mathrm{E}}"}, {"category_id": 13, "poly": [846, 930, 865, 930, 865, 952, 846, 952], "score": 0.72, "latex": "n"}, {"category_id": 15, "poly": [298.0, 834.0, 1402.0, 834.0, 1402.0, 866.0, 298.0, 866.0], "score": 0.98, "text": "Expert Initialization We initialize the experts in a similar way to upcycling (Komatsuzaki et al.,"}, {"category_id": 15, "poly": [296.0, 862.0, 1407.0, 862.0, 1407.0, 901.0, 296.0, 901.0], "score": 0.99, "text": "2023), leveraging the weights of a dense model. In contrast, our approach emphasizes diversification"}, {"category_id": 15, "poly": [298.0, 896.0, 1402.0, 896.0, 1402.0, 928.0, 298.0, 928.0], "score": 0.99, "text": "among fine-grained experts to enhance the model's representational breadth. Given the designated"}, {"category_id": 15, "poly": [293.0, 988.0, 1400.0, 988.0, 1400.0, 1020.0, 293.0, 1020.0], "score": 0.99, "text": " of experts while accommodating any arbitrary expert intermediate size. To promote diversity within"}, {"category_id": 15, "poly": [296.0, 1015.0, 1404.0, 1015.0, 1404.0, 1054.0, 296.0, 1054.0], "score": 0.98, "text": "each FFN copy, parameters are shuffed along the intermediate dimension. This guarantees that each"}, {"category_id": 15, "poly": [293.0, 1045.0, 1407.0, 1045.0, 1407.0, 1084.0, 293.0, 1084.0], "score": 0.99, "text": "fine-grained expert exhibits unique characteristics, even across different FFN copies. Subsequently,"}, {"category_id": 15, "poly": [296.0, 1079.0, 1404.0, 1079.0, 1404.0, 1111.0, 296.0, 1111.0], "score": 0.99, "text": "these experts are extracted from the FFN copies, and the remaining dimensions are discarded. For"}, {"category_id": 15, "poly": [296.0, 1139.0, 1407.0, 1139.0, 1407.0, 1171.0, 296.0, 1171.0], "score": 1.0, "text": "additional stochasticity into expert initialization, potentially enhancing the model's capacity for"}, {"category_id": 15, "poly": [291.0, 1166.0, 608.0, 1169.0, 607.0, 1208.0, 291.0, 1205.0], "score": 0.99, "text": " exploration during training."}, {"category_id": 15, "poly": [291.0, 951.0, 494.0, 956.0, 494.0, 992.0, 291.0, 988.0], "score": 0.99, "text": " FFN is replicated"}, {"category_id": 15, "poly": [622.0, 951.0, 1407.0, 956.0, 1407.0, 992.0, 622.0, 988.0], "score": 0.99, "text": "times. This replication ensures compatibility with the specified number"}, {"category_id": 15, "poly": [1355.0, 926.0, 1404.0, 926.0, 1404.0, 958.0, 1355.0, 958.0], "score": 0.88, "text": ", the"}, {"category_id": 15, "poly": [296.0, 1109.0, 579.0, 1109.0, 579.0, 1141.0, 296.0, 1141.0], "score": 1.0, "text": "each fine-grained expert,"}, {"category_id": 15, "poly": [636.0, 1109.0, 1404.0, 1109.0, 1404.0, 1141.0, 636.0, 1141.0], "score": 0.99, "text": " of its parameters are randomly reinitialized. This process introduces"}, {"category_id": 15, "poly": [298.0, 926.0, 560.0, 926.0, 560.0, 958.0, 298.0, 958.0], "score": 1.0, "text": "expert intermediate size"}, {"category_id": 15, "poly": [595.0, 926.0, 845.0, 926.0, 845.0, 958.0, 595.0, 958.0], "score": 1.0, "text": ", the number of experts"}, {"category_id": 15, "poly": [866.0, 926.0, 1297.0, 926.0, 1297.0, 958.0, 866.0, 958.0], "score": 0.97, "text": ", and the original FFN intermediate size"}, {"category_id": 15, "poly": [298.0, 1336.0, 1402.0, 1336.0, 1402.0, 1368.0, 298.0, 1368.0], "score": 0.99, "text": "The Qwen2 series consists of models of 5 sizes, which are Qwen2-0.5B, Qwen2-1.5B, Qwen2-7B,"}, {"category_id": 15, "poly": [296.0, 1366.0, 1400.0, 1366.0, 1400.0, 1398.0, 296.0, 1398.0], "score": 0.98, "text": "Qwen2-57B-A14B, and Qwen2-72B. Table 1 lists the hyper-parameters and important information,"}, {"category_id": 15, "poly": [293.0, 1396.0, 1407.0, 1393.0, 1407.0, 1432.0, 293.0, 1435.0], "score": 0.99, "text": "e.g., the number of pre-trained tokens. Particularly, Qwen2-57B-A14B is upscaled from Qwen2-7B."}, {"category_id": 15, "poly": [296.0, 1430.0, 1402.0, 1430.0, 1402.0, 1462.0, 296.0, 1462.0], "score": 1.0, "text": "Notably, Qwen2 models demonstrate a substantially lower Key-Value (KV) size per token relative"}, {"category_id": 15, "poly": [298.0, 1460.0, 1402.0, 1460.0, 1402.0, 1492.0, 298.0, 1492.0], "score": 1.0, "text": "to Qwen1.5 models. This characteristic translates into a reduced memory footprint, particularly"}, {"category_id": 15, "poly": [296.0, 1492.0, 801.0, 1492.0, 801.0, 1522.0, 296.0, 1522.0], "score": 1.0, "text": "advantageous in long-context inference tasks."}, {"category_id": 15, "poly": [298.0, 1797.0, 1400.0, 1797.0, 1400.0, 1829.0, 298.0, 1829.0], "score": 0.99, "text": "The pre-training of the Qwen2 models involves the development of a new, large-scale, high-quality"}, {"category_id": 15, "poly": [298.0, 1859.0, 1402.0, 1859.0, 1402.0, 1891.0, 298.0, 1891.0], "score": 0.99, "text": "Qwen and Qwen1.5 models (Bai et al., 2023a; Qwen Team, 2024a), enhancing the scale, quality, and"}, {"category_id": 15, "poly": [296.0, 1886.0, 889.0, 1891.0, 889.0, 1923.0, 296.0, 1918.0], "score": 0.99, "text": "diversity of the pre-training data in several key areas:"}, {"category_id": 15, "poly": [293.0, 1565.0, 566.0, 1565.0, 566.0, 1604.0, 293.0, 1604.0], "score": 1.0, "text": "3PRE-TRAINING"}, {"category_id": 15, "poly": [300.0, 1946.0, 1402.0, 1946.0, 1402.0, 1978.0, 300.0, 1978.0], "score": 0.97, "text": "Quality Enhancement  The filtering algorithm has been refined with additional heuristic and model-"}, {"category_id": 15, "poly": [298.0, 1973.0, 1402.0, 1975.0, 1402.0, 2008.0, 298.0, 2005.0], "score": 0.99, "text": "based methods, including the use of the Qwen models to filter out low-quality data. Moreover, these"}, {"category_id": 15, "poly": [293.0, 2001.0, 1002.0, 2003.0, 1002.0, 2042.0, 293.0, 2040.0], "score": 0.98, "text": " models are utilized to synthesize high-quality pre-training data."}, {"category_id": 15, "poly": [293.0, 1636.0, 1402.0, 1639.0, 1402.0, 1671.0, 293.0, 1668.0], "score": 0.99, "text": " In the pre-training of Qwen2, our efforts were focused on refining the dataset and investigating"}, {"category_id": 15, "poly": [293.0, 1664.0, 917.0, 1666.0, 917.0, 1705.0, 293.0, 1703.0], "score": 0.96, "text": " methods to handle extended context lengths effectively."}, {"category_id": 15, "poly": [296.0, 1735.0, 619.0, 1735.0, 619.0, 1774.0, 296.0, 1774.0], "score": 1.0, "text": "3.1 PRE-TRAINING DATA"}, {"category_id": 15, "poly": [298.0, 1290.0, 1282.0, 1290.0, 1282.0, 1322.0, 298.0, 1322.0], "score": 0.99, "text": "In the following, we provide the key configuration and information for the Qwen2 series."}, {"category_id": 15, "poly": [294.0, 1231.0, 688.0, 1233.0, 688.0, 1272.0, 293.0, 1270.0], "score": 0.99, "text": "2.2.3 MODEL CONFIGURATION"}, {"category_id": 15, "poly": [296.0, 227.0, 1400.0, 227.0, 1400.0, 259.0, 296.0, 259.0], "score": 1.0, "text": "Table 1: Architecture of Qwen2 dense and MoE models. For MoE models, 57B-A14B denotes that"}, {"category_id": 15, "poly": [298.0, 257.0, 1404.0, 257.0, 1404.0, 289.0, 298.0, 289.0], "score": 1.0, "text": "the model has 57B parameters in total and for each token 14B parameters are active, the Intermediate"}, {"category_id": 15, "poly": [298.0, 289.0, 1240.0, 289.0, 1240.0, 321.0, 298.0, 321.0], "score": 0.97, "text": "size denotes that of each expert, and # Activated Experts excludes the shared experts."}], "page_info": {"page_no": 4, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [297.5793762207031, 487.5835876464844, 1404.1107177734375, 487.5835876464844, 1404.1107177734375, 700.9957275390625, 297.5793762207031, 700.9957275390625], "score": 0.9999847412109375}, {"category_id": 1, "poly": [298.1483154296875, 1366.1318359375, 1404.7552490234375, 1366.1318359375, 1404.7552490234375, 1644.4344482421875, 298.1483154296875, 1644.4344482421875], "score": 0.9999815821647644}, {"category_id": 1, "poly": [296.7158203125, 378.3772277832031, 1404.7840576171875, 378.3772277832031, 1404.7840576171875, 470.8656921386719, 296.7158203125, 470.8656921386719], "score": 0.9999423027038574}, {"category_id": 1, "poly": [298.0557556152344, 964.0026245117188, 1403.156494140625, 964.0026245117188, 1403.156494140625, 1116.4156494140625, 298.0557556152344, 1116.4156494140625], "score": 0.9999415278434753}, {"category_id": 1, "poly": [297.30072021484375, 1882.3209228515625, 1405.1129150390625, 1882.3209228515625, 1405.1129150390625, 2036.4881591796875, 297.30072021484375, 2036.4881591796875], "score": 0.9999272227287292}, {"category_id": 1, "poly": [298.04766845703125, 715.1026611328125, 1403.953369140625, 715.1026611328125, 1403.953369140625, 870.4227294921875, 298.04766845703125, 870.4227294921875], "score": 0.9999257922172546}, {"category_id": 1, "poly": [298.038330078125, 1736.200439453125, 1403.5472412109375, 1736.200439453125, 1403.5472412109375, 1867.10791015625, 298.038330078125, 1867.10791015625], "score": 0.9999216794967651}, {"category_id": 1, "poly": [296.16064453125, 229.6908721923828, 1406.2802734375, 229.6908721923828, 1406.2802734375, 354.5464782714844, 296.16064453125, 354.5464782714844], "score": 0.9999038577079773}, {"category_id": 0, "poly": [298.9678039550781, 1301.48828125, 584.1826782226562, 1301.48828125, 584.1826782226562, 1333.445556640625, 298.9678039550781, 1333.445556640625], "score": 0.9998700618743896}, {"category_id": 1, "poly": [298.2104187011719, 1132.1162109375, 1403.53369140625, 1132.1162109375, 1403.53369140625, 1256.67236328125, 298.2104187011719, 1256.67236328125], "score": 0.9998421669006348}, {"category_id": 2, "poly": [841.084228515625, 2090.297119140625, 858.1881103515625, 2090.297119140625, 858.1881103515625, 2112.703125, 841.084228515625, 2112.703125], "score": 0.999351978302002}, {"category_id": 1, "poly": [297.9178466796875, 1679.2734375, 632.385009765625, 1679.2734375, 632.385009765625, 1710.578369140625, 297.9178466796875, 1710.578369140625], "score": 0.9706660509109497}, {"category_id": 0, "poly": [298.61968994140625, 908.1997680664062, 692.6254272460938, 908.1997680664062, 692.6254272460938, 938.2210693359375, 298.61968994140625, 938.2210693359375], "score": 0.9413647055625916}, {"category_id": 1, "poly": [302.7560729980469, 907.9458618164062, 694.2022705078125, 907.9458618164062, 694.2022705078125, 937.880859375, 302.7560729980469, 937.880859375], "score": 0.20761418342590332}, {"category_id": 13, "poly": [1184, 1734, 1355, 1734, 1355, 1769, 1184, 1769], "score": 0.94, "latex": "\\mathcal{D}=\\{(x_{i},y_{i})\\}"}, {"category_id": 13, "poly": [846, 2003, 946, 2003, 946, 2037, 846, 2037], "score": 0.93, "latex": "(y_{i}^{+},y_{i}^{-})"}, {"category_id": 13, "poly": [473, 1767, 699, 1767, 699, 1804, 473, 1804], "score": 0.93, "latex": "\\mathcal{P}=\\{(x_{i},y_{i}^{+},y_{i}^{-})\\}"}, {"category_id": 13, "poly": [911, 1801, 947, 1801, 947, 1837, 911, 1837], "score": 0.91, "latex": "y_{i}^{+}"}, {"category_id": 13, "poly": [456, 1801, 492, 1801, 492, 1837, 456, 1837], "score": 0.9, "latex": "y_{i}^{+}"}, {"category_id": 13, "poly": [543, 1805, 579, 1805, 579, 1837, 543, 1837], "score": 0.9, "latex": "y_{i}^{-}"}, {"category_id": 13, "poly": [1306, 1803, 1341, 1803, 1341, 1838, 1306, 1838], "score": 0.89, "latex": "y_{i}^{-}"}, {"category_id": 13, "poly": [783, 1775, 812, 1775, 812, 1800, 783, 1800], "score": 0.85, "latex": "x_{i}"}, {"category_id": 13, "poly": [1105, 1775, 1131, 1775, 1131, 1801, 1105, 1801], "score": 0.84, "latex": "y_{i}"}, {"category_id": 13, "poly": [297, 2008, 323, 2008, 323, 2035, 297, 2035], "score": 0.84, "latex": "y_{i}"}, {"category_id": 13, "poly": [665, 1836, 690, 1836, 690, 1862, 665, 1862], "score": 0.84, "latex": "\\mathcal{P}"}, {"category_id": 13, "poly": [816, 1808, 844, 1808, 844, 1834, 816, 1834], "score": 0.84, "latex": "x_{i}"}, {"category_id": 13, "poly": [335, 1836, 361, 1836, 361, 1861, 335, 1861], "score": 0.82, "latex": "\\mathcal{D}"}, {"category_id": 15, "poly": [296.0, 488.0, 1404.0, 488.0, 1404.0, 520.0, 296.0, 520.0], "score": 0.99, "text": "Based on these enhancements, the pre-training data was expanded from 3 trillion tokens in"}, {"category_id": 15, "poly": [298.0, 520.0, 1404.0, 520.0, 1404.0, 550.0, 298.0, 550.0], "score": 0.98, "text": "Qwen1.5 (Qwen Team, 2024a) to 7 trillion tokens. An attempt to further relax the quality threshold"}, {"category_id": 15, "poly": [298.0, 550.0, 1404.0, 550.0, 1404.0, 582.0, 298.0, 582.0], "score": 0.99, "text": "resulted in a 12 trillion token dataset. However, the model trained on this dataset did not show a"}, {"category_id": 15, "poly": [296.0, 580.0, 1402.0, 580.0, 1402.0, 612.0, 296.0, 612.0], "score": 0.99, "text": "significant performance improvement over the 7 trillion token model. It is suspected that increasing"}, {"category_id": 15, "poly": [293.0, 610.0, 1402.0, 612.0, 1402.0, 644.0, 293.0, 642.0], "score": 0.98, "text": " the volume of data does not necessarily benefit model pre-training. Considering training costs, we"}, {"category_id": 15, "poly": [296.0, 639.0, 1402.0, 639.0, 1402.0, 671.0, 296.0, 671.0], "score": 0.99, "text": "opted to use the higher-quality 7 trillion token dataset for training larger models, leaving further"}, {"category_id": 15, "poly": [296.0, 671.0, 732.0, 671.0, 732.0, 704.0, 296.0, 704.0], "score": 1.0, "text": "exploration for future model iterations."}, {"category_id": 15, "poly": [296.0, 1368.0, 1402.0, 1368.0, 1402.0, 1400.0, 296.0, 1400.0], "score": 1.0, "text": "Following extensive large-scale pre-training, we engage in a post-training phase for Qwen2. This"}, {"category_id": 15, "poly": [293.0, 1398.0, 1402.0, 1398.0, 1402.0, 1430.0, 293.0, 1430.0], "score": 0.99, "text": " process is pivotal in enhancing its proficiency across a broad spectrum of domains, including coding,"}, {"category_id": 15, "poly": [296.0, 1430.0, 1407.0, 1430.0, 1407.0, 1462.0, 296.0, 1462.0], "score": 1.0, "text": "mathematics, logical reasoning, instruction following, and multilingual comprehension. Moreover,"}, {"category_id": 15, "poly": [296.0, 1462.0, 1404.0, 1462.0, 1404.0, 1492.0, 296.0, 1492.0], "score": 0.99, "text": "it ensures that the generation from the models is in harmony with human values, making it helpful,"}, {"category_id": 15, "poly": [296.0, 1490.0, 1404.0, 1490.0, 1404.0, 1522.0, 296.0, 1522.0], "score": 1.0, "text": "honest, and harmless. Unlike traditional methods that heavily rely on extensive human supervision,"}, {"category_id": 15, "poly": [298.0, 1522.0, 1407.0, 1522.0, 1407.0, 1554.0, 298.0, 1554.0], "score": 0.98, "text": "our approach focuses on scalable alignment with minimal human annotation (Cao et al., 2024)."}, {"category_id": 15, "poly": [298.0, 1551.0, 1407.0, 1551.0, 1407.0, 1584.0, 298.0, 1584.0], "score": 0.99, "text": "Specifically, we investigate methods to acquire high-quality demonstration and preference data for "}, {"category_id": 15, "poly": [293.0, 1579.0, 1409.0, 1579.0, 1409.0, 1618.0, 293.0, 1618.0], "score": 0.99, "text": " Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF), aiming"}, {"category_id": 15, "poly": [296.0, 1613.0, 1377.0, 1613.0, 1377.0, 1645.0, 296.0, 1645.0], "score": 1.0, "text": "to minimize the need for human labeling while maximizing the quality and reliability of the data."}, {"category_id": 15, "poly": [296.0, 378.0, 1402.0, 383.0, 1402.0, 415.0, 296.0, 410.0], "score": 0.99, "text": "Distribution Improvement  To ensure the model learns the distribution akin to human-like learning,"}, {"category_id": 15, "poly": [296.0, 412.0, 1402.0, 412.0, 1402.0, 445.0, 296.0, 445.0], "score": 1.0, "text": "we conduct experiments on scaled-down models to optimize the mixing of data from various sources"}, {"category_id": 15, "poly": [298.0, 447.0, 448.0, 447.0, 448.0, 472.0, 298.0, 472.0], "score": 1.0, "text": "anddomains."}, {"category_id": 15, "poly": [293.0, 962.0, 1404.0, 962.0, 1404.0, 1001.0, 293.0, 1001.0], "score": 0.99, "text": "To enhance the long-context capability of Qwen2, we augmented the context length from 4,096 tokens"}, {"category_id": 15, "poly": [296.0, 997.0, 1402.0, 997.0, 1402.0, 1029.0, 296.0, 1029.0], "score": 1.0, "text": "to 32,768 tokens during the concluding phase of pre-training. This expansion was complemented by"}, {"category_id": 15, "poly": [296.0, 1027.0, 1400.0, 1027.0, 1400.0, 1059.0, 296.0, 1059.0], "score": 0.99, "text": "the introduction of a significantly increased volume of high-quality, lengthy data. In conjunction with"}, {"category_id": 15, "poly": [298.0, 1056.0, 1404.0, 1056.0, 1404.0, 1089.0, 298.0, 1089.0], "score": 0.99, "text": "these enhancements, we modified the base frequency of RoPE from 10,000 to 1,000,000 to optimize"}, {"category_id": 15, "poly": [298.0, 1089.0, 956.0, 1089.0, 956.0, 1121.0, 298.0, 1121.0], "score": 0.99, "text": "performance in long-context scenarios (Xiong et al., 2023)."}, {"category_id": 15, "poly": [298.0, 1884.0, 1402.0, 1884.0, 1402.0, 1916.0, 298.0, 1916.0], "score": 0.99, "text": "The construction of training data entails a two-step process: collaborative data annotation and"}, {"category_id": 15, "poly": [298.0, 1916.0, 1402.0, 1916.0, 1402.0, 1946.0, 298.0, 1946.0], "score": 1.0, "text": "automated data synthesis. First, we extract the data ontology from large-scale instruction corpora,"}, {"category_id": 15, "poly": [298.0, 1946.0, 1402.0, 1946.0, 1402.0, 1978.0, 298.0, 1978.0], "score": 1.0, "text": "leading to a broad and diverse set of high-quality instructions. These instructions are systematically"}, {"category_id": 15, "poly": [298.0, 1978.0, 1402.0, 1978.0, 1402.0, 2008.0, 298.0, 2008.0], "score": 1.0, "text": "enhanced to incorporate greater complexity. Through human annotation, we obtain the target response"}, {"category_id": 15, "poly": [947.0, 2003.0, 1404.0, 2003.0, 1404.0, 2042.0, 947.0, 2042.0], "score": 0.97, "text": ". Subsequently, a variety of automated"}, {"category_id": 15, "poly": [324.0, 2003.0, 845.0, 2003.0, 845.0, 2042.0, 324.0, 2042.0], "score": 0.98, "text": " and their positive and negative counterparts"}, {"category_id": 15, "poly": [296.0, 715.0, 1407.0, 715.0, 1407.0, 754.0, 296.0, 754.0], "score": 0.99, "text": "All Qwen2 dense models, excluding Qwen2-0.5B, were pre-trained on this large-scale dataset of"}, {"category_id": 15, "poly": [298.0, 749.0, 1402.0, 749.0, 1402.0, 781.0, 298.0, 781.0], "score": 0.99, "text": "over 7 trillion tokens. Qwen2-0.5B were pre-trained using the 12 trillion token dataset. The MoE"}, {"category_id": 15, "poly": [296.0, 777.0, 1404.0, 781.0, 1404.0, 814.0, 296.0, 809.0], "score": 0.99, "text": "model received an additional 4.5 trillion tokens of pre-training, in line with the principle of upcycling."}, {"category_id": 15, "poly": [298.0, 811.0, 1404.0, 811.0, 1404.0, 843.0, 298.0, 843.0], "score": 0.99, "text": "Similar to previous Qwen models, high-quality multi-task instruction data is integrated into the"}, {"category_id": 15, "poly": [300.0, 841.0, 1340.0, 841.0, 1340.0, 873.0, 300.0, 873.0], "score": 0.99, "text": "Qwen2 pre-training process to enhance in-context learning and instruction-following abilities."}, {"category_id": 15, "poly": [293.0, 1735.0, 1183.0, 1735.0, 1183.0, 1774.0, 293.0, 1774.0], "score": 0.98, "text": " The post-training data primarily consists of two components: demonstration data"}, {"category_id": 15, "poly": [1356.0, 1735.0, 1404.0, 1735.0, 1404.0, 1774.0, 1356.0, 1774.0], "score": 1.0, "text": "and"}, {"category_id": 15, "poly": [293.0, 1769.0, 472.0, 1769.0, 472.0, 1808.0, 293.0, 1808.0], "score": 0.98, "text": " preference data"}, {"category_id": 15, "poly": [296.0, 1804.0, 455.0, 1804.0, 455.0, 1842.0, 296.0, 1842.0], "score": 1.0, "text": "response, and"}, {"category_id": 15, "poly": [493.0, 1804.0, 542.0, 1804.0, 542.0, 1842.0, 493.0, 1842.0], "score": 1.0, "text": "and"}, {"category_id": 15, "poly": [948.0, 1804.0, 1305.0, 1804.0, 1305.0, 1842.0, 948.0, 1842.0], "score": 0.98, "text": "being the preferred choice over"}, {"category_id": 15, "poly": [1342.0, 1804.0, 1404.0, 1804.0, 1404.0, 1842.0, 1342.0, 1842.0], "score": 0.98, "text": ". The"}, {"category_id": 15, "poly": [700.0, 1769.0, 782.0, 1769.0, 782.0, 1808.0, 700.0, 1808.0], "score": 0.94, "text": ", where"}, {"category_id": 15, "poly": [813.0, 1769.0, 1104.0, 1769.0, 1104.0, 1808.0, 813.0, 1808.0], "score": 0.96, "text": "represents the instruction,"}, {"category_id": 15, "poly": [1132.0, 1769.0, 1404.0, 1769.0, 1404.0, 1808.0, 1132.0, 1808.0], "score": 1.0, "text": "represents a satisfactory"}, {"category_id": 15, "poly": [691.0, 1838.0, 942.0, 1838.0, 942.0, 1868.0, 691.0, 1868.0], "score": 0.99, "text": "is employed in RLHF."}, {"category_id": 15, "poly": [580.0, 1804.0, 815.0, 1804.0, 815.0, 1842.0, 580.0, 1842.0], "score": 1.0, "text": "are two responses to"}, {"category_id": 15, "poly": [845.0, 1804.0, 910.0, 1804.0, 910.0, 1842.0, 845.0, 1842.0], "score": 0.98, "text": ", with"}, {"category_id": 15, "poly": [298.0, 1838.0, 334.0, 1838.0, 334.0, 1868.0, 298.0, 1868.0], "score": 1.0, "text": "set"}, {"category_id": 15, "poly": [362.0, 1838.0, 664.0, 1838.0, 664.0, 1868.0, 362.0, 1868.0], "score": 0.99, "text": "is utilized in SFT, whereas"}, {"category_id": 15, "poly": [296.0, 229.0, 1402.0, 231.0, 1402.0, 264.0, 296.0, 261.0], "score": 0.98, "text": "Data Expansion  Compared to Qwen1.5 (Qwen Team, 2024a), we have collected a significantly"}, {"category_id": 15, "poly": [298.0, 266.0, 1402.0, 266.0, 1402.0, 296.0, 298.0, 296.0], "score": 0.99, "text": "larger volume of high-quality code, mathematics, and multilingual data, enhancing the model's capa-"}, {"category_id": 15, "poly": [298.0, 325.0, 1342.0, 325.0, 1342.0, 358.0, 298.0, 358.0], "score": 1.0, "text": "Chinese, Spanish, French, German, Arabic, Russian, Korean, Japanese, Thai, and Vietnamese."}, {"category_id": 15, "poly": [296.0, 1299.0, 582.0, 1299.0, 582.0, 1338.0, 296.0, 1338.0], "score": 1.0, "text": "4POST-TRAINING"}, {"category_id": 15, "poly": [293.0, 1127.0, 1404.0, 1132.0, 1404.0, 1171.0, 293.0, 1166.0], "score": 0.98, "text": " To fully leverage the model's length extrapolation potential, we adopted the YARN mechanism (Peng"}, {"category_id": 15, "poly": [298.0, 1164.0, 1402.0, 1164.0, 1402.0, 1196.0, 298.0, 1196.0], "score": 0.98, "text": "et al., 2023) and the Dual Chunk Attention mechanism (An et al., 2024). These strategies enable"}, {"category_id": 15, "poly": [296.0, 1194.0, 1402.0, 1196.0, 1402.0, 1228.0, 296.0, 1226.0], "score": 0.99, "text": "the model to process sequences of up to 131,072 tokens while maintaining high performance, as"}, {"category_id": 15, "poly": [298.0, 1228.0, 1113.0, 1228.0, 1113.0, 1260.0, 298.0, 1260.0], "score": 1.0, "text": "evidenced by minimal perplexity degradation in preliminary experiments."}, {"category_id": 15, "poly": [294.0, 1675.0, 631.0, 1678.0, 630.0, 1717.0, 293.0, 1714.0], "score": 0.99, "text": "4.1 POST-TRAINING DATA"}, {"category_id": 15, "poly": [296.0, 905.0, 691.0, 910.0, 690.0, 942.0, 296.0, 937.0], "score": 0.97, "text": "3.2 LONG-CONTEXT TRAINING"}, {"category_id": 15, "poly": [296.0, 905.0, 691.0, 910.0, 690.0, 942.0, 296.0, 937.0], "score": 0.97, "text": "3.2 LONG-CONTEXT TRAINING"}], "page_info": {"page_no": 5, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [297.42333984375, 1574.7669677734375, 1404.943603515625, 1574.7669677734375, 1404.943603515625, 1820.4091796875, 297.42333984375, 1820.4091796875], "score": 0.999992311000824}, {"category_id": 1, "poly": [297.415771484375, 1850.4786376953125, 1405.3900146484375, 1850.4786376953125, 1405.3900146484375, 2034.953857421875, 297.415771484375, 2034.953857421875], "score": 0.9999842643737793}, {"category_id": 1, "poly": [297.8554382324219, 548.21826171875, 1403.341796875, 548.21826171875, 1403.341796875, 640.592529296875, 297.8554382324219, 640.592529296875], "score": 0.9999823570251465}, {"category_id": 1, "poly": [298.2532958984375, 795.4998779296875, 1403.699951171875, 795.4998779296875, 1403.699951171875, 919.076171875, 298.2532958984375, 919.076171875], "score": 0.9999739527702332}, {"category_id": 1, "poly": [297.061279296875, 1358.1904296875, 1405.21533203125, 1358.1904296875, 1405.21533203125, 1544.4371337890625, 297.061279296875, 1544.4371337890625], "score": 0.9999688863754272}, {"category_id": 1, "poly": [297.56109619140625, 671.0260620117188, 1405.9609375, 671.0260620117188, 1405.9609375, 764.8956909179688, 297.56109619140625, 764.8956909179688], "score": 0.9999620318412781}, {"category_id": 1, "poly": [298.5215759277344, 1051.2320556640625, 1403.51171875, 1051.2320556640625, 1403.51171875, 1142.0323486328125, 298.5215759277344, 1142.0323486328125], "score": 0.9999615550041199}, {"category_id": 1, "poly": [297.38800048828125, 423.5633850097656, 1406.1251220703125, 423.5633850097656, 1406.1251220703125, 518.163330078125, 297.38800048828125, 518.163330078125], "score": 0.9999511241912842}, {"category_id": 1, "poly": [298.1602478027344, 231.86251831054688, 1404.6898193359375, 231.86251831054688, 1404.6898193359375, 295.2427062988281, 298.1602478027344, 295.2427062988281], "score": 0.9998646974563599}, {"category_id": 1, "poly": [296.7518310546875, 1173.0775146484375, 1405.3409423828125, 1173.0775146484375, 1405.3409423828125, 1328.01025390625, 296.7518310546875, 1328.01025390625], "score": 0.9997749328613281}, {"category_id": 0, "poly": [297.5265808105469, 358.9090881347656, 835.276611328125, 358.9090881347656, 835.276611328125, 389.81707763671875, 297.5265808105469, 389.81707763671875], "score": 0.9994706511497498}, {"category_id": 2, "poly": [842.2420654296875, 2089.405517578125, 857.7125244140625, 2089.405517578125, 857.7125244140625, 2110.144775390625, 842.2420654296875, 2110.144775390625], "score": 0.9992438554763794}, {"category_id": 0, "poly": [298.728271484375, 986.4564819335938, 759.3578491210938, 986.4564819335938, 759.3578491210938, 1015.723876953125, 298.728271484375, 1015.723876953125], "score": 0.9961134791374207}, {"category_id": 15, "poly": [298.0, 1577.0, 1402.0, 1577.0, 1402.0, 1609.0, 298.0, 1609.0], "score": 0.98, "text": "Data Repurposing  Creating skilled responses in literary writing tasks is challenging for annotators"}, {"category_id": 15, "poly": [296.0, 1606.0, 1402.0, 1606.0, 1402.0, 1639.0, 296.0, 1639.0], "score": 0.99, "text": "without specialized training. To tackle this problem, we aggregate high-quality literary works"}, {"category_id": 15, "poly": [293.0, 1634.0, 1407.0, 1634.0, 1407.0, 1673.0, 293.0, 1673.0], "score": 0.99, "text": "from the public domain and employ LLMs to develop instructions with varying levels of detail."}, {"category_id": 15, "poly": [296.0, 1668.0, 1404.0, 1668.0, 1404.0, 1700.0, 296.0, 1700.0], "score": 0.99, "text": "These instructions, paired with the original works, serve as demonstration data. For example, to"}, {"category_id": 15, "poly": [296.0, 1698.0, 1404.0, 1698.0, 1404.0, 1730.0, 296.0, 1730.0], "score": 0.99, "text": "compile roleplay data with vivid and engaging responses, we source detailed character profiles from"}, {"category_id": 15, "poly": [293.0, 1726.0, 1404.0, 1726.0, 1404.0, 1765.0, 293.0, 1765.0], "score": 0.99, "text": " knowledge repositories such as Wikipedia and instruct LLMs to generate corresponding instructions"}, {"category_id": 15, "poly": [296.0, 1760.0, 1407.0, 1760.0, 1407.0, 1792.0, 296.0, 1792.0], "score": 0.99, "text": "and responses (Lu et al., 2024b). This process, similar to a reading comprehension task, ensures that "}, {"category_id": 15, "poly": [293.0, 1790.0, 873.0, 1790.0, 873.0, 1822.0, 293.0, 1822.0], "score": 0.96, "text": " the integrity of the character's profile is maintained."}, {"category_id": 15, "poly": [293.0, 1847.0, 1404.0, 1849.0, 1404.0, 1888.0, 293.0, 1886.0], "score": 0.97, "text": " Constitutional Feedback  Constitutional AI refers to the process of guiding LLMs to generate"}, {"category_id": 15, "poly": [296.0, 1884.0, 1400.0, 1884.0, 1400.0, 1916.0, 296.0, 1916.0], "score": 0.99, "text": "responses based on predefined sets of principles (Bai et al., 2022). To ensure adherence to guidelines"}, {"category_id": 15, "poly": [293.0, 1909.0, 1404.0, 1911.0, 1404.0, 1950.0, 293.0, 1948.0], "score": 1.0, "text": "such as safety and values, a constitution dataset was compiled. This dataset delineates principles to"}, {"category_id": 15, "poly": [298.0, 1946.0, 1402.0, 1946.0, 1402.0, 1978.0, 298.0, 1978.0], "score": 0.99, "text": "be followed and those to be avoided. It was used to instruct LLMs to produce responses that either"}, {"category_id": 15, "poly": [293.0, 1973.0, 1402.0, 1975.0, 1402.0, 2008.0, 293.0, 2005.0], "score": 0.99, "text": " are aligned with or deviated from these guidelines, serving as a reference for demonstration and"}, {"category_id": 15, "poly": [296.0, 2008.0, 478.0, 2008.0, 478.0, 2037.0, 296.0, 2037.0], "score": 1.0, "text": "preferencedata."}, {"category_id": 15, "poly": [296.0, 548.0, 1400.0, 550.0, 1400.0, 582.0, 296.0, 580.0], "score": 0.99, "text": "Instruction Selection  Each instruction, with tags annotated, is evaluated for tag diversity, semantic"}, {"category_id": 15, "poly": [296.0, 580.0, 1402.0, 582.0, 1402.0, 614.0, 296.0, 612.0], "score": 0.99, "text": "richness, complexity, and intent completeness. Based on these criteria, we select a set of representative"}, {"category_id": 15, "poly": [296.0, 612.0, 654.0, 612.0, 654.0, 644.0, 296.0, 644.0], "score": 0.98, "text": "instructions (Dong et al., 2023)."}, {"category_id": 15, "poly": [296.0, 795.0, 1402.0, 798.0, 1402.0, 830.0, 296.0, 827.0], "score": 1.0, "text": "Human Annotation Multiple responses to an instruction are obtained using diverse generation"}, {"category_id": 15, "poly": [296.0, 832.0, 1402.0, 832.0, 1402.0, 862.0, 296.0, 862.0], "score": 0.99, "text": "strategies and Qwen models of different scales. Annotators rank these responses based on their"}, {"category_id": 15, "poly": [291.0, 859.0, 1404.0, 855.0, 1404.0, 891.0, 291.0, 896.0], "score": 0.99, "text": " preferences, ensuring the best response meets established criteria, yielding both demonstration and"}, {"category_id": 15, "poly": [293.0, 892.0, 478.0, 889.0, 478.0, 921.0, 294.0, 924.0], "score": 0.94, "text": "preferencedata."}, {"category_id": 15, "poly": [298.0, 1361.0, 1404.0, 1361.0, 1404.0, 1393.0, 298.0, 1393.0], "score": 0.98, "text": "Execution Feedback  For coding tasks, LLMs are employed to generate solutions and associated"}, {"category_id": 15, "poly": [298.0, 1393.0, 1402.0, 1393.0, 1402.0, 1425.0, 298.0, 1425.0], "score": 0.99, "text": "test cases. The efficacy of these solutions is evaluated by compiling and executing them against the"}, {"category_id": 15, "poly": [293.0, 1416.0, 1407.0, 1419.0, 1407.0, 1458.0, 293.0, 1455.0], "score": 0.99, "text": " test cases, thereby creating demonstration and preference data. This methodology is also applicable"}, {"category_id": 15, "poly": [291.0, 1448.0, 1407.0, 1451.0, 1407.0, 1490.0, 291.0, 1487.0], "score": 0.96, "text": " to assessing instruction following (Dong et al., 2024). For each instruction with constraints, e.g.,"}, {"category_id": 15, "poly": [291.0, 1478.0, 1407.0, 1480.0, 1407.0, 1519.0, 291.0, 1517.0], "score": 0.99, "text": " length limit, the LLM is tasked to generate a Python verification function to ensure the response"}, {"category_id": 15, "poly": [296.0, 1515.0, 748.0, 1515.0, 748.0, 1545.0, 296.0, 1545.0], "score": 1.0, "text": "aligns with the instruction requirements."}, {"category_id": 15, "poly": [298.0, 674.0, 1404.0, 674.0, 1404.0, 706.0, 298.0, 706.0], "score": 0.98, "text": "Instruction Evolution  To enrich the instruction dataset, a self-evolution strategy (Zhao et al., 2024)"}, {"category_id": 15, "poly": [298.0, 706.0, 1402.0, 706.0, 1402.0, 738.0, 298.0, 738.0], "score": 0.99, "text": "is employed, prompting the Qwen models to add constraints or requirements to existing instructions,"}, {"category_id": 15, "poly": [293.0, 733.0, 1407.0, 733.0, 1407.0, 772.0, 293.0, 772.0], "score": 0.99, "text": " thereby increasing their complexity and ensuring a diverse range of difficulty levels within the dataset."}, {"category_id": 15, "poly": [298.0, 1054.0, 1402.0, 1054.0, 1402.0, 1084.0, 298.0, 1084.0], "score": 0.99, "text": "Maintaining the quality of annotations for responses to instructions presents significant challenges on"}, {"category_id": 15, "poly": [300.0, 1084.0, 1404.0, 1084.0, 1404.0, 1116.0, 300.0, 1116.0], "score": 1.0, "text": "a large scale, particularly those that require expertise, experience, carefulness, or patience. To address"}, {"category_id": 15, "poly": [293.0, 1111.0, 1356.0, 1114.0, 1356.0, 1146.0, 293.0, 1144.0], "score": 0.99, "text": " these challenges, we devised various automated alignment strategies to synthesize data at scale."}, {"category_id": 15, "poly": [300.0, 426.0, 1402.0, 426.0, 1402.0, 458.0, 300.0, 458.0], "score": 0.97, "text": "Automatic Ontology Extraction  The process initiates with the application of InsTag (Lu et al.,"}, {"category_id": 15, "poly": [298.0, 458.0, 1402.0, 458.0, 1402.0, 490.0, 298.0, 490.0], "score": 0.99, "text": "2024c), an open-set fine-grained tagger, to extract the underlying ontology from a large-scale"}, {"category_id": 15, "poly": [293.0, 481.0, 1388.0, 486.0, 1388.0, 525.0, 293.0, 520.0], "score": 0.98, "text": " instruction dataset. Subsequent manual refinement ensures the accuracy of the extracted ontology."}, {"category_id": 15, "poly": [300.0, 231.0, 1400.0, 231.0, 1400.0, 264.0, 300.0, 264.0], "score": 0.99, "text": "alignment strategies are employed to synthesize a substantial volume of artificially annotated data"}, {"category_id": 15, "poly": [298.0, 266.0, 1386.0, 266.0, 1386.0, 298.0, 298.0, 298.0], "score": 1.0, "text": "across the domains of code, mathematics, instruction-following, creation, role-playing, and safety."}, {"category_id": 15, "poly": [298.0, 1176.0, 1402.0, 1176.0, 1402.0, 1208.0, 298.0, 1208.0], "score": 0.98, "text": "Rejection Sampling For mathematical or similar tasks with definitive final answers, rejection"}, {"category_id": 15, "poly": [298.0, 1208.0, 1402.0, 1208.0, 1402.0, 1240.0, 298.0, 1240.0], "score": 0.99, "text": "sampling (Yuan et al., 2023) is applied to improve the quality of solutions. Large language models"}, {"category_id": 15, "poly": [298.0, 1238.0, 1404.0, 1238.0, 1404.0, 1270.0, 298.0, 1270.0], "score": 0.99, "text": "(LLMs) are tasked to generate multiple responses, namely the reasoning paths, for each instruction."}, {"category_id": 15, "poly": [296.0, 1263.0, 1404.0, 1265.0, 1404.0, 1304.0, 296.0, 1302.0], "score": 0.99, "text": "Paths that result in accurate conclusions and are considered reasonable by the model are preserved,"}, {"category_id": 15, "poly": [298.0, 1299.0, 1402.0, 1299.0, 1402.0, 1331.0, 298.0, 1331.0], "score": 1.0, "text": "serving as demonstration data. Preference data is generated by contrasting correct and incorrect paths."}, {"category_id": 15, "poly": [300.0, 360.0, 834.0, 360.0, 834.0, 392.0, 300.0, 392.0], "score": 0.98, "text": "4.1.1 COLLABORATIVE DATA ANNOTATION"}, {"category_id": 15, "poly": [296.0, 981.0, 760.0, 983.0, 760.0, 1022.0, 296.0, 1020.0], "score": 0.99, "text": "4.1.2 AUTOMATED DATA SYNTHESIS"}], "page_info": {"page_no": 6, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [294.56768798828125, 568.5234375, 1406.0755615234375, 568.5234375, 1406.0755615234375, 844.3341674804688, 294.56768798828125, 844.3341674804688], "score": 0.9999872446060181}, {"category_id": 1, "poly": [294.7462158203125, 958.5598754882812, 1407.3995361328125, 958.5598754882812, 1407.3995361328125, 1176.558837890625, 294.7462158203125, 1176.558837890625], "score": 0.9999820590019226}, {"category_id": 1, "poly": [295.61566162109375, 287.4085388183594, 1405.9425048828125, 287.4085388183594, 1405.9425048828125, 472.9677734375, 295.61566162109375, 472.9677734375], "score": 0.9999706149101257}, {"category_id": 0, "poly": [297.3915710449219, 509.9008483886719, 1022.6004638671875, 509.9008483886719, 1022.6004638671875, 544.2587280273438, 297.3915710449219, 544.2587280273438], "score": 0.9999504089355469}, {"category_id": 2, "poly": [295.75384521484375, 232.2351837158203, 686.9925537109375, 232.2351837158203, 686.9925537109375, 261.7475280761719, 295.75384521484375, 261.7475280761719], "score": 0.9999424815177917}, {"category_id": 1, "poly": [295.8984069824219, 1271.80224609375, 1405.3988037109375, 1271.80224609375, 1405.3988037109375, 1398.3265380859375, 295.8984069824219, 1398.3265380859375], "score": 0.999941349029541}, {"category_id": 1, "poly": [295.6628723144531, 1482.8983154296875, 1407.2037353515625, 1482.8983154296875, 1407.2037353515625, 2037.2408447265625, 295.6628723144531, 2037.2408447265625], "score": 0.9999388456344604}, {"category_id": 0, "poly": [297.95843505859375, 1430.9532470703125, 636.4472045898438, 1430.9532470703125, 636.4472045898438, 1463.5892333984375, 297.95843505859375, 1463.5892333984375], "score": 0.9999252557754517}, {"category_id": 0, "poly": [295.8407897949219, 1214.116455078125, 689.8175048828125, 1214.116455078125, 689.8175048828125, 1248.8856201171875, 295.8407897949219, 1248.8856201171875], "score": 0.9999251365661621}, {"category_id": 0, "poly": [298.52581787109375, 890.07666015625, 542.8966064453125, 890.07666015625, 542.8966064453125, 926.7128295898438, 298.52581787109375, 926.7128295898438], "score": 0.9999241828918457}, {"category_id": 2, "poly": [841.4461059570312, 2089.233642578125, 858.59033203125, 2089.233642578125, 858.59033203125, 2112.617919921875, 841.4461059570312, 2112.617919921875], "score": 0.9995622634887695}, {"category_id": 13, "poly": [1262, 378, 1371, 378, 1371, 409, 1262, 409], "score": 0.92, "latex": "7\\times10^{-6}"}, {"category_id": 13, "poly": [514, 629, 551, 629, 551, 663, 514, 663], "score": 0.91, "latex": "\\mathit{\\bar{y}_{i}^{+}}"}, {"category_id": 13, "poly": [297, 408, 404, 408, 404, 440, 297, 440], "score": 0.9, "latex": "7\\times10^{-7}"}, {"category_id": 13, "poly": [600, 630, 637, 630, 637, 663, 600, 663], "score": 0.9, "latex": "y_{i}^{-}"}, {"category_id": 13, "poly": [1147, 1761, 1202, 1761, 1202, 1789, 1147, 1789], "score": 0.85, "latex": "\\mathrm{C++}"}, {"category_id": 13, "poly": [1030, 601, 1055, 601, 1055, 628, 1030, 628], "score": 0.84, "latex": "\\mathcal{P}"}, {"category_id": 15, "poly": [298.0, 571.0, 1404.0, 571.0, 1404.0, 603.0, 298.0, 603.0], "score": 0.99, "text": "Our training regime for RLHF comprises two sequential stages: offline and online training. In the"}, {"category_id": 15, "poly": [293.0, 660.0, 1407.0, 660.0, 1407.0, 699.0, 293.0, 699.0], "score": 0.98, "text": " the online training stage, the model iteratively refines its performance in real-time, leveraging reward"}, {"category_id": 15, "poly": [296.0, 692.0, 1400.0, 692.0, 1400.0, 724.0, 296.0, 724.0], "score": 0.99, "text": "models for immediate feedback. Specifically, we sample multiple responses from the current policy"}, {"category_id": 15, "poly": [293.0, 722.0, 1404.0, 724.0, 1404.0, 756.0, 293.0, 754.0], "score": 0.99, "text": " model, and the reward model selects the most and the least preferred responses, forming preference"}, {"category_id": 15, "poly": [296.0, 754.0, 1404.0, 754.0, 1404.0, 786.0, 296.0, 786.0], "score": 1.0, "text": "pairs that are used for DPO in each episode. Moreover, we employ Online Merging Optimizer (Lu"}, {"category_id": 15, "poly": [291.0, 779.0, 1409.0, 784.0, 1409.0, 823.0, 291.0, 818.0], "score": 0.99, "text": " et al., 2024a) to mitigate the alignment tax, i.e., the performance degradation associated with aligning"}, {"category_id": 15, "poly": [296.0, 816.0, 774.0, 816.0, 774.0, 848.0, 296.0, 848.0], "score": 1.0, "text": "model generation with human preferences."}, {"category_id": 15, "poly": [293.0, 630.0, 513.0, 630.0, 513.0, 669.0, 293.0, 669.0], "score": 1.0, "text": "likelihood between"}, {"category_id": 15, "poly": [552.0, 630.0, 599.0, 630.0, 599.0, 669.0, 552.0, 669.0], "score": 1.0, "text": "and"}, {"category_id": 15, "poly": [638.0, 630.0, 1404.0, 630.0, 1404.0, 669.0, 638.0, 669.0], "score": 1.0, "text": "with Direct Preference Optimization (DPO, Rafailov et al., 2023). In"}, {"category_id": 15, "poly": [293.0, 596.0, 1029.0, 598.0, 1029.0, 637.0, 293.0, 635.0], "score": 0.99, "text": " offline training stage, we use a pre-compiled preference dataset"}, {"category_id": 15, "poly": [1056.0, 596.0, 1404.0, 598.0, 1404.0, 637.0, 1056.0, 635.0], "score": 0.98, "text": "to maximize the difference in"}, {"category_id": 15, "poly": [296.0, 962.0, 1402.0, 962.0, 1402.0, 995.0, 296.0, 995.0], "score": 0.99, "text": "To thoroughly assess the Qwen2 models, consisting of both base and instruction-tuned models,"}, {"category_id": 15, "poly": [296.0, 995.0, 1404.0, 995.0, 1404.0, 1027.0, 296.0, 1027.0], "score": 0.99, "text": "we implement a comprehensive evaluation protocol. This protocol examines a range of compe-"}, {"category_id": 15, "poly": [296.0, 1027.0, 1404.0, 1027.0, 1404.0, 1059.0, 296.0, 1059.0], "score": 0.99, "text": "tencies, including general knowledge understanding, language comprehension, generation, coding,"}, {"category_id": 15, "poly": [296.0, 1052.0, 1407.0, 1052.0, 1407.0, 1091.0, 296.0, 1091.0], "score": 0.98, "text": "mathematics, reasoning, and additional areas of expertise. Specifically, base models are assessed"}, {"category_id": 15, "poly": [296.0, 1086.0, 1404.0, 1086.0, 1404.0, 1118.0, 296.0, 1118.0], "score": 0.99, "text": "using established benchmark datasets for large language models (LLMs), with responses elicited"}, {"category_id": 15, "poly": [293.0, 1116.0, 1407.0, 1114.0, 1407.0, 1146.0, 293.0, 1148.0], "score": 0.99, "text": " through few-shot prompting, unless specified otherwise. For instruction-tuned models, in addition to"}, {"category_id": 15, "poly": [298.0, 1148.0, 1065.0, 1148.0, 1065.0, 1178.0, 298.0, 1178.0], "score": 0.99, "text": "benchmark evaluations, we prioritize human preference assessments."}, {"category_id": 15, "poly": [298.0, 291.0, 1402.0, 291.0, 1402.0, 323.0, 298.0, 323.0], "score": 0.98, "text": "We have assembled an extensive instruction dataset featuring more than 50o,000 examples that"}, {"category_id": 15, "poly": [293.0, 314.0, 1404.0, 319.0, 1404.0, 358.0, 293.0, 353.0], "score": 0.98, "text": " cover skills such as instruction following, coding, mathematics, logical reasoning, role-playing,"}, {"category_id": 15, "poly": [293.0, 351.0, 1402.0, 351.0, 1402.0, 383.0, 293.0, 383.0], "score": 0.99, "text": " multilingualism, and safety. Our model was fine-tuned for two epochs with a sequence length of"}, {"category_id": 15, "poly": [296.0, 445.0, 559.0, 445.0, 559.0, 474.0, 296.0, 474.0], "score": 0.95, "text": "maximum value of 1.0."}, {"category_id": 15, "poly": [293.0, 378.0, 1261.0, 376.0, 1261.0, 415.0, 293.0, 417.0], "score": 0.99, "text": " 32,768 tokens. To optimize learning, the learning rate was gradually decreased from"}, {"category_id": 15, "poly": [1372.0, 378.0, 1407.0, 376.0, 1407.0, 415.0, 1372.0, 417.0], "score": 0.98, "text": "to"}, {"category_id": 15, "poly": [405.0, 403.0, 1407.0, 408.0, 1407.0, 454.0, 405.0, 449.0], "score": 0.97, "text": ". To address overfitting, we applied a weight decay of 0.1 and gradients were clipped at a"}, {"category_id": 15, "poly": [296.0, 511.0, 1021.0, 516.0, 1021.0, 548.0, 296.0, 543.0], "score": 0.98, "text": "4.3  REINFORCEMENT LEARNING FROM HUMAN FEEDBACK"}, {"category_id": 15, "poly": [296.0, 229.0, 688.0, 229.0, 688.0, 268.0, 296.0, 268.0], "score": 0.99, "text": "4.2 SUPERVISED FINE-TUNING"}, {"category_id": 15, "poly": [298.0, 1274.0, 1402.0, 1274.0, 1402.0, 1306.0, 298.0, 1306.0], "score": 0.99, "text": "In this section, we illustrate the evaluation of the base language models of the Qwen2 series. Specifi-"}, {"category_id": 15, "poly": [296.0, 1304.0, 1400.0, 1304.0, 1400.0, 1336.0, 296.0, 1336.0], "score": 0.99, "text": "cally, we evaluate the models on benchmark datasets for knowledge and basic capabilities and apply"}, {"category_id": 15, "poly": [293.0, 1334.0, 1404.0, 1331.0, 1404.0, 1370.0, 293.0, 1373.0], "score": 0.99, "text": " multilingual benchmark datasets to evaluate their support of languages. As there are multiple model"}, {"category_id": 15, "poly": [296.0, 1366.0, 1298.0, 1368.0, 1298.0, 1400.0, 296.0, 1398.0], "score": 0.99, "text": "sizes, we compare them with the state-of-the-art (SOTA) models of similar or larger sizes."}, {"category_id": 15, "poly": [298.0, 1487.0, 1402.0, 1487.0, 1402.0, 1519.0, 298.0, 1519.0], "score": 0.99, "text": "Benchmarks and Evaluation Protocol The common practice of evaluating the core capabilities"}, {"category_id": 15, "poly": [298.0, 1517.0, 1402.0, 1517.0, 1402.0, 1549.0, 298.0, 1549.0], "score": 0.99, "text": "of base language models is the implementation of benchmark dataset evaluation with few-shot or"}, {"category_id": 15, "poly": [298.0, 1549.0, 1402.0, 1549.0, 1402.0, 1581.0, 298.0, 1581.0], "score": 0.99, "text": "zero-shot prompting. The evaluation mainly focuses on the model performance of natural language"}, {"category_id": 15, "poly": [296.0, 1577.0, 1407.0, 1577.0, 1407.0, 1616.0, 296.0, 1616.0], "score": 0.99, "text": "understanding, general question answering, coding, mathematics, scientific knowledge, reasoning, etc."}, {"category_id": 15, "poly": [293.0, 1602.0, 1404.0, 1607.0, 1404.0, 1645.0, 293.0, 1641.0], "score": 0.99, "text": "The datasets for evaluation include MMLU (Hendrycks et al., 2021a) (5-shot), MMLU-Pro (Wang"}, {"category_id": 15, "poly": [298.0, 1639.0, 1404.0, 1639.0, 1404.0, 1671.0, 298.0, 1671.0], "score": 0.99, "text": "et al., 2024) (5-shot), GPQA (Rein et al., 2023) (5shot), Theorem QA (Chen et al., 2023a) (5-shot),"}, {"category_id": 15, "poly": [298.0, 1671.0, 1402.0, 1671.0, 1402.0, 1703.0, 298.0, 1703.0], "score": 0.99, "text": "BBH (Suzgun et al., 2023) (3-shot), HellaSwag (Zellers et al., 2019) (10-shot), Winogrande (Sak-"}, {"category_id": 15, "poly": [296.0, 1700.0, 1404.0, 1698.0, 1404.0, 1730.0, 296.0, 1733.0], "score": 0.99, "text": "aguchi et al., 2021) (5-shot), TruthfulQA (Lin et al., 2022a) (0-shot), ARC-C (Clark et al., 2018)"}, {"category_id": 15, "poly": [296.0, 1728.0, 1400.0, 1728.0, 1400.0, 1760.0, 296.0, 1760.0], "score": 0.98, "text": "(25-shot), HumanEval (Chen et al., 2021) (0-shot), MBPP (Austin et al., 2021) (0-shot), EvalPlus(Liu"}, {"category_id": 15, "poly": [298.0, 1792.0, 1402.0, 1792.0, 1402.0, 1824.0, 298.0, 1824.0], "score": 0.99, "text": "Script, C#, Bash, and JavaScript), GSM8K (Cobbe et al., 2021) (5-shot), MATH (Hendrycks et al.,"}, {"category_id": 15, "poly": [296.0, 1822.0, 1402.0, 1822.0, 1402.0, 1854.0, 296.0, 1854.0], "score": 0.98, "text": "2021b) (4-shot), C-Eval (Huang et al., 2023) (5-shot), and CMMLU (Li et al., 2023) (5-shot). Multi-"}, {"category_id": 15, "poly": [298.0, 1854.0, 1404.0, 1854.0, 1404.0, 1886.0, 298.0, 1886.0], "score": 1.0, "text": "lingual datasets can be grouped into four categories: (a) Exam: M3Exam (5-shot, we only choose"}, {"category_id": 15, "poly": [298.0, 1884.0, 1402.0, 1884.0, 1402.0, 1916.0, 298.0, 1916.0], "score": 0.99, "text": "examples that require no image), IndoMMLU (Koto et al., 2023) (3-shot), ruMMLU (Fenogenova"}, {"category_id": 15, "poly": [298.0, 1914.0, 1404.0, 1914.0, 1404.0, 1946.0, 298.0, 1946.0], "score": 0.98, "text": "et al., 2024) (5-shot), and translated MMLU (Chen et al., 2023b) (5-shot on Arabic, Spanish, French,"}, {"category_id": 15, "poly": [298.0, 1946.0, 1402.0, 1946.0, 1402.0, 1978.0, 298.0, 1978.0], "score": 0.99, "text": "Portuguese, German, Italian, Japanese, and Korean); (b) Understanding: BELEBELE (Bandarkar"}, {"category_id": 15, "poly": [298.0, 1975.0, 1402.0, 1975.0, 1402.0, 2005.0, 298.0, 2005.0], "score": 0.98, "text": "et al., 2023) (5-shot), XCOPA (Ponti et al., 2020) (5-shot), XWinograd (Muennighoff et al., 2023)"}, {"category_id": 15, "poly": [296.0, 2005.0, 1404.0, 2005.0, 1404.0, 2037.0, 296.0, 2037.0], "score": 1.0, "text": "(5-shot), XStoryCloze (Lin et al., 2022b) (0-shot) and PAWS-X (Yang et al., 2019) (5-shot); (c)"}, {"category_id": 15, "poly": [296.0, 1760.0, 1146.0, 1762.0, 1146.0, 1794.0, 296.0, 1792.0], "score": 0.99, "text": "et al., 2023a) (0-shot), MultiPL-E (Cassano et al., 2023) (0-shot on Python,"}, {"category_id": 15, "poly": [1203.0, 1760.0, 1404.0, 1762.0, 1404.0, 1794.0, 1203.0, 1792.0], "score": 0.98, "text": ",Java,PHP,Type-"}, {"category_id": 15, "poly": [296.0, 1430.0, 635.0, 1430.0, 635.0, 1469.0, 296.0, 1469.0], "score": 1.0, "text": "5.1.1 CORE CAPABILITIES"}, {"category_id": 15, "poly": [298.0, 1217.0, 686.0, 1217.0, 686.0, 1249.0, 298.0, 1249.0], "score": 0.99, "text": "5.1 BASE LANGUAGE MODELS"}, {"category_id": 15, "poly": [293.0, 891.0, 538.0, 891.0, 538.0, 930.0, 293.0, 930.0], "score": 1.0, "text": "5EVALUATION"}], "page_info": {"page_no": 7, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [296.8150634765625, 1484.97021484375, 1407.7579345703125, 1484.97021484375, 1407.7579345703125, 1914.413818359375, 296.8150634765625, 1914.413818359375], "score": 0.9999836683273315}, {"category_id": 5, "poly": [297.3540954589844, 337.8158874511719, 1404.124755859375, 337.8158874511719, 1404.124755859375, 1331.3404541015625, 297.3540954589844, 1331.3404541015625], "score": 0.9998732805252075}, {"category_id": 2, "poly": [839.3309326171875, 2087.263427734375, 859.7817993164062, 2087.263427734375, 859.7817993164062, 2111.670166015625, 839.3309326171875, 2111.670166015625], "score": 0.9996851682662964}, {"category_id": 1, "poly": [298.16937255859375, 1393.856201171875, 1405.5096435546875, 1393.856201171875, 1405.5096435546875, 1455.845947265625, 298.16937255859375, 1455.845947265625], "score": 0.9993720054626465}, {"category_id": 6, "poly": [296.4033203125, 222.89154052734375, 1405.3900146484375, 222.89154052734375, 1405.3900146484375, 317.5655212402344, 296.4033203125, 317.5655212402344], "score": 0.9985324740409851}, {"category_id": 1, "poly": [296.01739501953125, 1942.02099609375, 1406.841796875, 1942.02099609375, 1406.841796875, 2035.6036376953125, 296.01739501953125, 2035.6036376953125], "score": 0.997810959815979}, {"category_id": 13, "poly": [626, 225, 694, 225, 694, 254, 626, 254], "score": 0.85, "latex": "{\\bf70B+}"}, {"category_id": 13, "poly": [392, 255, 468, 255, 468, 285, 392, 285], "score": 0.73, "latex": "8\\mathrm{x}22\\mathrm{B}"}, {"category_id": 13, "poly": [1317, 1518, 1339, 1518, 1339, 1544, 1317, 1544], "score": 0.31, "latex": "@"}, {"category_id": 13, "poly": [1118, 1852, 1194, 1852, 1194, 1881, 1118, 1881], "score": 0.29, "latex": "\\cdot8x22\\mathrm{B}"}, {"category_id": 15, "poly": [298.0, 1487.0, 1404.0, 1487.0, 1404.0, 1519.0, 298.0, 1519.0], "score": 0.99, "text": "Qwen2-72B In terms of the largest model of Qwen2, we compare Qwen2-72B with competitive"}, {"category_id": 15, "poly": [298.0, 1549.0, 1404.0, 1549.0, 1404.0, 1581.0, 298.0, 1581.0], "score": 0.99, "text": "2024), as well as Qwen1.5-72B (Qwen Team, 2024a) and Qwen1.5-110B (Qwen Team, 2024b)."}, {"category_id": 15, "poly": [296.0, 1579.0, 1402.0, 1579.0, 1402.0, 1611.0, 296.0, 1611.0], "score": 1.0, "text": "The results are reported in Table 2. Qwen2-72B outperforms Llama-3-70B in general knowledge"}, {"category_id": 15, "poly": [298.0, 1609.0, 1402.0, 1609.0, 1402.0, 1641.0, 298.0, 1641.0], "score": 0.99, "text": "understanding on both MMLU and MMLU-Pro, achieving accuracy improvements of 4.7 and 2.8,"}, {"category_id": 15, "poly": [298.0, 1641.0, 1402.0, 1641.0, 1402.0, 1673.0, 298.0, 1673.0], "score": 0.99, "text": "respectively. In scientific assessments, Qwen2-72B demonstrates superiority over Llama-3-70B with"}, {"category_id": 15, "poly": [296.0, 1671.0, 1402.0, 1671.0, 1402.0, 1703.0, 296.0, 1703.0], "score": 0.98, "text": "enhancements of 1.6 and 9.8 on GPQA and Theorem QA. Upon enrichment of coding data, Qwen2-"}, {"category_id": 15, "poly": [293.0, 1698.0, 1407.0, 1698.0, 1407.0, 1737.0, 293.0, 1737.0], "score": 0.98, "text": " 72B exhibits a significant 18.3 and 10.0 percentage point advantage over Qwen1.5-72B in HumanEval"}, {"category_id": 15, "poly": [296.0, 1732.0, 1402.0, 1732.0, 1402.0, 1765.0, 296.0, 1765.0], "score": 0.99, "text": "and MBPP evaluations. Enhanced mathematics-related data allows Qwen2-72B to outperform"}, {"category_id": 15, "poly": [296.0, 1760.0, 1407.0, 1760.0, 1407.0, 1799.0, 296.0, 1799.0], "score": 1.0, "text": "Qwen1.5-72B by 10.0 and 17.0 percentage points in the GSM8K and MATH benchmarks. Qwen2-"}, {"category_id": 15, "poly": [296.0, 1790.0, 1404.0, 1790.0, 1404.0, 1829.0, 296.0, 1829.0], "score": 0.99, "text": "72B displays reasoning capabilities equivalent to Llama-3-70B, considering BBH, Winogrande,"}, {"category_id": 15, "poly": [291.0, 1817.0, 1404.0, 1820.0, 1404.0, 1859.0, 291.0, 1856.0], "score": 0.99, "text": " and ARC-C, attributable to its improved coding and mathematical data. In assessing language"}, {"category_id": 15, "poly": [298.0, 1886.0, 704.0, 1886.0, 704.0, 1918.0, 298.0, 1918.0], "score": 1.0, "text": "and also outperforms Qwen1.5-72B."}, {"category_id": 15, "poly": [298.0, 1519.0, 1316.0, 1519.0, 1316.0, 1551.0, 298.0, 1551.0], "score": 0.99, "text": "baseline open-weight models, including Mixtral-8x22B (Jiang et al., 2024), Llama-3-70B (AI"}, {"category_id": 15, "poly": [1340.0, 1519.0, 1404.0, 1519.0, 1404.0, 1551.0, 1340.0, 1551.0], "score": 1.0, "text": "Meta,"}, {"category_id": 15, "poly": [296.0, 1854.0, 1117.0, 1854.0, 1117.0, 1886.0, 296.0, 1886.0], "score": 0.99, "text": "understanding in Chinese, Qwen2-72B significantly outperforms Mixtral-"}, {"category_id": 15, "poly": [1195.0, 1854.0, 1404.0, 1854.0, 1404.0, 1886.0, 1195.0, 1886.0], "score": 0.98, "text": "and Llama-3-70B,"}, {"category_id": 15, "poly": [296.0, 1396.0, 1400.0, 1396.0, 1400.0, 1425.0, 296.0, 1425.0], "score": 0.99, "text": "Mathematics: MGSM (Goyal et al., 2022) (8-shot CoT); and (d) Translation: Flores-101 (Goyal et al."}, {"category_id": 15, "poly": [296.0, 1425.0, 469.0, 1430.0, 468.0, 1462.0, 295.0, 1457.0], "score": 0.96, "text": "2022) (5-shot)."}, {"category_id": 15, "poly": [298.0, 289.0, 788.0, 289.0, 788.0, 319.0, 298.0, 319.0], "score": 1.0, "text": "demonstrates advantages over the baselines."}, {"category_id": 15, "poly": [293.0, 220.0, 625.0, 225.0, 625.0, 264.0, 293.0, 259.0], "score": 0.95, "text": "Table 2:Performance of the"}, {"category_id": 15, "poly": [695.0, 220.0, 1402.0, 225.0, 1402.0, 264.0, 695.0, 259.0], "score": 0.99, "text": "models. We compare Qwen2-72B with the baselines, including"}, {"category_id": 15, "poly": [298.0, 257.0, 391.0, 257.0, 391.0, 289.0, 298.0, 289.0], "score": 0.94, "text": "Mixtral-"}, {"category_id": 15, "poly": [469.0, 257.0, 1400.0, 257.0, 1400.0, 289.0, 469.0, 289.0], "score": 0.99, "text": ", Llama-3-70B, Qwen1.5-110B, and Qwen1.5-72B. For most datasets, Qwen2-72B"}, {"category_id": 15, "poly": [300.0, 1946.0, 1402.0, 1946.0, 1402.0, 1978.0, 300.0, 1978.0], "score": 0.99, "text": "Qwen2-57B-A14B For the evaluation of the MoE model, Qwen2-57B-A14B is compared against"}, {"category_id": 15, "poly": [300.0, 1975.0, 1400.0, 1975.0, 1400.0, 2005.0, 300.0, 2005.0], "score": 0.99, "text": "baselines of similar sizes. These baselines include other MoE models, such as Mixtral-8x7B (Jiang"}, {"category_id": 15, "poly": [300.0, 2005.0, 1402.0, 2005.0, 1402.0, 2037.0, 300.0, 2037.0], "score": 1.0, "text": "et al., 2024) and Jamba (Lieber et al., 2024), and dense models, such as Yi-1.5-34B (Young et al., 2024)"}], "page_info": {"page_no": 8, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [296.2042236328125, 1579.05712890625, 1407.821533203125, 1579.05712890625, 1407.821533203125, 1855.47900390625, 296.2042236328125, 1855.47900390625], "score": 0.999995231628418}, {"category_id": 5, "poly": [304.3889465332031, 427.6263122558594, 1394.1190185546875, 427.6263122558594, 1394.1190185546875, 1526.2025146484375, 304.3889465332031, 1526.2025146484375], "score": 0.9998726844787598}, {"category_id": 1, "poly": [295.22149658203125, 1879.861083984375, 1408.4073486328125, 1879.861083984375, 1408.4073486328125, 2036.3070068359375, 295.22149658203125, 2036.3070068359375], "score": 0.9998695254325867}, {"category_id": 2, "poly": [835.0218505859375, 2088.39501953125, 865.4112548828125, 2088.39501953125, 865.4112548828125, 2112.633056640625, 835.0218505859375, 2112.633056640625], "score": 0.999778151512146}, {"category_id": 6, "poly": [296.922119140625, 220.7910614013672, 1409.2158203125, 220.7910614013672, 1409.2158203125, 408.77410888671875, 296.922119140625, 408.77410888671875], "score": 0.9987851977348328}, {"category_id": 13, "poly": [628, 225, 696, 225, 696, 254, 628, 254], "score": 0.86, "latex": "\\mathbf{30B+}"}, {"category_id": 13, "poly": [913, 224, 1045, 224, 1045, 254, 913, 254], "score": 0.78, "latex": "\\bf{40B+M o E}"}, {"category_id": 13, "poly": [1214, 316, 1276, 316, 1276, 345, 1214, 345], "score": 0.48, "latex": "{\\cdot}8\\mathrm{x}7\\mathrm{B}"}, {"category_id": 15, "poly": [296.0, 1584.0, 1402.0, 1584.0, 1402.0, 1616.0, 296.0, 1616.0], "score": 0.99, "text": "and Qwen1.5-32B (Qwen Team, 2024a), both of which have approximately 30 billion parameters"}, {"category_id": 15, "poly": [296.0, 1613.0, 1404.0, 1613.0, 1404.0, 1643.0, 296.0, 1643.0], "score": 0.99, "text": "The results are shown in Table 3. We anticipate that Qwen2-57B-A14B, which activates 14 billion"}, {"category_id": 15, "poly": [296.0, 1643.0, 1404.0, 1643.0, 1404.0, 1675.0, 296.0, 1675.0], "score": 0.99, "text": "parameters, will match the performance of a 30 billion parameter dense equivalent Qwen2 model. Our"}, {"category_id": 15, "poly": [291.0, 1668.0, 1404.0, 1671.0, 1404.0, 1710.0, 291.0, 1707.0], "score": 0.99, "text": " evaluation reveals that Qwen2-57B-A14B performs comparably to Yi-1.5-34B in natural language"}, {"category_id": 15, "poly": [298.0, 1705.0, 1404.0, 1705.0, 1404.0, 1737.0, 298.0, 1737.0], "score": 0.99, "text": "understanding tasks. Moreover, it outperforms the baseline models in coding and mathematics tasks."}, {"category_id": 15, "poly": [298.0, 1735.0, 1404.0, 1735.0, 1404.0, 1767.0, 298.0, 1767.0], "score": 1.0, "text": "Additionally, Qwen2-57B-A14B demonstrates robust Chinese language understanding capabilities,"}, {"category_id": 15, "poly": [296.0, 1765.0, 1402.0, 1765.0, 1402.0, 1797.0, 296.0, 1797.0], "score": 0.98, "text": "rivaling the larger Qwen2-72B model. In essence, Qwen2-57B-A14B is an efficient model that, while"}, {"category_id": 15, "poly": [296.0, 1797.0, 1404.0, 1797.0, 1404.0, 1829.0, 296.0, 1829.0], "score": 1.0, "text": "activating only 14 billion parameters per forward pass, maintains the performance level of a 30 billion"}, {"category_id": 15, "poly": [293.0, 1827.0, 566.0, 1824.0, 566.0, 1856.0, 294.0, 1859.0], "score": 0.99, "text": "parameter densemodel."}, {"category_id": 15, "poly": [298.0, 1884.0, 1402.0, 1884.0, 1402.0, 1916.0, 298.0, 1916.0], "score": 0.97, "text": "Qwen2-7B  The 7B model is widely utilized, as it enables the execution in 16-bit foating points on"}, {"category_id": 15, "poly": [298.0, 1916.0, 1402.0, 1916.0, 1402.0, 1948.0, 298.0, 1948.0], "score": 1.0, "text": "accelerators equipped with 16GB memory. Our focus is on comparing this model with other leading"}, {"category_id": 15, "poly": [298.0, 1946.0, 1402.0, 1946.0, 1402.0, 1978.0, 298.0, 1978.0], "score": 1.0, "text": "7B models, including Llama-3-8B, which has recently demonstrated exceptional performance in the"}, {"category_id": 15, "poly": [298.0, 1975.0, 1400.0, 1975.0, 1400.0, 2008.0, 298.0, 2008.0], "score": 0.99, "text": "Chatbot Arena (Chiang et al., 2024). This comparison also includes Mistral-7B-v0.2 (Jiang et al."}, {"category_id": 15, "poly": [298.0, 2005.0, 1402.0, 2005.0, 1402.0, 2037.0, 298.0, 2037.0], "score": 0.98, "text": "2023a), Gemma-7B (Mesnard et al., 2024), and our predecessor, Qwen1.5-7B (Qwen Team, 2024a)."}, {"category_id": 15, "poly": [829.0, 2083.0, 871.0, 2083.0, 871.0, 2127.0, 829.0, 2127.0], "score": 1.0, "text": "10"}, {"category_id": 15, "poly": [298.0, 257.0, 1402.0, 257.0, 1402.0, 289.0, 298.0, 289.0], "score": 0.98, "text": "MoE model with a total of 57 billion parameters and 14 billion activated parameters, is designed"}, {"category_id": 15, "poly": [296.0, 289.0, 1404.0, 289.0, 1404.0, 319.0, 296.0, 319.0], "score": 0.99, "text": "to match the performance of 30 billion parameter dense models. This comparison includes dense"}, {"category_id": 15, "poly": [298.0, 348.0, 1402.0, 348.0, 1402.0, 380.0, 298.0, 380.0], "score": 0.99, "text": "Results demonstrate that Qwen2-57B-A14B achieves competitive performance overall, with a notable"}, {"category_id": 15, "poly": [296.0, 380.0, 795.0, 380.0, 795.0, 410.0, 296.0, 410.0], "score": 0.99, "text": "superiority in coding and mathematics tasks."}, {"category_id": 15, "poly": [298.0, 227.0, 627.0, 227.0, 627.0, 259.0, 298.0, 259.0], "score": 0.98, "text": "Table 3: Performance of the"}, {"category_id": 15, "poly": [697.0, 227.0, 912.0, 227.0, 912.0, 259.0, 697.0, 259.0], "score": 0.99, "text": "densemodels and"}, {"category_id": 15, "poly": [1046.0, 227.0, 1402.0, 227.0, 1402.0, 259.0, 1046.0, 259.0], "score": 0.97, "text": "models. Qwen2-57B-A14B, an"}, {"category_id": 15, "poly": [298.0, 316.0, 1213.0, 316.0, 1213.0, 348.0, 298.0, 348.0], "score": 0.98, "text": "model baselines: Yi-1.5-34B and Qwen1.5-32B, as well as MoE baselines: Mixtral."}, {"category_id": 15, "poly": [1277.0, 316.0, 1402.0, 316.0, 1402.0, 348.0, 1277.0, 348.0], "score": 0.99, "text": "andJamba."}], "page_info": {"page_no": 9, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [294.5309143066406, 1556.947509765625, 1408.48779296875, 1556.947509765625, 1408.48779296875, 1928.1142578125, 294.5309143066406, 1928.1142578125], "score": 0.9999918937683105}, {"category_id": 5, "poly": [334.6364440917969, 338.2691650390625, 1356.5618896484375, 338.2691650390625, 1356.5618896484375, 1329.2178955078125, 334.6364440917969, 1329.2178955078125], "score": 0.9998840689659119}, {"category_id": 2, "poly": [833.95751953125, 2087.284423828125, 864.1422729492188, 2087.284423828125, 864.1422729492188, 2113.54541015625, 833.95751953125, 2113.54541015625], "score": 0.9998821020126343}, {"category_id": 1, "poly": [294.77716064453125, 1941.7318115234375, 1406.713134765625, 1941.7318115234375, 1406.713134765625, 2036.6429443359375, 294.77716064453125, 2036.6429443359375], "score": 0.9997086524963379}, {"category_id": 1, "poly": [295.52545166015625, 1373.5709228515625, 1406.515625, 1373.5709228515625, 1406.515625, 1532.48974609375, 295.52545166015625, 1532.48974609375], "score": 0.9995028376579285}, {"category_id": 6, "poly": [295.6308288574219, 222.0921630859375, 1408.6485595703125, 222.0921630859375, 1408.6485595703125, 319.36346435546875, 295.6308288574219, 319.36346435546875], "score": 0.9989948272705078}, {"category_id": 13, "poly": [376, 256, 430, 256, 430, 284, 376, 284], "score": 0.86, "latex": "^{7\\mathrm{B}+}"}, {"category_id": 13, "poly": [621, 225, 674, 225, 674, 254, 621, 254], "score": 0.84, "latex": "{\\bf7B+}"}, {"category_id": 15, "poly": [298.0, 1561.0, 1402.0, 1561.0, 1402.0, 1593.0, 298.0, 1593.0], "score": 0.99, "text": "Qwen2-1.5B & Qwen2-0.5B  To evaluate the performance of our smaller models, specifically"}, {"category_id": 15, "poly": [298.0, 1593.0, 1402.0, 1593.0, 1402.0, 1625.0, 298.0, 1625.0], "score": 0.98, "text": "Qwen2-1.5B and Qwen2-0.5B, we compare them against established baselines: Phi-2 (Abdin et al.,"}, {"category_id": 15, "poly": [298.0, 1622.0, 1402.0, 1622.0, 1402.0, 1655.0, 298.0, 1655.0], "score": 0.97, "text": "2024), Gemma-2B (Mesnard et al., 2024), and Qwen1.5-1.8B (Qwen Team, 2024a). The results"}, {"category_id": 15, "poly": [293.0, 1650.0, 1407.0, 1650.0, 1407.0, 1689.0, 293.0, 1689.0], "score": 0.98, "text": " are given in Table 5. In language understanding, Qwen2-1.5B outperforms Phi-2, a model trained"}, {"category_id": 15, "poly": [298.0, 1684.0, 1402.0, 1684.0, 1402.0, 1716.0, 298.0, 1716.0], "score": 0.99, "text": "on textbook-like data. For coding tasks, Qwen2-0.5B matches the performance of Gemma-2B and"}, {"category_id": 15, "poly": [296.0, 1712.0, 1400.0, 1712.0, 1400.0, 1744.0, 296.0, 1744.0], "score": 0.99, "text": "Qwen1.5-1.8B, while Qwen2-1.5B surpasses these baselines, except for Phi-2. Both Qwen2 models"}, {"category_id": 15, "poly": [298.0, 1746.0, 1404.0, 1746.0, 1404.0, 1778.0, 298.0, 1778.0], "score": 1.0, "text": "exhibit superior performance in mathematics compared to their competitors. In terms of general"}, {"category_id": 15, "poly": [298.0, 1776.0, 1404.0, 1776.0, 1404.0, 1808.0, 298.0, 1808.0], "score": 0.99, "text": "reasoning, we find that Phi-2 generally outperforms all others, which to some extent reflects the"}, {"category_id": 15, "poly": [298.0, 1806.0, 1402.0, 1806.0, 1402.0, 1838.0, 298.0, 1838.0], "score": 1.0, "text": "significance of textbook data for reasoning capabilities. In TruthfulQA, Qwen2-1.5B performs the"}, {"category_id": 15, "poly": [296.0, 1836.0, 1402.0, 1836.0, 1402.0, 1868.0, 296.0, 1868.0], "score": 0.99, "text": "best, demonstrating that smaller models does not necessarily suffer from hallucination. In Chinese"}, {"category_id": 15, "poly": [296.0, 1868.0, 1402.0, 1868.0, 1402.0, 1900.0, 296.0, 1900.0], "score": 1.0, "text": "language understanding, both Qwen2 models outperform all the others, a trend consistent with larger"}, {"category_id": 15, "poly": [293.0, 1895.0, 739.0, 1898.0, 739.0, 1930.0, 293.0, 1927.0], "score": 0.99, "text": "models in their respective comparisons."}, {"category_id": 15, "poly": [829.0, 2083.0, 866.0, 2083.0, 866.0, 2129.0, 829.0, 2129.0], "score": 1.0, "text": "11"}, {"category_id": 15, "poly": [298.0, 1946.0, 1402.0, 1946.0, 1402.0, 1978.0, 298.0, 1978.0], "score": 1.0, "text": "In general, the Qwen2 series demonstrates superior performance against the baselines across different"}, {"category_id": 15, "poly": [298.0, 1975.0, 1402.0, 1975.0, 1402.0, 2008.0, 298.0, 2008.0], "score": 0.99, "text": "model sizes. Notably, Qwen2-72B exhibits the highest performance among all Qwen2 models,"}, {"category_id": 15, "poly": [293.0, 2001.0, 829.0, 2003.0, 829.0, 2042.0, 293.0, 2040.0], "score": 0.98, "text": "underscoring the eficacy of model size scaling."}, {"category_id": 15, "poly": [298.0, 1380.0, 1404.0, 1380.0, 1404.0, 1409.0, 298.0, 1409.0], "score": 0.98, "text": "The results can be found in Table 4. Qwen2-7B demonstrates superior performance across most"}, {"category_id": 15, "poly": [298.0, 1409.0, 1402.0, 1409.0, 1402.0, 1441.0, 298.0, 1441.0], "score": 0.99, "text": "datasets compared to other models, particularly excelling in coding tasks, mathematics, and Chinese"}, {"category_id": 15, "poly": [296.0, 1437.0, 1404.0, 1437.0, 1404.0, 1476.0, 296.0, 1476.0], "score": 0.99, "text": "language tasks. It also shows strong performance in multilingual understanding and exams. This"}, {"category_id": 15, "poly": [293.0, 1469.0, 1404.0, 1469.0, 1404.0, 1508.0, 293.0, 1508.0], "score": 0.99, "text": " indicates that Qwen2-7B has been optimized for a wide range of language and logic-based tasks,"}, {"category_id": 15, "poly": [298.0, 1501.0, 873.0, 1501.0, 873.0, 1533.0, 298.0, 1533.0], "score": 0.99, "text": "showcasing its versatility and advanced capabilities."}, {"category_id": 15, "poly": [300.0, 289.0, 1400.0, 289.0, 1400.0, 321.0, 300.0, 321.0], "score": 0.99, "text": "Qwen2-7B demonstrates significant advantages over the baselines in most of the evaluation datasets."}, {"category_id": 15, "poly": [300.0, 257.0, 375.0, 257.0, 375.0, 289.0, 300.0, 289.0], "score": 0.94, "text": "the-art"}, {"category_id": 15, "poly": [431.0, 257.0, 1402.0, 257.0, 1402.0, 289.0, 431.0, 289.0], "score": 0.99, "text": "models including Mixtral-7B, Gemma-7B, Llama-3-8B, and our previous Qwen1.5-7B."}, {"category_id": 15, "poly": [298.0, 227.0, 620.0, 227.0, 620.0, 259.0, 298.0, 259.0], "score": 0.96, "text": "Table 4: Performance of the"}, {"category_id": 15, "poly": [675.0, 227.0, 1402.0, 227.0, 1402.0, 259.0, 675.0, 259.0], "score": 1.0, "text": "models. We compare Qwen2-7B with previously released state-of-"}], "page_info": {"page_no": 10, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [296.208251953125, 1373.89697265625, 1407.796630859375, 1373.89697265625, 1407.796630859375, 1682.5416259765625, 296.208251953125, 1682.5416259765625], "score": 0.9999912977218628}, {"category_id": 1, "poly": [296.6755676269531, 1708.080322265625, 1407.5369873046875, 1708.080322265625, 1407.5369873046875, 1957.5703125, 296.6755676269531, 1957.5703125], "score": 0.9999892711639404}, {"category_id": 1, "poly": [297.54583740234375, 1115.4803466796875, 1406.824462890625, 1115.4803466796875, 1406.824462890625, 1271.5062255859375, 297.54583740234375, 1271.5062255859375], "score": 0.9999815821647644}, {"category_id": 5, "poly": [321.08203125, 369.2574768066406, 1373.80615234375, 369.2574768066406, 1373.80615234375, 953.2183837890625, 321.08203125, 953.2183837890625], "score": 0.9999772906303406}, {"category_id": 0, "poly": [295.6910705566406, 1050.018798828125, 721.0256958007812, 1050.018798828125, 721.0256958007812, 1085.3682861328125, 295.6910705566406, 1085.3682861328125], "score": 0.999973475933075}, {"category_id": 0, "poly": [296.7283630371094, 1316.690673828125, 785.9839477539062, 1316.690673828125, 785.9839477539062, 1349.8526611328125, 296.7283630371094, 1349.8526611328125], "score": 0.999875009059906}, {"category_id": 2, "poly": [331.7485046386719, 2005.7545166015625, 974.422607421875, 2005.7545166015625, 974.422607421875, 2034.0301513671875, 331.7485046386719, 2034.0301513671875], "score": 0.9996529817581177}, {"category_id": 6, "poly": [295.1954345703125, 221.34873962402344, 1406.8016357421875, 221.34873962402344, 1406.8016357421875, 348.54559326171875, 295.1954345703125, 348.54559326171875], "score": 0.998734176158905}, {"category_id": 2, "poly": [836.5357666015625, 2088.085693359375, 864.5902099609375, 2088.085693359375, 864.5902099609375, 2113.00537109375, 836.5357666015625, 2113.00537109375], "score": 0.9828782081604004}, {"category_id": 13, "poly": [475, 1742, 549, 1742, 549, 1771, 475, 1771], "score": 0.57, "latex": "\\cdot8x22\\mathrm{B}"}, {"category_id": 13, "poly": [839, 1650, 918, 1650, 918, 1682, 839, 1682], "score": 0.37, "latex": "2023)^{4}"}, {"category_id": 15, "poly": [296.0, 1380.0, 1404.0, 1380.0, 1404.0, 1412.0, 296.0, 1412.0], "score": 0.99, "text": "To comprehensively evaluate the quality of instruction-tuned models, we compile automatic and"}, {"category_id": 15, "poly": [296.0, 1409.0, 1402.0, 1409.0, 1402.0, 1441.0, 296.0, 1441.0], "score": 0.99, "text": "human evaluation to assess the capabilities and human preference. For the evaluation of basic"}, {"category_id": 15, "poly": [291.0, 1437.0, 1404.0, 1435.0, 1404.0, 1474.0, 291.0, 1476.0], "score": 1.0, "text": " capabilities, we apply similar datasets in the pre-trained model evaluation, which target on natural"}, {"category_id": 15, "poly": [298.0, 1471.0, 1404.0, 1471.0, 1404.0, 1503.0, 298.0, 1503.0], "score": 1.0, "text": "language understanding, coding, mathematics, and reasoning. Specifically, we evaluate on MMLU,"}, {"category_id": 15, "poly": [296.0, 1499.0, 1402.0, 1499.0, 1402.0, 1531.0, 296.0, 1531.0], "score": 0.99, "text": "MMLU-Pro, GPQA, and Theorem QA for language understanding and knowledge, HumanEval,"}, {"category_id": 15, "poly": [298.0, 1531.0, 1404.0, 1531.0, 1404.0, 1563.0, 298.0, 1563.0], "score": 0.99, "text": "MBPP, MultiPL-E, and LiveCodeBench v1 (Jain et al., 2024) for coding, GSM8K and MATH for"}, {"category_id": 15, "poly": [296.0, 1563.0, 1402.0, 1563.0, 1402.0, 1593.0, 296.0, 1593.0], "score": 0.99, "text": "mathematics. Additionally, we assess the performance of human preference alignment and instruction"}, {"category_id": 15, "poly": [291.0, 1588.0, 1407.0, 1586.0, 1407.0, 1625.0, 291.0, 1627.0], "score": 0.99, "text": " following by evaluating on benchmarks including MT-Bench (Zheng et al., 2023), Arena-Hard (Li"}, {"category_id": 15, "poly": [296.0, 1622.0, 1407.0, 1622.0, 1407.0, 1655.0, 296.0, 1655.0], "score": 0.98, "text": "et al., 2024), AlignBench (Liu et al., 2023b), MixEval (Ni et al., 2024) whose results approximate "}, {"category_id": 15, "poly": [291.0, 1648.0, 838.0, 1650.0, 838.0, 1689.0, 291.0, 1687.0], "score": 0.99, "text": " those of Chatbot Arena, and IFEval (Zhou et al.,"}, {"category_id": 15, "poly": [919.0, 1648.0, 1206.0, 1650.0, 1206.0, 1689.0, 919.0, 1687.0], "score": 0.96, "text": "for instruction following."}, {"category_id": 15, "poly": [298.0, 1712.0, 559.0, 1709.0, 559.0, 1742.0, 298.0, 1744.0], "score": 1.0, "text": "Qwen2-72B-Instruct"}, {"category_id": 15, "poly": [545.0, 1712.0, 1404.0, 1712.0, 1404.0, 1744.0, 545.0, 1744.0], "score": 0.99, "text": "We compare Qwen2-72B-Instruct against the instruction-tuned models in-"}, {"category_id": 15, "poly": [298.0, 1774.0, 1404.0, 1774.0, 1404.0, 1806.0, 298.0, 1806.0], "score": 1.0, "text": "presented in Table 6. It can be found that a strong base language model can help boost the downstream"}, {"category_id": 15, "poly": [293.0, 1806.0, 1400.0, 1806.0, 1400.0, 1838.0, 293.0, 1838.0], "score": 0.99, "text": " performance of the instruction-tuned model. Specifically, Qwen2-72B-Instruct outshines its peers in"}, {"category_id": 15, "poly": [293.0, 1831.0, 1404.0, 1829.0, 1404.0, 1868.0, 293.0, 1870.0], "score": 0.99, "text": " areas such as language understanding, coding, and mathematics, with the exception of GPQA and"}, {"category_id": 15, "poly": [298.0, 1865.0, 1404.0, 1865.0, 1404.0, 1898.0, 298.0, 1898.0], "score": 0.99, "text": "MBPP. Regarding human preference alignment and instruction following, Qwen2-72B has significant"}, {"category_id": 15, "poly": [291.0, 1891.0, 1404.0, 1893.0, 1404.0, 1932.0, 291.0, 1930.0], "score": 0.98, "text": " advantages over the baselines. We assume this achievement is attributed to both the high-quality"}, {"category_id": 15, "poly": [296.0, 1927.0, 1307.0, 1927.0, 1307.0, 1959.0, 296.0, 1959.0], "score": 1.0, "text": "pre-trained model and improvements in both data and training techniques for post-training."}, {"category_id": 15, "poly": [298.0, 1744.0, 474.0, 1744.0, 474.0, 1776.0, 298.0, 1776.0], "score": 0.99, "text": "cludingMixtral-"}, {"category_id": 15, "poly": [550.0, 1744.0, 1404.0, 1744.0, 1404.0, 1776.0, 550.0, 1776.0], "score": 0.99, "text": "-Instruct, Llama-3-70B-Instruct, as well as Qwen1.5-72B-Chat. The results are"}, {"category_id": 15, "poly": [296.0, 1116.0, 1402.0, 1118.0, 1402.0, 1150.0, 296.0, 1148.0], "score": 0.98, "text": "To critically evaluate instruction-tuned models, we implement a multifaceted approach. Assessments"}, {"category_id": 15, "poly": [298.0, 1148.0, 1404.0, 1148.0, 1404.0, 1180.0, 298.0, 1180.0], "score": 0.99, "text": "of foundational skills and human preferences are conducted using open datasets and benchmarks. Our"}, {"category_id": 15, "poly": [296.0, 1180.0, 1402.0, 1180.0, 1402.0, 1212.0, 296.0, 1212.0], "score": 0.99, "text": "detailed in-house examinations further probe model competencies in key areas. A particular focus is"}, {"category_id": 15, "poly": [296.0, 1208.0, 1400.0, 1208.0, 1400.0, 1240.0, 296.0, 1240.0], "score": 0.99, "text": "placed on assessing long context capability. Safety measures include multilingual safety assessments"}, {"category_id": 15, "poly": [291.0, 1238.0, 1407.0, 1235.0, 1407.0, 1274.0, 291.0, 1276.0], "score": 0.99, "text": " and red teaming exercises. The following sections detail the evaluation methods and their outcomes."}, {"category_id": 15, "poly": [296.0, 1054.0, 718.0, 1054.0, 718.0, 1086.0, 296.0, 1086.0], "score": 0.98, "text": "5.2 INSTRUCTION-TUNED MODEL"}, {"category_id": 15, "poly": [298.0, 1320.0, 785.0, 1320.0, 785.0, 1352.0, 298.0, 1352.0], "score": 0.99, "text": "5.2.1 OPEN BENCHMARK EVALUATION"}, {"category_id": 15, "poly": [331.0, 1998.0, 973.0, 2005.0, 972.0, 2047.0, 330.0, 2039.0], "score": 0.95, "text": "4For simplicity, we report the results of the subset strict-prom."}, {"category_id": 15, "poly": [298.0, 227.0, 1402.0, 227.0, 1402.0, 259.0, 298.0, 259.0], "score": 0.99, "text": "Table 5: Performance of the smaller models. We compare our Qwen2-0.5B and Qwen2-1.5B"}, {"category_id": 15, "poly": [298.0, 257.0, 1402.0, 257.0, 1402.0, 289.0, 298.0, 289.0], "score": 1.0, "text": "with the previous SOTA small models including Phi-2, Gemma-2B and Qwen1.5-1.8B. Qwen2-0.5B"}, {"category_id": 15, "poly": [298.0, 289.0, 1402.0, 289.0, 1402.0, 321.0, 298.0, 321.0], "score": 1.0, "text": "with a much smaller model size achieves competitive performance, and Qwen2-1.5B significantly"}, {"category_id": 15, "poly": [298.0, 319.0, 591.0, 319.0, 591.0, 351.0, 298.0, 351.0], "score": 0.98, "text": "outperforms Qwen2-0.5B."}, {"category_id": 15, "poly": [822.0, 2089.0, 863.0, 2075.0, 878.0, 2121.0, 837.0, 2135.0], "score": 1.0, "text": "12"}], "page_info": {"page_no": 11, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [296.3668212890625, 1449.340087890625, 1407.443115234375, 1449.340087890625, 1407.443115234375, 1758.4691162109375, 296.3668212890625, 1758.4691162109375], "score": 0.9999939799308777}, {"category_id": 1, "poly": [295.710205078125, 1787.0987548828125, 1408.0477294921875, 1787.0987548828125, 1408.0477294921875, 2037.0645751953125, 295.710205078125, 2037.0645751953125], "score": 0.9999780654907227}, {"category_id": 5, "poly": [293.0823669433594, 368.9128723144531, 1406.140869140625, 368.9128723144531, 1406.140869140625, 1116.5777587890625, 293.0823669433594, 1116.5777587890625], "score": 0.9999537467956543}, {"category_id": 1, "poly": [296.36773681640625, 1202.27880859375, 1408.1881103515625, 1202.27880859375, 1408.1881103515625, 1422.2896728515625, 296.36773681640625, 1422.2896728515625], "score": 0.9999223947525024}, {"category_id": 6, "poly": [296.31402587890625, 222.02392578125, 1408.22607421875, 222.02392578125, 1408.22607421875, 349.19903564453125, 296.31402587890625, 349.19903564453125], "score": 0.999919593334198}, {"category_id": 2, "poly": [835.5646362304688, 2088.378173828125, 863.9412231445312, 2088.378173828125, 863.9412231445312, 2114.027587890625, 835.5646362304688, 2114.027587890625], "score": 0.9998384714126587}, {"category_id": 13, "poly": [584, 225, 652, 225, 652, 254, 584, 254], "score": 0.85, "latex": "{\\bf70B+}"}, {"category_id": 13, "poly": [392, 255, 470, 255, 470, 284, 392, 284], "score": 0.79, "latex": "\\cdot8x22\\mathrm{B}"}, {"category_id": 15, "poly": [298.0, 1453.0, 1404.0, 1453.0, 1404.0, 1485.0, 298.0, 1485.0], "score": 0.98, "text": "Qwen2-7B-Instruct Within the spectrum of 7B to 9B models, we compare Qwen2-7B-Instruct"}, {"category_id": 15, "poly": [296.0, 1480.0, 1402.0, 1483.0, 1402.0, 1515.0, 296.0, 1512.0], "score": 1.0, "text": "with Llama-3-8B-Instruct, Yi-1.5-9B-Chat, GLM-4-9B-Chat, and Qwen1.5-7B-Chat. The results"}, {"category_id": 15, "poly": [296.0, 1515.0, 1404.0, 1515.0, 1404.0, 1547.0, 296.0, 1547.0], "score": 1.0, "text": "can be found in Table 8. Qwen2-7B-Instruct demonstrates substantial advancements compared"}, {"category_id": 15, "poly": [296.0, 1545.0, 1404.0, 1545.0, 1404.0, 1577.0, 296.0, 1577.0], "score": 1.0, "text": "to its predecessor, Qwen1.5-7B-Chat, across comprehensive evaluations, notably achieving higher"}, {"category_id": 15, "poly": [298.0, 1577.0, 1404.0, 1577.0, 1404.0, 1606.0, 298.0, 1606.0], "score": 0.99, "text": "scores in coding and mathematics-related tasks. Compared with the recent SOTA model, Llama-3-"}, {"category_id": 15, "poly": [298.0, 1606.0, 1402.0, 1606.0, 1402.0, 1639.0, 298.0, 1639.0], "score": 1.0, "text": "8B-Instruct, Qwen2-7B-Instruct demonstrates competitive performance and specifically it achieves"}, {"category_id": 15, "poly": [291.0, 1634.0, 1407.0, 1632.0, 1407.0, 1671.0, 291.0, 1673.0], "score": 0.98, "text": " superior performance in coding. Nonetheless, in terms of instruction following, Qwen2-7B-Instruct"}, {"category_id": 15, "poly": [293.0, 1664.0, 1404.0, 1664.0, 1404.0, 1703.0, 293.0, 1703.0], "score": 0.98, "text": " greatly falls behind the competitor. To address this limitation, we plan to augment the 7B model's"}, {"category_id": 15, "poly": [296.0, 1698.0, 1407.0, 1698.0, 1407.0, 1730.0, 296.0, 1730.0], "score": 1.0, "text": "instruction-following ability by enhancing the quality of post-training data, ensuring a more robust"}, {"category_id": 15, "poly": [296.0, 1730.0, 882.0, 1730.0, 882.0, 1760.0, 296.0, 1760.0], "score": 0.98, "text": "understanding and execution of complex commands."}, {"category_id": 15, "poly": [296.0, 1785.0, 1404.0, 1788.0, 1404.0, 1826.0, 296.0, 1824.0], "score": 0.98, "text": "Qwen2-1.5B-Instruct & Qwen2-0.5B-Instruct  In the context of smaller models, we compare"}, {"category_id": 15, "poly": [300.0, 1822.0, 1404.0, 1822.0, 1404.0, 1854.0, 300.0, 1854.0], "score": 0.99, "text": "Qwen2-0.5B-Instruct with Qwen1.5-0.5B-Chat, and Qwen2-1.5B-Instruct with Qwen1.5-1.8B-Chat."}, {"category_id": 15, "poly": [293.0, 1847.0, 1407.0, 1849.0, 1407.0, 1888.0, 293.0, 1886.0], "score": 0.97, "text": " Notably, the complexity of certain datasets designed for larger models exceeds the capabilities of"}, {"category_id": 15, "poly": [298.0, 1884.0, 1402.0, 1884.0, 1402.0, 1916.0, 298.0, 1916.0], "score": 0.99, "text": "these smaller models; thus, our analysis focuses on a selected subset. As detailed in Table 9, the"}, {"category_id": 15, "poly": [298.0, 1914.0, 1402.0, 1914.0, 1402.0, 1946.0, 298.0, 1946.0], "score": 0.99, "text": "Qwen2 models demonstrate a marked advantage over their predecessors in both core capabilities and"}, {"category_id": 15, "poly": [298.0, 1946.0, 1402.0, 1946.0, 1402.0, 1978.0, 298.0, 1978.0], "score": 0.99, "text": "instruction-following tasks. The achievement mainly attributes to the scaling of pre-training data."}, {"category_id": 15, "poly": [298.0, 1975.0, 1402.0, 1975.0, 1402.0, 2008.0, 298.0, 2008.0], "score": 0.99, "text": "Consequently, our results affirm that data scaling remains an effective strategy for enhancing model"}, {"category_id": 15, "poly": [296.0, 2005.0, 1030.0, 2005.0, 1030.0, 2037.0, 296.0, 2037.0], "score": 0.99, "text": "performance, even in the domain of sub-billion parameter models."}, {"category_id": 15, "poly": [296.0, 1201.0, 1404.0, 1203.0, 1404.0, 1242.0, 296.0, 1240.0], "score": 1.0, "text": "Qwen2-57B-A14B-Instruct For medium-size models, we compare Qwen2-57B-A14B-Instruct"}, {"category_id": 15, "poly": [298.0, 1237.0, 1402.0, 1237.0, 1402.0, 1270.0, 298.0, 1270.0], "score": 1.0, "text": "with Mixtral-8x7B-Instruct, another MoE baseline, as well as the dense SOTA models with over 30"}, {"category_id": 15, "poly": [298.0, 1267.0, 1407.0, 1267.0, 1407.0, 1299.0, 298.0, 1299.0], "score": 0.99, "text": "billion parameters, e.g., Yi-1.5-34B-Chat and Qwen1.5-32B-Chat. The results are provided in Table 7."}, {"category_id": 15, "poly": [293.0, 1295.0, 1402.0, 1295.0, 1402.0, 1327.0, 293.0, 1327.0], "score": 1.0, "text": "Compared with Qwen1.5-32B-Chat, Qwen2-57B-A14B-Instruct reaches superior performance in"}, {"category_id": 15, "poly": [298.0, 1329.0, 1402.0, 1329.0, 1402.0, 1361.0, 298.0, 1361.0], "score": 0.99, "text": "almost all benchmarks, and compared with the 30B SOTA model Yi-1.5-34B-Chat, Qwen2-57B-"}, {"category_id": 15, "poly": [296.0, 1357.0, 1404.0, 1359.0, 1404.0, 1391.0, 296.0, 1389.0], "score": 1.0, "text": "A14B-Instruct has gained advantages in most evaluations except for those for mathematics. In terms"}, {"category_id": 15, "poly": [298.0, 1391.0, 1388.0, 1391.0, 1388.0, 1423.0, 298.0, 1423.0], "score": 0.99, "text": "of the evaluation for alignment, the advantages of Qwen2-57B-A14B-Instruct are notably evident."}, {"category_id": 15, "poly": [296.0, 286.0, 1404.0, 289.0, 1404.0, 321.0, 296.0, 319.0], "score": 0.98, "text": "Instruct or -Chat\" is omitted in the table. Qwen2-72B-Instruct demonstrates advantages in core"}, {"category_id": 15, "poly": [296.0, 316.0, 1081.0, 316.0, 1081.0, 348.0, 296.0, 348.0], "score": 1.0, "text": "capabilities, and superior performance in human preference alignment."}, {"category_id": 15, "poly": [298.0, 227.0, 583.0, 227.0, 583.0, 259.0, 298.0, 259.0], "score": 0.95, "text": "Table 6: Performance of"}, {"category_id": 15, "poly": [653.0, 227.0, 1402.0, 227.0, 1402.0, 259.0, 653.0, 259.0], "score": 1.0, "text": "instruction-tuned models. We compare Qwen2-72B-Instruct with"}, {"category_id": 15, "poly": [298.0, 257.0, 391.0, 257.0, 391.0, 289.0, 298.0, 289.0], "score": 0.99, "text": "Mixtral-"}, {"category_id": 15, "poly": [471.0, 257.0, 1402.0, 257.0, 1402.0, 289.0, 471.0, 289.0], "score": 1.0, "text": "-Instruct, Llama-3-70B-Instruct, Qwen1.5-72B-Chat, and Qwen1.5-110B-Chat. "}, {"category_id": 15, "poly": [823.0, 2087.0, 864.0, 2079.0, 873.0, 2123.0, 832.0, 2131.0], "score": 1.0, "text": "13"}], "page_info": {"page_no": 12, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [295.85858154296875, 1570.0738525390625, 1408.4705810546875, 1570.0738525390625, 1408.4705810546875, 1848.2337646484375, 295.85858154296875, 1848.2337646484375], "score": 0.9999910593032837}, {"category_id": 1, "poly": [296.2867126464844, 1384.109130859375, 1406.242919921875, 1384.109130859375, 1406.242919921875, 1539.5972900390625, 296.2867126464844, 1539.5972900390625], "score": 0.9999874830245972}, {"category_id": 6, "poly": [297.1496887207031, 220.61900329589844, 1407.9119873046875, 220.61900329589844, 1407.9119873046875, 378.3599853515625, 297.1496887207031, 378.3599853515625], "score": 0.9999262094497681}, {"category_id": 5, "poly": [331.76568603515625, 402.0240783691406, 1368.7877197265625, 402.0240783691406, 1368.7877197265625, 1221.23828125, 331.76568603515625, 1221.23828125], "score": 0.9999260902404785}, {"category_id": 2, "poly": [834.484619140625, 2087.95458984375, 865.2107543945312, 2087.95458984375, 865.2107543945312, 2112.537841796875, 834.484619140625, 2112.537841796875], "score": 0.999779224395752}, {"category_id": 1, "poly": [295.8758239746094, 1879.6329345703125, 1408.077880859375, 1879.6329345703125, 1408.077880859375, 2036.9478759765625, 295.8758239746094, 2036.9478759765625], "score": 0.9994637370109558}, {"category_id": 0, "poly": [296.666259765625, 1311.3909912109375, 826.30908203125, 1311.3909912109375, 826.30908203125, 1346.565673828125, 296.666259765625, 1346.565673828125], "score": 0.9965410232543945}, {"category_id": 13, "poly": [594, 225, 663, 225, 663, 254, 594, 254], "score": 0.86, "latex": "^{\\mathbf{30B+}}"}, {"category_id": 13, "poly": [794, 224, 863, 224, 863, 254, 794, 254], "score": 0.59, "latex": "{\\bf40B+}"}, {"category_id": 15, "poly": [298.0, 1574.0, 1402.0, 1574.0, 1402.0, 1606.0, 298.0, 1606.0], "score": 0.99, "text": "Chinese Evaluation For the evaluations in Chinese, we focus on comparing the performance of"}, {"category_id": 15, "poly": [298.0, 1604.0, 1402.0, 1604.0, 1402.0, 1636.0, 298.0, 1636.0], "score": 1.0, "text": "Qwen2 models with the Qwen1.5 counterparts. For the small models, Qwen2-1.5B-Instruct generally"}, {"category_id": 15, "poly": [296.0, 1634.0, 1402.0, 1634.0, 1402.0, 1666.0, 296.0, 1666.0], "score": 0.99, "text": "outperforms Qwen1.5-1.8B-Chat in almost all the evaluations even with fewer parameters. In terms of"}, {"category_id": 15, "poly": [296.0, 1666.0, 1404.0, 1666.0, 1404.0, 1698.0, 296.0, 1698.0], "score": 0.99, "text": "the comparison of 7B models, the advantages of Qwen2 are more significant. Noteworthy is Qwen2-"}, {"category_id": 15, "poly": [300.0, 1696.0, 1404.0, 1696.0, 1404.0, 1728.0, 300.0, 1728.0], "score": 0.99, "text": "72B's superior performance to Qwen1.5-110B-Chat, despite the latter's greatly more parameters."}, {"category_id": 15, "poly": [293.0, 1723.0, 1407.0, 1721.0, 1407.0, 1760.0, 293.0, 1762.0], "score": 0.98, "text": "The MoE model displays superior performance across most domains relative to Qwen1.5-32B-Chat,"}, {"category_id": 15, "poly": [298.0, 1758.0, 1402.0, 1758.0, 1402.0, 1790.0, 298.0, 1790.0], "score": 0.99, "text": "excluding knowledge understanding. This discrepancy may be attributed to a short of pre-training"}, {"category_id": 15, "poly": [296.0, 1788.0, 1404.0, 1788.0, 1404.0, 1820.0, 296.0, 1820.0], "score": 0.99, "text": "tokens. In the near future, we are about to continue the pre-training of the MoE model to discover its "}, {"category_id": 15, "poly": [296.0, 1820.0, 501.0, 1820.0, 501.0, 1849.0, 296.0, 1849.0], "score": 1.0, "text": "scalingbehaviors."}, {"category_id": 15, "poly": [298.0, 1386.0, 1402.0, 1386.0, 1402.0, 1419.0, 298.0, 1419.0], "score": 0.99, "text": "Despite a number of open benchmark datasets for the evaluation, we believe that it is far from"}, {"category_id": 15, "poly": [296.0, 1419.0, 1404.0, 1419.0, 1404.0, 1451.0, 296.0, 1451.0], "score": 0.99, "text": "sufficient to fully comprehend the capabilities of LLMs. Specifically, we have made a series of"}, {"category_id": 15, "poly": [293.0, 1444.0, 1404.0, 1446.0, 1404.0, 1485.0, 293.0, 1483.0], "score": 0.99, "text": " in-house datasets that assess different capabilities of the models, e.g., knowledge understanding,"}, {"category_id": 15, "poly": [296.0, 1478.0, 1404.0, 1478.0, 1404.0, 1510.0, 296.0, 1510.0], "score": 1.0, "text": "text generation, coding, etc. The evaluation is in Chinese and English. The results are gathered in"}, {"category_id": 15, "poly": [294.0, 1501.0, 695.0, 1508.0, 695.0, 1547.0, 293.0, 1540.0], "score": 0.97, "text": "Table 10 and Table 11, respectively."}, {"category_id": 15, "poly": [300.0, 257.0, 1404.0, 257.0, 1404.0, 289.0, 300.0, 289.0], "score": 0.99, "text": "Qwen2-57B-A14B-Instruct with the similar-size MoE model Mixtral-8x7B-Instruct, 30B dense"}, {"category_id": 15, "poly": [298.0, 289.0, 1402.0, 289.0, 1402.0, 319.0, 298.0, 319.0], "score": 0.97, "text": "models such as Yi-1.5-34B-Chat and Qwen1.5-32B-Chat. -Instruct\" or -Chat\" is omitted in the"}, {"category_id": 15, "poly": [298.0, 319.0, 1402.0, 319.0, 1402.0, 351.0, 298.0, 351.0], "score": 0.98, "text": "table. Qwen2-57B-A14B-Instruct is competitive with the recent SOTA 30B dense models, and"}, {"category_id": 15, "poly": [298.0, 348.0, 797.0, 348.0, 797.0, 380.0, 298.0, 380.0], "score": 1.0, "text": "significantly outcompetes the MoE baseline."}, {"category_id": 15, "poly": [296.0, 225.0, 593.0, 227.0, 593.0, 259.0, 296.0, 257.0], "score": 0.96, "text": "Table 7: Performance of"}, {"category_id": 15, "poly": [664.0, 225.0, 793.0, 227.0, 793.0, 259.0, 664.0, 257.0], "score": 1.0, "text": "denseand"}, {"category_id": 15, "poly": [864.0, 225.0, 1402.0, 227.0, 1402.0, 259.0, 864.0, 257.0], "score": 0.98, "text": "MoE instruction-tuned models. We compare"}, {"category_id": 15, "poly": [829.0, 2083.0, 871.0, 2083.0, 871.0, 2127.0, 829.0, 2127.0], "score": 1.0, "text": "14"}, {"category_id": 15, "poly": [298.0, 1884.0, 1402.0, 1884.0, 1402.0, 1916.0, 298.0, 1916.0], "score": 0.98, "text": "English Evaluation  For English, we compare Qwen2 with both Qwen1.5 and Llama-3. Similarly,"}, {"category_id": 15, "poly": [296.0, 1916.0, 1402.0, 1916.0, 1402.0, 1946.0, 296.0, 1946.0], "score": 0.99, "text": "the small models of Qwen2 significantly outcompete the Qwen1.5 counterparts. However, in com-"}, {"category_id": 15, "poly": [291.0, 1943.0, 1404.0, 1939.0, 1404.0, 1978.0, 291.0, 1982.0], "score": 0.99, "text": " parison with Llama-3-70B, Qwen2-72B-Instruct is falling behind by small margins especially in"}, {"category_id": 15, "poly": [300.0, 1975.0, 1402.0, 1975.0, 1402.0, 2008.0, 300.0, 2008.0], "score": 1.0, "text": "comprehension and coding. We assume both the amount of English tokens for pre-training and the"}, {"category_id": 15, "poly": [296.0, 2003.0, 1254.0, 2003.0, 1254.0, 2042.0, 296.0, 2042.0], "score": 0.99, "text": "quantity and diversity of data for post-training lead to the performance gap in English."}, {"category_id": 15, "poly": [293.0, 1311.0, 825.0, 1313.0, 824.0, 1352.0, 293.0, 1350.0], "score": 0.99, "text": "5.2.2 IN-HOUSE AUTOMATIC EVALUATION"}], "page_info": {"page_no": 13, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 5, "poly": [353.156982421875, 1267.7286376953125, 1354.4786376953125, 1267.7286376953125, 1354.4786376953125, 1490.4144287109375, 353.156982421875, 1490.4144287109375], "score": 0.9999925494194031}, {"category_id": 1, "poly": [295.0018005371094, 1694.27490234375, 1407.9591064453125, 1694.27490234375, 1407.9591064453125, 2037.1680908203125, 295.0018005371094, 2037.1680908203125], "score": 0.9999768137931824}, {"category_id": 5, "poly": [319.0831298828125, 370.07171630859375, 1380.4222412109375, 370.07171630859375, 1380.4222412109375, 1085.001220703125, 319.0831298828125, 1085.001220703125], "score": 0.9999444484710693}, {"category_id": 1, "poly": [297.6474609375, 1605.448974609375, 1404.489990234375, 1605.448974609375, 1404.489990234375, 1673.015625, 297.6474609375, 1673.015625], "score": 0.9998862147331238}, {"category_id": 6, "poly": [297.271484375, 220.83816528320312, 1408.227783203125, 220.83816528320312, 1408.227783203125, 348.7638854980469, 297.271484375, 348.7638854980469], "score": 0.999852180480957}, {"category_id": 2, "poly": [834.7745361328125, 2086.1572265625, 865.7176513671875, 2086.1572265625, 865.7176513671875, 2114.64111328125, 834.7745361328125, 2114.64111328125], "score": 0.9998165369033813}, {"category_id": 6, "poly": [295.43206787109375, 1118.9945068359375, 1408.511474609375, 1118.9945068359375, 1408.511474609375, 1246.209228515625, 295.43206787109375, 1246.209228515625], "score": 0.9993368983268738}, {"category_id": 0, "poly": [296.5392761230469, 1546.7728271484375, 764.0711059570312, 1546.7728271484375, 764.0711059570312, 1585.28564453125, 296.5392761230469, 1585.28564453125], "score": 0.998333215713501}, {"category_id": 13, "poly": [1033, 1760, 1084, 1760, 1084, 1788, 1033, 1788], "score": 0.88, "latex": "10\\%"}, {"category_id": 13, "poly": [581, 225, 634, 225, 634, 254, 581, 254], "score": 0.86, "latex": "{\\bf7B+}"}, {"category_id": 13, "poly": [960, 1760, 1000, 1760, 1000, 1788, 960, 1788], "score": 0.85, "latex": "0\\%"}, {"category_id": 15, "poly": [291.0, 1694.0, 1404.0, 1696.0, 1404.0, 1735.0, 291.0, 1732.0], "score": 0.97, "text": " Needle in a Haystack  This experiment assesses a model's proficiency in pinpointing facts within"}, {"category_id": 15, "poly": [296.0, 1730.0, 1402.0, 1730.0, 1402.0, 1762.0, 296.0, 1762.0], "score": 0.99, "text": "voluminous texts. Texts with 8K, 16K, .., 128K tokens in length were crafted, with facts strategically"}, {"category_id": 15, "poly": [293.0, 1792.0, 1402.0, 1792.0, 1402.0, 1824.0, 293.0, 1824.0], "score": 0.99, "text": " For contexts over 32K, YARN (Peng et al., 2023) was applied in this evaluation. As illustrated in"}, {"category_id": 15, "poly": [296.0, 1822.0, 1402.0, 1822.0, 1402.0, 1854.0, 296.0, 1854.0], "score": 1.0, "text": "Figure 1, Qwen2-72B-Instruct exhibits exceptional accuracy in retrieving information from the entire"}, {"category_id": 15, "poly": [293.0, 1847.0, 1407.0, 1849.0, 1407.0, 1888.0, 293.0, 1886.0], "score": 0.99, "text": "128K context. Coupled with its inherent strength, this model emerges as the optimal choice for"}, {"category_id": 15, "poly": [298.0, 1884.0, 1402.0, 1884.0, 1402.0, 1916.0, 298.0, 1916.0], "score": 1.0, "text": "processing extensive texts, assuming sufficient resources are accessible. Additionally, models within"}, {"category_id": 15, "poly": [296.0, 1914.0, 1402.0, 1914.0, 1402.0, 1946.0, 296.0, 1946.0], "score": 0.99, "text": "the same series showcases remarkable performance across different context lengths. Precisely, Qwen2-"}, {"category_id": 15, "poly": [296.0, 1943.0, 1402.0, 1943.0, 1402.0, 1975.0, 296.0, 1975.0], "score": 0.99, "text": "7B-Instruct achieves a high level of accuracy in handling contexts up to 128K tokens. Meanwhile,"}, {"category_id": 15, "poly": [298.0, 1975.0, 1404.0, 1975.0, 1404.0, 2008.0, 298.0, 2008.0], "score": 1.0, "text": "Qwen2-57B-A14B-Instruct manages contexts up to 64K tokens proficiently, and the two smaller"}, {"category_id": 15, "poly": [296.0, 2005.0, 1032.0, 2005.0, 1032.0, 2037.0, 296.0, 2037.0], "score": 1.0, "text": "models in the Qwen2 series could support contexts of 32K tokens."}, {"category_id": 15, "poly": [1085.0, 1758.0, 1407.0, 1758.0, 1407.0, 1797.0, 1085.0, 1797.0], "score": 0.96, "text": ", encompassed two instances."}, {"category_id": 15, "poly": [293.0, 1758.0, 959.0, 1758.0, 959.0, 1797.0, 293.0, 1797.0], "score": 0.97, "text": " positioned at varying depths. Each depth interval, e.g., from"}, {"category_id": 15, "poly": [1001.0, 1758.0, 1032.0, 1758.0, 1032.0, 1797.0, 1001.0, 1797.0], "score": 0.94, "text": "to"}, {"category_id": 15, "poly": [300.0, 1613.0, 1402.0, 1613.0, 1402.0, 1645.0, 300.0, 1645.0], "score": 0.99, "text": "Three methods to evaluate long context capabilities are employed: the Needle in a Haystack (NIAH,"}, {"category_id": 15, "poly": [300.0, 1643.0, 1402.0, 1643.0, 1402.0, 1675.0, 300.0, 1675.0], "score": 0.98, "text": "Kamradt, 2023), NeedleBench (OpenCompass Contributors, 2023), and LV-Eval (Yuan et al., 2024))"}, {"category_id": 15, "poly": [300.0, 257.0, 1402.0, 257.0, 1402.0, 289.0, 300.0, 289.0], "score": 0.99, "text": "recent SOTA models with 7-9 billion parameters, including Llama-3-8B-Instruct, Yi-1.5-9B-Chat,"}, {"category_id": 15, "poly": [298.0, 286.0, 1404.0, 284.0, 1404.0, 316.0, 298.0, 319.0], "score": 0.97, "text": "GLM-4-9B-Chat, and Qwen1.5-7B-Chat. -Instruct\" or \"-Chat is omitted in the table. Qwen2-7B-"}, {"category_id": 15, "poly": [298.0, 319.0, 1150.0, 319.0, 1150.0, 351.0, 298.0, 351.0], "score": 1.0, "text": "Instruct demonstrates competitive performance against Llama-3-8B-Instruct."}, {"category_id": 15, "poly": [296.0, 227.0, 580.0, 227.0, 580.0, 259.0, 296.0, 259.0], "score": 0.96, "text": "Table 8: Performance of"}, {"category_id": 15, "poly": [635.0, 227.0, 1400.0, 227.0, 1400.0, 259.0, 635.0, 259.0], "score": 0.99, "text": "instruction-tuned models. We compare Qwen2-7B-Instruct with the"}, {"category_id": 15, "poly": [825.0, 2086.0, 865.0, 2079.0, 873.0, 2124.0, 833.0, 2131.0], "score": 1.0, "text": "15"}, {"category_id": 15, "poly": [298.0, 1123.0, 1404.0, 1123.0, 1404.0, 1155.0, 298.0, 1155.0], "score": 1.0, "text": "Table 9: Performance of smaller instruction-tuned models. We compare both Qwen2-0.5B-Instruct"}, {"category_id": 15, "poly": [298.0, 1155.0, 1404.0, 1155.0, 1404.0, 1185.0, 298.0, 1185.0], "score": 0.98, "text": "and Qwen2-1.5B-Instruct with Qwen1.5-0.5B-Chat and Qwen2-1.8B-Chat. -Instruct\" or -Chat\""}, {"category_id": 15, "poly": [298.0, 1185.0, 1404.0, 1185.0, 1404.0, 1217.0, 298.0, 1217.0], "score": 0.98, "text": "is omitted in the table. Compared with the similar-size baselines, Qwen2 significant surpasses the"}, {"category_id": 15, "poly": [296.0, 1217.0, 587.0, 1214.0, 587.0, 1247.0, 296.0, 1249.0], "score": 0.97, "text": "performance of Qwen1.5."}, {"category_id": 15, "poly": [296.0, 1551.0, 758.0, 1551.0, 758.0, 1584.0, 296.0, 1584.0], "score": 0.98, "text": "5.2.3 LONG CONTEXT CAPABILITIES"}], "page_info": {"page_no": 14, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 5, "poly": [298.32720947265625, 370.16033935546875, 1400.4765625, 370.16033935546875, 1400.4765625, 1032.582763671875, 298.32720947265625, 1032.582763671875], "score": 0.9999847412109375}, {"category_id": 5, "poly": [379.142822265625, 1226.7342529296875, 1320.395263671875, 1226.7342529296875, 1320.395263671875, 1999.2059326171875, 379.142822265625, 1999.2059326171875], "score": 0.9999771118164062}, {"category_id": 6, "poly": [296.3201904296875, 253.27572631835938, 1406.492919921875, 253.27572631835938, 1406.492919921875, 347.9520568847656, 296.3201904296875, 347.9520568847656], "score": 0.9999080896377563}, {"category_id": 6, "poly": [296.1713562011719, 1110.3829345703125, 1405.390625, 1110.3829345703125, 1405.390625, 1203.9619140625, 296.1713562011719, 1203.9619140625], "score": 0.9996384978294373}, {"category_id": 2, "poly": [835.2117309570312, 2088.677490234375, 865.7759399414062, 2088.677490234375, 865.7759399414062, 2113.296142578125, 835.2117309570312, 2113.296142578125], "score": 0.9994726181030273}, {"category_id": 15, "poly": [296.0, 254.0, 1400.0, 257.0, 1400.0, 289.0, 296.0, 286.0], "score": 0.99, "text": "Table 10: Performances of Qwen2-Instruct models on our in-house Chinese automatic evaluation"}, {"category_id": 15, "poly": [298.0, 286.0, 1402.0, 289.0, 1402.0, 321.0, 298.0, 319.0], "score": 0.99, "text": "benchmark. Scores of Qwen2 models surpassing their comparable-sized Qwen1.5 counterparts are"}, {"category_id": 15, "poly": [298.0, 319.0, 1127.0, 319.0, 1127.0, 351.0, 298.0, 351.0], "score": 0.99, "text": "in bold. Qwen2-57B-A14B-Instruct is compared with Qwen1.5-32B-Chat."}, {"category_id": 15, "poly": [298.0, 1111.0, 1402.0, 1111.0, 1402.0, 1144.0, 298.0, 1144.0], "score": 0.99, "text": "Table 11: Performances of Qwen2-Instruct models on our in-house English automatic evaluation"}, {"category_id": 15, "poly": [298.0, 1144.0, 1402.0, 1144.0, 1402.0, 1176.0, 298.0, 1176.0], "score": 0.99, "text": "benchmark. Scores of Qwen2 models surpassing their comparable-sized Qwen1.5 and Llama-3"}, {"category_id": 15, "poly": [298.0, 1176.0, 1312.0, 1176.0, 1312.0, 1208.0, 298.0, 1208.0], "score": 0.99, "text": "counterparts are in bold. Qwen2-57B-A14B-Instruct is compared with Qwen1.5-32B-Chat."}, {"category_id": 15, "poly": [829.0, 2083.0, 871.0, 2083.0, 871.0, 2129.0, 829.0, 2129.0], "score": 1.0, "text": "16"}], "page_info": {"page_no": 15, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 2, "poly": [836.4478759765625, 2087.69677734375, 863.7443237304688, 2087.69677734375, 863.7443237304688, 2112.89013671875, 836.4478759765625, 2112.89013671875], "score": 0.999982476234436}, {"category_id": 5, "poly": [300.559814453125, 1680.11962890625, 1401.0032958984375, 1680.11962890625, 1401.0032958984375, 1973.3875732421875, 300.559814453125, 1973.3875732421875], "score": 0.9999798536300659}, {"category_id": 3, "poly": [299.5755310058594, 384.6409606933594, 1398.5340576171875, 384.6409606933594, 1398.5340576171875, 1372.8900146484375, 299.5755310058594, 1372.8900146484375], "score": 0.9999752044677734}, {"category_id": 4, "poly": [295.5313415527344, 1398.3304443359375, 1404.9056396484375, 1398.3304443359375, 1404.9056396484375, 1462.5904541015625, 295.5313415527344, 1462.5904541015625], "score": 0.9999269247055054}, {"category_id": 6, "poly": [296.27581787109375, 1591.437744140625, 1404.9915771484375, 1591.437744140625, 1404.9915771484375, 1658.27587890625, 296.27581787109375, 1658.27587890625], "score": 0.9998863935470581}, {"category_id": 0, "poly": [415.3927917480469, 287.5004577636719, 1293.229248046875, 287.5004577636719, 1293.229248046875, 326.3540954589844, 415.3927917480469, 326.3540954589844], "score": 0.9998116493225098}, {"category_id": 1, "poly": [321.254150390625, 337.18841552734375, 1361.24658203125, 337.18841552734375, 1361.24658203125, 371.36181640625, 321.254150390625, 371.36181640625], "score": 0.9985284209251404}, {"category_id": 13, "poly": [410, 1626, 572, 1626, 572, 1654, 410, 1654], "score": 0.72, "latex": "+Y A R N{+}D C A"}, {"category_id": 13, "poly": [1058, 1625, 1105, 1625, 1105, 1653, 1058, 1653], "score": 0.28, "latex": "32\\mathrm{k}"}, {"category_id": 15, "poly": [829.0, 2083.0, 868.0, 2083.0, 868.0, 2127.0, 829.0, 2127.0], "score": 1.0, "text": "17"}, {"category_id": 15, "poly": [298.0, 1400.0, 1404.0, 1400.0, 1404.0, 1432.0, 298.0, 1432.0], "score": 0.99, "text": "Figure 1: Performance of Qwen2 instruction-tuned models on Needle in A Haystack Test. All"}, {"category_id": 15, "poly": [296.0, 1432.0, 1280.0, 1432.0, 1280.0, 1464.0, 296.0, 1464.0], "score": 0.99, "text": "models that supports context lengths above 32k tokens integrates the YARN mechanism."}, {"category_id": 15, "poly": [298.0, 1597.0, 1404.0, 1597.0, 1404.0, 1629.0, 298.0, 1629.0], "score": 1.0, "text": "Table 12: Performance of Qwen2-72B-Instruct and Qwen2-7B-Instruct on NeedleBench and"}, {"category_id": 15, "poly": [296.0, 1625.0, 409.0, 1627.0, 409.0, 1659.0, 296.0, 1657.0], "score": 0.98, "text": "LV-Eval."}, {"category_id": 15, "poly": [573.0, 1625.0, 1057.0, 1627.0, 1057.0, 1659.0, 573.0, 1657.0], "score": 0.99, "text": "does not change the model behavior within"}, {"category_id": 15, "poly": [1106.0, 1625.0, 1190.0, 1627.0, 1189.0, 1659.0, 1106.0, 1657.0], "score": 1.0, "text": "tokens."}, {"category_id": 15, "poly": [416.0, 289.0, 1291.0, 289.0, 1291.0, 335.0, 416.0, 335.0], "score": 0.98, "text": "Testing Qwen2-Instruct via \"Needle in A HayStack\""}, {"category_id": 15, "poly": [323.0, 341.0, 1358.0, 341.0, 1358.0, 374.0, 323.0, 374.0], "score": 0.99, "text": "Retrieve Facts from Given Documents across Context Lengths and Document Depth"}], "page_info": {"page_no": 16, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 5, "poly": [297.1655578613281, 400.509765625, 1404.359375, 400.509765625, 1404.359375, 822.0902709960938, 297.1655578613281, 822.0902709960938], "score": 0.9999792575836182}, {"category_id": 1, "poly": [297.0867919921875, 1441.378662109375, 1406.55224609375, 1441.378662109375, 1406.55224609375, 1596.4027099609375, 297.0867919921875, 1596.4027099609375], "score": 0.9999746084213257}, {"category_id": 1, "poly": [297.197021484375, 1124.2010498046875, 1406.82373046875, 1124.2010498046875, 1406.82373046875, 1342.5482177734375, 297.197021484375, 1342.5482177734375], "score": 0.9999688863754272}, {"category_id": 1, "poly": [297.68585205078125, 1609.8009033203125, 1405.921630859375, 1609.8009033203125, 1405.921630859375, 1764.800537109375, 297.68585205078125, 1764.800537109375], "score": 0.9999493360519409}, {"category_id": 6, "poly": [295.4906311035156, 220.9849395751953, 1408.16943359375, 220.9849395751953, 1408.16943359375, 378.9195556640625, 295.4906311035156, 378.9195556640625], "score": 0.9999369382858276}, {"category_id": 1, "poly": [296.7181701660156, 1864.88818359375, 1405.5904541015625, 1864.88818359375, 1405.5904541015625, 1956.796875, 296.7181701660156, 1956.796875], "score": 0.9999291300773621}, {"category_id": 0, "poly": [297.8687438964844, 1384.4818115234375, 743.9710083007812, 1384.4818115234375, 743.9710083007812, 1417.350830078125, 297.8687438964844, 1417.350830078125], "score": 0.9998351335525513}, {"category_id": 1, "poly": [296.6714782714844, 883.5443115234375, 1406.273193359375, 883.5443115234375, 1406.273193359375, 1101.142822265625, 296.6714782714844, 1101.142822265625], "score": 0.9998016357421875}, {"category_id": 1, "poly": [296.0188293457031, 1971.70166015625, 1408.11572265625, 1971.70166015625, 1408.11572265625, 2036.439697265625, 296.0188293457031, 2036.439697265625], "score": 0.9997365474700928}, {"category_id": 0, "poly": [298.0435485839844, 1806.4539794921875, 724.16845703125, 1806.4539794921875, 724.16845703125, 1840.6290283203125, 298.0435485839844, 1840.6290283203125], "score": 0.9996814131736755}, {"category_id": 2, "poly": [835.1615600585938, 2088.64208984375, 864.3776245117188, 2088.64208984375, 864.3776245117188, 2112.826904296875, 835.1615600585938, 2112.826904296875], "score": 0.9995487928390503}, {"category_id": 15, "poly": [298.0, 1444.0, 1404.0, 1444.0, 1404.0, 1476.0, 298.0, 1476.0], "score": 0.99, "text": "For the multilingual evaluation, we implement a comprehensive human evaluation for the assessment"}, {"category_id": 15, "poly": [296.0, 1474.0, 1402.0, 1471.0, 1402.0, 1503.0, 296.0, 1506.0], "score": 0.98, "text": "of multilingual capabilities. Specifically, we design diverse test cases assessing different capabilities"}, {"category_id": 15, "poly": [293.0, 1503.0, 1407.0, 1503.0, 1407.0, 1542.0, 293.0, 1542.0], "score": 0.98, "text": " of large language models, and we have test cases that are in a number of languages. For the annotators,"}, {"category_id": 15, "poly": [298.0, 1538.0, 1407.0, 1538.0, 1407.0, 1568.0, 298.0, 1568.0], "score": 1.0, "text": "we invite one professional annotator for each language who majors in the language for the evaluation."}, {"category_id": 15, "poly": [296.0, 1568.0, 1293.0, 1568.0, 1293.0, 1600.0, 296.0, 1600.0], "score": 0.99, "text": "For each test case, the annotator grades the response from model with a score from 1 to 5."}, {"category_id": 15, "poly": [296.0, 1125.0, 1402.0, 1128.0, 1402.0, 1160.0, 296.0, 1157.0], "score": 0.98, "text": "LV-Eval LV-Eval comprises 11 diverse QA datasets that demand comprehension of multiple pieces"}, {"category_id": 15, "poly": [296.0, 1160.0, 1404.0, 1160.0, 1404.0, 1192.0, 296.0, 1192.0], "score": 0.99, "text": "of evidence at once. To rectify the shortcomings of its original metric, which was excessively stringent"}, {"category_id": 15, "poly": [296.0, 1189.0, 1404.0, 1189.0, 1404.0, 1221.0, 296.0, 1221.0], "score": 0.99, "text": "and led to a high rate of false negatives, we adopt the keyword recall as the reported score. As shown"}, {"category_id": 15, "poly": [293.0, 1217.0, 1404.0, 1219.0, 1404.0, 1251.0, 293.0, 1249.0], "score": 0.99, "text": "in Table 12, integrating YARN and DCA substantially bolsters the long-context competencies of"}, {"category_id": 15, "poly": [296.0, 1247.0, 1407.0, 1247.0, 1407.0, 1286.0, 296.0, 1286.0], "score": 0.99, "text": "Qwen2 models on LV-Eval. Qwen2-7B-Instruct achieves parity with ChatGLM4-9B-1M, albeit with"}, {"category_id": 15, "poly": [291.0, 1276.0, 1409.0, 1279.0, 1409.0, 1318.0, 291.0, 1315.0], "score": 0.99, "text": " a more noticeable decline at extended contexts. Moreover, Qwen2-72B-Instruct demonstrates strong"}, {"category_id": 15, "poly": [296.0, 1313.0, 1284.0, 1313.0, 1284.0, 1343.0, 296.0, 1343.0], "score": 1.0, "text": "performance across all lengths, confirming its proficiency in handling long-context tasks."}, {"category_id": 15, "poly": [298.0, 1613.0, 1402.0, 1613.0, 1402.0, 1645.0, 298.0, 1645.0], "score": 0.99, "text": "We report the results of our model and the baselines in the evaluation of different languages. From"}, {"category_id": 15, "poly": [300.0, 1643.0, 1404.0, 1643.0, 1404.0, 1675.0, 300.0, 1675.0], "score": 0.98, "text": "Table 13, it can be found that on average Qwen2-72B-Instruct significantly outperforms GPT-3.5-"}, {"category_id": 15, "poly": [296.0, 1673.0, 1404.0, 1673.0, 1404.0, 1705.0, 296.0, 1705.0], "score": 0.99, "text": "Turbo and it is competitive with GPT-4-Turbo and slightly falls behind Claude-3-Opus. This shows "}, {"category_id": 15, "poly": [296.0, 1703.0, 1402.0, 1703.0, 1402.0, 1735.0, 296.0, 1735.0], "score": 0.99, "text": "that our multilingual pre-training and instruction tuning data contribute to the multilingual capabilities"}, {"category_id": 15, "poly": [293.0, 1730.0, 1296.0, 1730.0, 1296.0, 1769.0, 293.0, 1769.0], "score": 0.99, "text": " of Qwen2-72B-Instruct and it is competitive with most state-of-the-art proprietary LLMs."}, {"category_id": 15, "poly": [298.0, 227.0, 1402.0, 227.0, 1402.0, 259.0, 298.0, 259.0], "score": 1.0, "text": "Table 13: Performance of Qwen2-72B-Instruct and proprietary LLMs in multilingual human"}, {"category_id": 15, "poly": [298.0, 257.0, 1402.0, 257.0, 1402.0, 289.0, 298.0, 289.0], "score": 0.99, "text": "evaluation. We compare Qwen2-72B-Instruct with GPT-3.5-Turbo-1106, GPT-4-Turbo-0409, GPT-"}, {"category_id": 15, "poly": [298.0, 286.0, 1402.0, 286.0, 1402.0, 319.0, 298.0, 319.0], "score": 0.99, "text": "4o-0513, Claude-3-Opus-0229. Scores range from 1 to 5. Overall, Qwen2-72B-Instruct performs"}, {"category_id": 15, "poly": [298.0, 319.0, 1402.0, 319.0, 1402.0, 351.0, 298.0, 351.0], "score": 0.99, "text": "substantially better than GPT-3.5-Turbo but there is progress to be made to be competitive with the"}, {"category_id": 15, "poly": [291.0, 346.0, 841.0, 344.0, 841.0, 383.0, 291.0, 385.0], "score": 0.97, "text": " proprietary models released in the last 6 months."}, {"category_id": 15, "poly": [296.0, 1868.0, 1402.0, 1868.0, 1402.0, 1900.0, 296.0, 1900.0], "score": 1.0, "text": "LLMs with openly accessible weights effectively accelerate the development of the research as well"}, {"category_id": 15, "poly": [298.0, 1898.0, 1404.0, 1898.0, 1404.0, 1930.0, 298.0, 1930.0], "score": 0.99, "text": "as their applications. Moreover, we believe that it is crucial to build safe and responsible LLMs so"}, {"category_id": 15, "poly": [293.0, 1927.0, 1187.0, 1930.0, 1187.0, 1962.0, 293.0, 1959.0], "score": 0.98, "text": " that the effect of the misuse of AI technologies could be significantly alleviated."}, {"category_id": 15, "poly": [298.0, 1386.0, 739.0, 1386.0, 739.0, 1419.0, 298.0, 1419.0], "score": 0.98, "text": "5.2.4 MULTILINGUAL EVALUATION"}, {"category_id": 15, "poly": [296.0, 887.0, 1402.0, 887.0, 1402.0, 919.0, 296.0, 919.0], "score": 0.98, "text": "NeedleBench NeedleBench ups the challenge on NIAH by including multiple facts (two to five) in"}, {"category_id": 15, "poly": [293.0, 914.0, 1404.0, 912.0, 1404.0, 951.0, 293.0, 953.0], "score": 0.98, "text": " passages, necessitating simultaneous identification and multi-hop reasoning. Table 12 reveals that"}, {"category_id": 15, "poly": [296.0, 944.0, 1407.0, 944.0, 1407.0, 983.0, 296.0, 983.0], "score": 0.98, "text": "the integration of YARN and DCA (An et al., 2024) notably improves Qwen2 models' long-context"}, {"category_id": 15, "poly": [293.0, 972.0, 1407.0, 974.0, 1407.0, 1013.0, 293.0, 1011.0], "score": 0.99, "text": " abilities. Qwen2-7B-Instruct surpasses ChatGLM4-9B-1M (Zeng et al., 2024), which claims a 1M"}, {"category_id": 15, "poly": [291.0, 1004.0, 1404.0, 1006.0, 1404.0, 1045.0, 291.0, 1043.0], "score": 0.99, "text": " context length. Moreover, Qwen2-72B-Instruct demonstrates strong performance, with an accuracy"}, {"category_id": 15, "poly": [296.0, 1040.0, 1407.0, 1040.0, 1407.0, 1070.0, 296.0, 1070.0], "score": 0.99, "text": "reduction of just 6 points, compared to ChatGLM4-9B-1M, which shows a more pronounced decline"}, {"category_id": 15, "poly": [291.0, 1066.0, 929.0, 1068.0, 928.0, 1107.0, 291.0, 1105.0], "score": 0.98, "text": " of 11 points, particularly given its lower initial accuracy."}, {"category_id": 15, "poly": [300.0, 1975.0, 1402.0, 1975.0, 1402.0, 2008.0, 300.0, 2008.0], "score": 0.99, "text": "We implement a multilingual safety evaluation that tests the LLMs in different languages. Specif-"}, {"category_id": 15, "poly": [300.0, 2008.0, 1402.0, 2008.0, 1402.0, 2040.0, 300.0, 2040.0], "score": 1.0, "text": "ically, we assess the safety performance of the models in the topics about illegal behaviors, fraud,"}, {"category_id": 15, "poly": [293.0, 1806.0, 721.0, 1806.0, 721.0, 1845.0, 293.0, 1845.0], "score": 0.98, "text": "5.2.5 SAFETY & RESPONSIBILITY"}, {"category_id": 15, "poly": [823.0, 2087.0, 867.0, 2079.0, 875.0, 2123.0, 831.0, 2131.0], "score": 1.0, "text": "18"}], "page_info": {"page_no": 17, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 5, "poly": [463.3813781738281, 341.3003845214844, 1236.759765625, 341.3003845214844, 1236.759765625, 532.586669921875, 463.3813781738281, 532.586669921875], "score": 0.999994158744812}, {"category_id": 1, "poly": [298.863525390625, 665.7908325195312, 1403.313720703125, 665.7908325195312, 1403.313720703125, 849.5612182617188, 298.863525390625, 849.5612182617188], "score": 0.9999868869781494}, {"category_id": 1, "poly": [298.0088806152344, 961.5335693359375, 1405.3580322265625, 961.5335693359375, 1405.3580322265625, 1300.83642578125, 298.0088806152344, 1300.83642578125], "score": 0.9999704360961914}, {"category_id": 1, "poly": [300.1067810058594, 587.7910766601562, 1403.1163330078125, 587.7910766601562, 1403.1163330078125, 649.253662109375, 300.1067810058594, 649.253662109375], "score": 0.9999675154685974}, {"category_id": 0, "poly": [299.0171203613281, 894.9230346679688, 546.204345703125, 894.9230346679688, 546.204345703125, 928.6372680664062, 299.0171203613281, 928.6372680664062], "score": 0.9999403357505798}, {"category_id": 2, "poly": [835.9227905273438, 2088.706298828125, 864.934814453125, 2088.706298828125, 864.934814453125, 2112.5419921875, 835.9227905273438, 2112.5419921875], "score": 0.9996909499168396}, {"category_id": 6, "poly": [294.9932861328125, 222.24803161621094, 1404.484619140625, 222.24803161621094, 1404.484619140625, 317.3661193847656, 294.9932861328125, 317.3661193847656], "score": 0.9994062185287476}, {"category_id": 13, "poly": [388, 757, 462, 757, 462, 786, 388, 786], "score": 0.78, "latex": "\\cdot8x22\\mathrm{B}"}, {"category_id": 13, "poly": [511, 255, 585, 255, 585, 284, 511, 284], "score": 0.34, "latex": "{\\bf8x22B}"}, {"category_id": 15, "poly": [291.0, 662.0, 1404.0, 665.0, 1404.0, 704.0, 291.0, 701.0], "score": 0.99, "text": " The results are presented in Table 14, where the proportion of harmful responses generated by the"}, {"category_id": 15, "poly": [291.0, 692.0, 1404.0, 694.0, 1404.0, 733.0, 291.0, 731.0], "score": 0.99, "text": " models are shown and the lower, the better. It can be observed that Qwen2-72B-Instruct performs"}, {"category_id": 15, "poly": [298.0, 729.0, 1404.0, 729.0, 1404.0, 761.0, 298.0, 761.0], "score": 0.99, "text": "better than the proprietary model, GPT-4, and significantly outperforms the open-weight model,"}, {"category_id": 15, "poly": [298.0, 791.0, 1402.0, 791.0, 1402.0, 823.0, 298.0, 823.0], "score": 0.99, "text": "be a safer and more responsible model, especially in terms of pornography, which is a conventionally"}, {"category_id": 15, "poly": [296.0, 820.0, 857.0, 820.0, 857.0, 852.0, 296.0, 852.0], "score": 0.99, "text": "difficult category to differentiate even for humans."}, {"category_id": 15, "poly": [298.0, 759.0, 387.0, 759.0, 387.0, 791.0, 298.0, 791.0], "score": 0.99, "text": "Mixtral-"}, {"category_id": 15, "poly": [463.0, 759.0, 1402.0, 759.0, 1402.0, 791.0, 463.0, 791.0], "score": 0.99, "text": "-Instruct. However, we believe that there is still much room for our model to improve to"}, {"category_id": 15, "poly": [296.0, 965.0, 1404.0, 965.0, 1404.0, 997.0, 296.0, 997.0], "score": 0.99, "text": "This technical report has presented the Qwen2 series, a versatile suite of foundational and instruction-"}, {"category_id": 15, "poly": [296.0, 997.0, 1402.0, 997.0, 1402.0, 1029.0, 296.0, 1029.0], "score": 0.99, "text": "tuned language models, ranging from 0.5 to 72 billion parameters, including models of dense and"}, {"category_id": 15, "poly": [296.0, 1027.0, 1404.0, 1027.0, 1404.0, 1059.0, 296.0, 1059.0], "score": 0.99, "text": "Mixture-of-Experts architecture. Qwen2 outperforms previous open-weight models, notably its "}, {"category_id": 15, "poly": [296.0, 1056.0, 1402.0, 1056.0, 1402.0, 1089.0, 296.0, 1089.0], "score": 0.99, "text": "predecessor Qwen1.5, and displays competitive performance against proprietary models across a"}, {"category_id": 15, "poly": [296.0, 1084.0, 1404.0, 1084.0, 1404.0, 1123.0, 296.0, 1123.0], "score": 1.0, "text": "broad spectrum of benchmarks in language understanding, generation, multilingual capabilities,"}, {"category_id": 15, "poly": [298.0, 1118.0, 1404.0, 1118.0, 1404.0, 1150.0, 298.0, 1150.0], "score": 1.0, "text": "coding, mathematics, and reasoning. In this update, we have extra focus on long-context, multi-"}, {"category_id": 15, "poly": [296.0, 1148.0, 1402.0, 1148.0, 1402.0, 1180.0, 296.0, 1180.0], "score": 0.99, "text": "lingual, coding, mathematics capabilities and safety and responsibility. In a commitment to fostering"}, {"category_id": 15, "poly": [296.0, 1178.0, 1402.0, 1178.0, 1402.0, 1210.0, 296.0, 1210.0], "score": 0.99, "text": "innovation and accessibility within the community, we have made the Qwen2 model weights openly"}, {"category_id": 15, "poly": [298.0, 1210.0, 1404.0, 1210.0, 1404.0, 1242.0, 298.0, 1242.0], "score": 1.0, "text": "accessible, which enables researchers and developers to harness the full potential of Qwen2 in a"}, {"category_id": 15, "poly": [298.0, 1240.0, 1404.0, 1240.0, 1404.0, 1272.0, 298.0, 1272.0], "score": 0.99, "text": "variety of applications and research projects. Through these efforts, we aim to contribute to the"}, {"category_id": 15, "poly": [298.0, 1272.0, 1065.0, 1272.0, 1065.0, 1304.0, 298.0, 1304.0], "score": 0.99, "text": "advancement of AI technologies and their positive impact on society."}, {"category_id": 15, "poly": [298.0, 591.0, 1404.0, 591.0, 1404.0, 623.0, 298.0, 623.0], "score": 0.99, "text": "pornography, and privacy. We have collected prompts prone to jail-breaking and use them to test"}, {"category_id": 15, "poly": [298.0, 623.0, 965.0, 623.0, 965.0, 653.0, 298.0, 653.0], "score": 1.0, "text": "whether the models can provide safe responses by rejection."}, {"category_id": 15, "poly": [293.0, 896.0, 545.0, 896.0, 545.0, 935.0, 293.0, 935.0], "score": 0.99, "text": "6CONCLUSION"}, {"category_id": 15, "poly": [829.0, 2083.0, 871.0, 2083.0, 871.0, 2127.0, 829.0, 2127.0], "score": 1.0, "text": "19"}, {"category_id": 15, "poly": [298.0, 227.0, 1402.0, 227.0, 1402.0, 259.0, 298.0, 259.0], "score": 0.99, "text": "Table 14: Performance of models in safety evaluation. We compare Qwen2-72B-Instruct with"}, {"category_id": 15, "poly": [293.0, 286.0, 647.0, 289.0, 647.0, 321.0, 293.0, 318.0], "score": 0.97, "text": "with risks than the competitors."}, {"category_id": 15, "poly": [293.0, 250.0, 510.0, 254.0, 510.0, 293.0, 293.0, 289.0], "score": 0.99, "text": "GPT-4 andMixtral-"}, {"category_id": 15, "poly": [586.0, 250.0, 1404.0, 254.0, 1404.0, 293.0, 586.0, 289.0], "score": 0.98, "text": "-Instruct. The lower, the beter. Qwen2-72B-Instruct rejected more prompts"}], "page_info": {"page_no": 18, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [297.9178161621094, 995.6095581054688, 1406.6187744140625, 995.6095581054688, 1406.6187744140625, 1214.9093017578125, 297.9178161621094, 1214.9093017578125], "score": 0.9999434351921082}, {"category_id": 1, "poly": [296.0719299316406, 1336.425537109375, 1406.89111328125, 1336.425537109375, 1406.89111328125, 1647.3800048828125, 296.0719299316406, 1647.3800048828125], "score": 0.9999407529830933}, {"category_id": 1, "poly": [295.1864929199219, 775.1276245117188, 1408.8819580078125, 775.1276245117188, 1408.8819580078125, 871.7578735351562, 295.1864929199219, 871.7578735351562], "score": 0.9997367858886719}, {"category_id": 1, "poly": [299.6258544921875, 886.0331420898438, 1405.522216796875, 886.0331420898438, 1405.522216796875, 981.9502563476562, 299.6258544921875, 981.9502563476562], "score": 0.9996438026428223}, {"category_id": 1, "poly": [298.3380432128906, 276.823974609375, 1407.0181884765625, 276.823974609375, 1407.0181884765625, 493.7052917480469, 298.3380432128906, 493.7052917480469], "score": 0.9995603561401367}, {"category_id": 1, "poly": [296.5304260253906, 1660.9935302734375, 1406.4324951171875, 1660.9935302734375, 1406.4324951171875, 1782.9842529296875, 296.5304260253906, 1782.9842529296875], "score": 0.9995430707931519}, {"category_id": 1, "poly": [298.6700134277344, 1227.7532958984375, 1404.3399658203125, 1227.7532958984375, 1404.3399658203125, 1320.9498291015625, 298.6700134277344, 1320.9498291015625], "score": 0.9994771480560303}, {"category_id": 1, "poly": [294.70654296875, 1800.8382568359375, 1404.9105224609375, 1800.8382568359375, 1404.9105224609375, 1896.78515625, 294.70654296875, 1896.78515625], "score": 0.9992391467094421}, {"category_id": 1, "poly": [299.3008117675781, 588.7805786132812, 1404.7928466796875, 588.7805786132812, 1404.7928466796875, 683.4517211914062, 299.3008117675781, 683.4517211914062], "score": 0.9990824460983276}, {"category_id": 1, "poly": [299.49554443359375, 509.7132873535156, 1404.5111083984375, 509.7132873535156, 1404.5111083984375, 571.8046875, 299.49554443359375, 571.8046875], "score": 0.9989830851554871}, {"category_id": 1, "poly": [294.55816650390625, 697.2274780273438, 1406.37158203125, 697.2274780273438, 1406.37158203125, 763.8479614257812, 294.55816650390625, 763.8479614257812], "score": 0.9986499547958374}, {"category_id": 1, "poly": [294.43475341796875, 1910.482666015625, 1407.5330810546875, 1910.482666015625, 1407.5330810546875, 2037.427490234375, 294.43475341796875, 2037.427490234375], "score": 0.9971474409103394}, {"category_id": 2, "poly": [833.6610107421875, 2084.53662109375, 869.4192504882812, 2084.53662109375, 869.4192504882812, 2113.39013671875, 833.6610107421875, 2113.39013671875], "score": 0.9945186376571655}, {"category_id": 2, "poly": [298.94989013671875, 227.00033569335938, 490.5442199707031, 227.00033569335938, 490.5442199707031, 261.0430908203125, 298.94989013671875, 261.0430908203125], "score": 0.8960908651351929}, {"category_id": 1, "poly": [298.8456115722656, 227.18560791015625, 490.4358825683594, 227.18560791015625, 490.4358825683594, 260.8744812011719, 298.8456115722656, 260.8744812011719], "score": 0.3486683964729309}, {"category_id": 13, "poly": [329, 511, 351, 511, 351, 536, 329, 536], "score": 0.3, "latex": "@"}, {"category_id": 15, "poly": [293.0, 999.0, 1400.0, 999.0, 1400.0, 1031.0, 293.0, 1031.0], "score": 0.99, "text": " Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge."}, {"category_id": 15, "poly": [323.0, 1029.0, 1404.0, 1029.0, 1404.0, 1061.0, 323.0, 1061.0], "score": 0.99, "text": "Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu,"}, {"category_id": 15, "poly": [326.0, 1061.0, 1404.0, 1061.0, 1404.0, 1093.0, 326.0, 1093.0], "score": 0.99, "text": "Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan,"}, {"category_id": 15, "poly": [323.0, 1089.0, 1407.0, 1089.0, 1407.0, 1128.0, 323.0, 1128.0], "score": 0.98, "text": "Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin"}, {"category_id": 15, "poly": [321.0, 1121.0, 1402.0, 1123.0, 1402.0, 1155.0, 321.0, 1153.0], "score": 0.99, "text": "Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng"}, {"category_id": 15, "poly": [326.0, 1153.0, 1402.0, 1153.0, 1402.0, 1182.0, 326.0, 1182.0], "score": 0.99, "text": "Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren"}, {"category_id": 15, "poly": [326.0, 1180.0, 1404.0, 1180.0, 1404.0, 1212.0, 326.0, 1212.0], "score": 0.99, "text": "Zhou, Xiaohuan Zhou, and Tianhang Zhu. Qwen technical report. CoRR, abs/2309.16609, 2023a."}, {"category_id": 15, "poly": [296.0, 1338.0, 1404.0, 1341.0, 1404.0, 1373.0, 296.0, 1370.0], "score": 1.0, "text": "Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones,"}, {"category_id": 15, "poly": [326.0, 1370.0, 1404.0, 1370.0, 1404.0, 1402.0, 326.0, 1402.0], "score": 0.99, "text": "Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Olsson,"}, {"category_id": 15, "poly": [326.0, 1402.0, 1404.0, 1402.0, 1404.0, 1435.0, 326.0, 1435.0], "score": 1.0, "text": "Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson,"}, {"category_id": 15, "poly": [323.0, 1430.0, 1404.0, 1432.0, 1404.0, 1464.0, 323.0, 1462.0], "score": 0.99, "text": "Ethan Perez, Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile"}, {"category_id": 15, "poly": [321.0, 1460.0, 1402.0, 1462.0, 1402.0, 1494.0, 321.0, 1492.0], "score": 0.99, "text": " Lukosiute, Liane Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova"}, {"category_id": 15, "poly": [323.0, 1492.0, 1402.0, 1492.0, 1402.0, 1524.0, 323.0, 1524.0], "score": 0.98, "text": "DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec, Sheer El"}, {"category_id": 15, "poly": [323.0, 1522.0, 1402.0, 1522.0, 1402.0, 1554.0, 323.0, 1554.0], "score": 1.0, "text": "Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly, Tom Henighan,"}, {"category_id": 15, "poly": [323.0, 1554.0, 1404.0, 1554.0, 1404.0, 1584.0, 323.0, 1584.0], "score": 1.0, "text": "Tristan Hume, Samuel R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario Amodei, Nicholas"}, {"category_id": 15, "poly": [323.0, 1586.0, 1404.0, 1586.0, 1404.0, 1616.0, 323.0, 1616.0], "score": 0.99, "text": "Joseph, Sam McCandlish, Tom Brown, and Jared Kaplan. Constitutional AI: Harmlessness from"}, {"category_id": 15, "poly": [326.0, 1613.0, 813.0, 1613.0, 813.0, 1645.0, 326.0, 1645.0], "score": 0.98, "text": "AI feedback. CoRR, abs/2212.08073, 2022."}, {"category_id": 15, "poly": [294.0, 776.0, 430.0, 782.0, 429.0, 814.0, 293.0, 809.0], "score": 1.0, "text": "Anthropic."}, {"category_id": 15, "poly": [476.0, 779.0, 871.0, 779.0, 871.0, 811.0, 476.0, 811.0], "score": 0.96, "text": "The Claude 3 model family:"}, {"category_id": 15, "poly": [889.0, 779.0, 1194.0, 779.0, 1194.0, 811.0, 889.0, 811.0], "score": 0.97, "text": " Opus, Sonnet, Haiku."}, {"category_id": 15, "poly": [1234.0, 774.0, 1407.0, 779.0, 1406.0, 812.0, 1233.0, 806.0], "score": 0.98, "text": "Technical  re-"}, {"category_id": 15, "poly": [321.0, 811.0, 721.0, 809.0, 721.0, 841.0, 321.0, 843.0], "score": 0.92, "text": "port,  Anthropic AI,  2024."}, {"category_id": 15, "poly": [808.0, 814.0, 878.0, 814.0, 878.0, 839.0, 808.0, 839.0], "score": 1.0, "text": "URL"}, {"category_id": 15, "poly": [875.0, 814.0, 1404.0, 814.0, 1404.0, 843.0, 875.0, 843.0], "score": 1.0, "text": "https://www-cdn.anthropic.com/"}, {"category_id": 15, "poly": [323.0, 839.0, 1400.0, 841.0, 1400.0, 873.0, 323.0, 871.0], "score": 0.99, "text": "de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Mode1_Card_C1aude_3.pdf."}, {"category_id": 15, "poly": [293.0, 887.0, 1402.0, 889.0, 1402.0, 921.0, 293.0, 919.0], "score": 0.99, "text": " Jacob Austin, Augustus Odena, Maxwell 1. Nye, Maarten Bosma, Henryk Michalewski, David Dohan,"}, {"category_id": 15, "poly": [323.0, 921.0, 1404.0, 921.0, 1404.0, 953.0, 323.0, 953.0], "score": 1.0, "text": "Ellen Jiang, Carrie J. Cai, Michael Terry, Quoc V. Le, and Charles Sutton. Program synthesis with"}, {"category_id": 15, "poly": [321.0, 949.0, 926.0, 944.0, 926.0, 983.0, 321.0, 988.0], "score": 0.99, "text": "large language models. CoRR, abs/2108.07732, 2021."}, {"category_id": 15, "poly": [293.0, 277.0, 1402.0, 280.0, 1402.0, 312.0, 293.0, 309.0], "score": 0.99, "text": "Marah Abdin, Jyoti Aneja, Sebastien Bubeck, Caio Csar Teodoro Mendes, Weizhu Chen, Allie Del"}, {"category_id": 15, "poly": [323.0, 312.0, 1407.0, 312.0, 1407.0, 341.0, 323.0, 341.0], "score": 0.99, "text": "Giorno, Ronen Eldan, Sivakanth Gopi, Suriya Gunasekar, Mojan Javaheripi, Piero Kauffmann,"}, {"category_id": 15, "poly": [326.0, 337.0, 1404.0, 339.0, 1404.0, 371.0, 326.0, 369.0], "score": 0.99, "text": "Yin Tat Lee, Yuanzhi Li, Anh Nguyen, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah,"}, {"category_id": 15, "poly": [321.0, 367.0, 1404.0, 369.0, 1404.0, 408.0, 321.0, 406.0], "score": 1.0, "text": "Michael Santacroce, Harkirat Singh Behl, Adam Taumann Kalai, Xin Wang, Rachel Ward, Philipp"}, {"category_id": 15, "poly": [326.0, 403.0, 1404.0, 403.0, 1404.0, 435.0, 326.0, 435.0], "score": 0.98, "text": "Witte, Cyril Zhang, and Yi Zhang. Phi-2: The surprising power of small language models,"}, {"category_id": 15, "poly": [326.0, 433.0, 1409.0, 433.0, 1409.0, 465.0, 326.0, 465.0], "score": 1.0, "text": "2024. URL https://www.microsoft.com/en-us/research/blog/phi-2-the-"}, {"category_id": 15, "poly": [326.0, 465.0, 1042.0, 465.0, 1042.0, 497.0, 326.0, 497.0], "score": 0.99, "text": "surprising-power-of-small-language-models/."}, {"category_id": 15, "poly": [296.0, 1664.0, 1402.0, 1664.0, 1402.0, 1696.0, 296.0, 1696.0], "score": 0.99, "text": "Lucas Bandarkar, Davis Liang, Benjamin Muller, Mikel Artetxe, Satya Narayan Shukla, Donald Husa,"}, {"category_id": 15, "poly": [323.0, 1696.0, 1402.0, 1696.0, 1402.0, 1726.0, 323.0, 1726.0], "score": 1.0, "text": "Naman Goyal, Abhinandan Krishnan, Luke Zettlemoyer, and Madian Khabsa. The Belebele bench-"}, {"category_id": 15, "poly": [326.0, 1726.0, 1404.0, 1726.0, 1404.0, 1758.0, 326.0, 1758.0], "score": 1.0, "text": "mark: A parallel reading comprehension dataset in 122 language variants. CoRR, abs/2308.16884,"}, {"category_id": 15, "poly": [323.0, 1753.0, 393.0, 1753.0, 393.0, 1785.0, 323.0, 1785.0], "score": 1.0, "text": "2023."}, {"category_id": 15, "poly": [293.0, 1228.0, 1402.0, 1231.0, 1402.0, 1263.0, 293.0, 1260.0], "score": 0.99, "text": " Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang"}, {"category_id": 15, "poly": [321.0, 1260.0, 1404.0, 1260.0, 1404.0, 1299.0, 321.0, 1299.0], "score": 0.97, "text": " Zhou, and Jingren Zhou. Qwen- VL: A frontier large vision-language model with versatile abilities."}, {"category_id": 15, "poly": [326.0, 1292.0, 672.0, 1292.0, 672.0, 1325.0, 326.0, 1325.0], "score": 0.99, "text": "CoRR, abs/2308.12966, 2023b."}, {"category_id": 15, "poly": [293.0, 1804.0, 1400.0, 1804.0, 1400.0, 1836.0, 293.0, 1836.0], "score": 0.99, "text": " Boxi Cao, Keming Lu, Xinyu Lu, Jiawei Chen, Mengjie Ren, Hao Xiang, Peilin Liu, Yaojie Lu, Ben"}, {"category_id": 15, "poly": [323.0, 1836.0, 1402.0, 1836.0, 1402.0, 1868.0, 323.0, 1868.0], "score": 0.99, "text": "He, Xianpei Han, Le Sun, Hongyu Lin, and Bowen Yu. Towards scalable automated alignment of"}, {"category_id": 15, "poly": [321.0, 1861.0, 864.0, 1858.0, 864.0, 1897.0, 321.0, 1900.0], "score": 1.0, "text": "LLMs: A survey. CoRR, abs/2406.01252, 2024."}, {"category_id": 15, "poly": [296.0, 591.0, 1402.0, 591.0, 1402.0, 623.0, 296.0, 623.0], "score": 1.0, "text": "Joshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebron, and Sumit"}, {"category_id": 15, "poly": [323.0, 623.0, 1404.0, 623.0, 1404.0, 655.0, 323.0, 655.0], "score": 0.99, "text": " Sanghai. GQA: Training generalized multi-query Transformer models from multi-head checkpoints."}, {"category_id": 15, "poly": [321.0, 646.0, 1192.0, 649.0, 1192.0, 688.0, 321.0, 685.0], "score": 0.99, "text": " In EMNLP, pp. 4895-4901. Association for Computational Linguistics, 2023."}, {"category_id": 15, "poly": [321.0, 543.0, 716.0, 543.0, 716.0, 573.0, 321.0, 573.0], "score": 0.99, "text": "blob/main/MODEL_CARD.md."}, {"category_id": 15, "poly": [298.0, 513.0, 328.0, 513.0, 328.0, 543.0, 298.0, 543.0], "score": 0.95, "text": "AI"}, {"category_id": 15, "poly": [352.0, 513.0, 1400.0, 513.0, 1400.0, 543.0, 352.0, 543.0], "score": 0.98, "text": "Meta. Llama 3 model card, 2024. URL https: / /github.com/meta-1lama/1lama3/"}, {"category_id": 15, "poly": [296.0, 697.0, 1402.0, 699.0, 1402.0, 738.0, 296.0, 736.0], "score": 0.99, "text": "Chenxin An, Fei Huang, Jun Zhang, Shansan Gong, Xipeng Qiu, Chang Zhou, and Lingpeng Kong."}, {"category_id": 15, "poly": [321.0, 731.0, 1342.0, 731.0, 1342.0, 770.0, 321.0, 770.0], "score": 0.99, "text": "Training-free long-context scaling of large language models. CoRR, abs/2402.17463, 2024."}, {"category_id": 15, "poly": [296.0, 1914.0, 1402.0, 1914.0, 1402.0, 1946.0, 296.0, 1946.0], "score": 0.99, "text": "Federico Cassano, John Gouwar, Daniel Nguyen, Sydney Nguyen, Luna Phipps-Costin, Donald"}, {"category_id": 15, "poly": [319.0, 1939.0, 1407.0, 1941.0, 1407.0, 1980.0, 319.0, 1978.0], "score": 0.99, "text": " Pinckney, Ming-Ho Yee, Yangtian Zi, Carolyn Jane Anderson, Molly Q. Feldman, Arjun Guha,"}, {"category_id": 15, "poly": [326.0, 1973.0, 1407.0, 1975.0, 1407.0, 2008.0, 326.0, 2005.0], "score": 0.99, "text": "Michael Greenberg, and Abhinav Jangda. MultiPL-E: A scalable and polyglot approach to"}, {"category_id": 15, "poly": [328.0, 2005.0, 1342.0, 2005.0, 1342.0, 2037.0, 328.0, 2037.0], "score": 0.99, "text": "benchmarking neural code generation. IEEE Trans. Software Eng., 49(7):3675-3691, 2023."}, {"category_id": 15, "poly": [832.0, 2083.0, 873.0, 2083.0, 873.0, 2129.0, 832.0, 2129.0], "score": 1.0, "text": "20"}, {"category_id": 15, "poly": [296.0, 224.0, 490.0, 229.0, 489.0, 268.0, 295.0, 263.0], "score": 1.0, "text": "REFERENCES"}, {"category_id": 15, "poly": [296.0, 224.0, 490.0, 229.0, 489.0, 268.0, 295.0, 263.0], "score": 1.0, "text": "REFERENCES"}], "page_info": {"page_no": 19, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [298.5601806640625, 230.2724151611328, 1406.7269287109375, 230.2724151611328, 1406.7269287109375, 568.1912231445312, 298.5601806640625, 568.1912231445312], "score": 0.9994937181472778}, {"category_id": 1, "poly": [299.28692626953125, 832.9326171875, 1406.1094970703125, 832.9326171875, 1406.1094970703125, 929.6233520507812, 299.28692626953125, 929.6233520507812], "score": 0.9929582476615906}, {"category_id": 2, "poly": [835.0376586914062, 2088.485595703125, 864.2525024414062, 2088.485595703125, 864.2525024414062, 2112.93603515625, 835.0376586914062, 2112.93603515625], "score": 0.9796991348266602}, {"category_id": 1, "poly": [297.47589111328125, 694.6475830078125, 1406.5322265625, 694.6475830078125, 1406.5322265625, 817.9527587890625, 297.47589111328125, 817.9527587890625], "score": 0.9704327583312988}, {"category_id": 1, "poly": [299.79302978515625, 584.35302734375, 1405.708984375, 584.35302734375, 1405.708984375, 677.5175170898438, 299.79302978515625, 677.5175170898438], "score": 0.9538699984550476}, {"category_id": 1, "poly": [298.89752197265625, 943.1017456054688, 1405.3447265625, 943.1017456054688, 1405.3447265625, 1037.8997802734375, 298.89752197265625, 1037.8997802734375], "score": 0.8401526808738708}, {"category_id": 1, "poly": [289.3221740722656, 283.32525634765625, 1410.1180419921875, 283.32525634765625, 1410.1180419921875, 2037.325927734375, 289.3221740722656, 2037.325927734375], "score": 0.763148307800293}, {"category_id": 1, "poly": [300.072265625, 1051.8199462890625, 1406.0054931640625, 1051.8199462890625, 1406.0054931640625, 1147.59814453125, 300.072265625, 1147.59814453125], "score": 0.6369796991348267}, {"category_id": 1, "poly": [298.96588134765625, 1161.0894775390625, 1408.2880859375, 1161.0894775390625, 1408.2880859375, 1261.0623779296875, 298.96588134765625, 1261.0623779296875], "score": 0.4340144395828247}, {"category_id": 1, "poly": [298.859130859375, 1271.813232421875, 1407.500244140625, 1271.813232421875, 1407.500244140625, 1399.4610595703125, 298.859130859375, 1399.4610595703125], "score": 0.33607110381126404}, {"category_id": 15, "poly": [293.0, 229.0, 1404.0, 231.0, 1404.0, 264.0, 293.0, 261.0], "score": 0.99, "text": " Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pond de Oliveira Pinto, Jared"}, {"category_id": 15, "poly": [323.0, 264.0, 1404.0, 264.0, 1404.0, 296.0, 323.0, 296.0], "score": 0.99, "text": "Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri,"}, {"category_id": 15, "poly": [326.0, 296.0, 1407.0, 296.0, 1407.0, 325.0, 326.0, 325.0], "score": 0.99, "text": "Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,"}, {"category_id": 15, "poly": [323.0, 321.0, 1404.0, 323.0, 1404.0, 355.0, 323.0, 353.0], "score": 1.0, "text": "Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,"}, {"category_id": 15, "poly": [326.0, 355.0, 1402.0, 355.0, 1402.0, 387.0, 326.0, 387.0], "score": 0.99, "text": "Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios"}, {"category_id": 15, "poly": [326.0, 385.0, 1407.0, 385.0, 1407.0, 417.0, 326.0, 417.0], "score": 0.99, "text": "Chantzis, Elizabeth Barnes, Ariel Herbert- Voss, William Hebgen Guss, Alex Nichol, Alex Paino,"}, {"category_id": 15, "poly": [323.0, 412.0, 1407.0, 415.0, 1407.0, 447.0, 323.0, 445.0], "score": 1.0, "text": "Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,"}, {"category_id": 15, "poly": [326.0, 447.0, 1404.0, 447.0, 1404.0, 477.0, 326.0, 477.0], "score": 0.99, "text": "Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa,"}, {"category_id": 15, "poly": [326.0, 477.0, 1402.0, 477.0, 1402.0, 509.0, 326.0, 509.0], "score": 0.99, "text": "Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob"}, {"category_id": 15, "poly": [323.0, 504.0, 1404.0, 509.0, 1404.0, 541.0, 323.0, 536.0], "score": 0.98, "text": "McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating"}, {"category_id": 15, "poly": [319.0, 536.0, 1106.0, 532.0, 1106.0, 568.0, 319.0, 573.0], "score": 0.99, "text": "large language models trained on code. CoRR, abs/2107.03374, 2021."}, {"category_id": 15, "poly": [293.0, 830.0, 1404.0, 832.0, 1404.0, 871.0, 293.0, 869.0], "score": 0.99, "text": "Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng"}, {"category_id": 15, "poly": [323.0, 869.0, 1402.0, 869.0, 1402.0, 898.0, 323.0, 898.0], "score": 1.0, "text": "Li, Hao Zhang, Banghua Zhu, Michael I. Jordan, Joseph E. Gonzalez, and Ion Stoica. Chatbot"}, {"category_id": 15, "poly": [323.0, 898.0, 1404.0, 896.0, 1404.0, 928.0, 323.0, 930.0], "score": 0.99, "text": "arena: An open platform for evaluating LLMs by human preference. CoRR, abs/2403.04132, 2024."}, {"category_id": 15, "poly": [832.0, 2083.0, 868.0, 2083.0, 868.0, 2131.0, 832.0, 2131.0], "score": 1.0, "text": "21"}, {"category_id": 15, "poly": [296.0, 697.0, 1404.0, 697.0, 1404.0, 729.0, 296.0, 729.0], "score": 0.99, "text": "Zhihong Chen, Shuo Yan, Juhao Liang, Feng Jiang, Xiangbo Wu, Fei Yu, Guiming Hardy Chen,"}, {"category_id": 15, "poly": [323.0, 726.0, 1404.0, 726.0, 1404.0, 759.0, 323.0, 759.0], "score": 0.99, "text": "Junying Chen, Hongbo Zhang, Li Jianquan, Wan Xiang, and Benyou Wang. Multilingual-"}, {"category_id": 15, "poly": [326.0, 754.0, 1402.0, 754.0, 1402.0, 786.0, 326.0, 786.0], "score": 0.98, "text": "SIFT: Multilingual supervised instruction fine-tuning, 2023b. URL ht tps : / /github . com/"}, {"category_id": 15, "poly": [326.0, 788.0, 935.0, 788.0, 935.0, 820.0, 326.0, 820.0], "score": 1.0, "text": "FreedomIntelligence/MultilingualSIFT."}, {"category_id": 15, "poly": [296.0, 587.0, 1402.0, 587.0, 1402.0, 619.0, 296.0, 619.0], "score": 0.99, "text": "Wenhu Chen, Ming Yin, Max Ku, Pan Lu, Yixin Wan, Xueguang Ma, Jianyu Xu, Xinyi Wang, and"}, {"category_id": 15, "poly": [326.0, 619.0, 1404.0, 619.0, 1404.0, 649.0, 326.0, 649.0], "score": 0.99, "text": "Tony Xia. TheoremQA: A theorem-driven question answering dataset. In EMNLP, pp. 7889-7901."}, {"category_id": 15, "poly": [326.0, 649.0, 887.0, 649.0, 887.0, 681.0, 326.0, 681.0], "score": 0.99, "text": "Association for Computational Linguistics, 2023a."}, {"category_id": 15, "poly": [293.0, 940.0, 1404.0, 942.0, 1404.0, 981.0, 293.0, 979.0], "score": 0.97, "text": " Yunfei Chu, Jin Xu, Xiaohuan Zhou, Qian Yang, Shiliang Zhang, Zhijie Yan, Chang Zhou, and"}, {"category_id": 15, "poly": [321.0, 979.0, 1402.0, 979.0, 1402.0, 1008.0, 321.0, 1008.0], "score": 0.99, "text": " Jingren Zhou. Qwen-Audio: Advancing universal audio understanding via unified large-scale"}, {"category_id": 15, "poly": [326.0, 1008.0, 935.0, 1008.0, 935.0, 1040.0, 326.0, 1040.0], "score": 1.0, "text": "audio-language models. CoRR, abs/2311.07919, 2023."}, {"category_id": 15, "poly": [328.0, 296.0, 1402.0, 296.0, 1402.0, 328.0, 328.0, 328.0], "score": 1.0, "text": "Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,"}, {"category_id": 15, "poly": [328.0, 325.0, 1402.0, 325.0, 1402.0, 355.0, 328.0, 355.0], "score": 0.99, "text": "Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,"}, {"category_id": 15, "poly": [326.0, 353.0, 1404.0, 353.0, 1404.0, 392.0, 326.0, 392.0], "score": 0.99, "text": "Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios"}, {"category_id": 15, "poly": [328.0, 387.0, 1402.0, 387.0, 1402.0, 417.0, 328.0, 417.0], "score": 0.99, "text": "Chantzis, Elizabeth Barnes, Ariel Herbert- Voss, William Hebgen Guss, Alex Nichol, Alex Paino,"}, {"category_id": 15, "poly": [326.0, 417.0, 1402.0, 417.0, 1402.0, 449.0, 326.0, 449.0], "score": 1.0, "text": "Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,"}, {"category_id": 15, "poly": [323.0, 445.0, 1402.0, 447.0, 1402.0, 479.0, 323.0, 477.0], "score": 1.0, "text": "Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa,"}, {"category_id": 15, "poly": [326.0, 479.0, 1402.0, 479.0, 1402.0, 509.0, 326.0, 509.0], "score": 0.99, "text": "Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob"}, {"category_id": 15, "poly": [326.0, 504.0, 1402.0, 509.0, 1402.0, 541.0, 326.0, 536.0], "score": 0.99, "text": "McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating"}, {"category_id": 15, "poly": [321.0, 536.0, 1109.0, 532.0, 1109.0, 571.0, 321.0, 575.0], "score": 0.99, "text": "large language models trained on code. CoRR, abs/2107.03374, 2021."}, {"category_id": 15, "poly": [293.0, 582.0, 1404.0, 584.0, 1404.0, 623.0, 293.0, 621.0], "score": 0.98, "text": "Wenhu Chen, Ming Yin, Max Ku, Pan Lu, Yixin Wan, Xueguang Ma, Jianyu Xu, Xinyi Wang, and"}, {"category_id": 15, "poly": [328.0, 619.0, 1404.0, 619.0, 1404.0, 651.0, 328.0, 651.0], "score": 0.99, "text": "Tony Xia. TheoremQA: A theorem-driven question answering dataset. In EMNLP, pp. 7889-7901."}, {"category_id": 15, "poly": [323.0, 646.0, 885.0, 646.0, 885.0, 678.0, 323.0, 678.0], "score": 1.0, "text": "Association for Computational Linguistics, 2023a."}, {"category_id": 15, "poly": [298.0, 697.0, 1404.0, 697.0, 1404.0, 729.0, 298.0, 729.0], "score": 0.99, "text": "Zhihong Chen, Shuo Yan, Juhao Liang, Feng Jiang, Xiangbo Wu, Fei Yu, Guiming Hardy Chen,"}, {"category_id": 15, "poly": [321.0, 724.0, 1404.0, 722.0, 1404.0, 761.0, 321.0, 763.0], "score": 0.98, "text": " Junying Chen, Hongbo Zhang, Li Jianquan, Wan Xiang, and Benyou Wang. Multilingual-"}, {"category_id": 15, "poly": [326.0, 759.0, 1402.0, 759.0, 1402.0, 791.0, 326.0, 791.0], "score": 0.97, "text": "SIFT: Multilingual supervised instruction fine-tuning, 2023b. URL ht tps : / / github . com/"}, {"category_id": 15, "poly": [323.0, 791.0, 933.0, 791.0, 933.0, 820.0, 323.0, 820.0], "score": 1.0, "text": "FreedomIntelligence/MultilingualSIFT."}, {"category_id": 15, "poly": [300.0, 836.0, 1402.0, 836.0, 1402.0, 869.0, 300.0, 869.0], "score": 1.0, "text": "Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng"}, {"category_id": 15, "poly": [326.0, 869.0, 1402.0, 869.0, 1402.0, 901.0, 326.0, 901.0], "score": 0.99, "text": "Li, Hao Zhang, Banghua Zhu, Michael I. Jordan, Joseph E. Gonzalez, and Ion Stoica. Chatbot"}, {"category_id": 15, "poly": [321.0, 896.0, 1407.0, 894.0, 1407.0, 933.0, 321.0, 935.0], "score": 0.99, "text": "arena: An open platform for evaluating LLMs by human preference. CoRR, abs/2403.04132, 2024."}, {"category_id": 15, "poly": [296.0, 942.0, 1404.0, 944.0, 1404.0, 983.0, 296.0, 981.0], "score": 0.98, "text": "Yunfei Chu, Jin Xu, Xiaohuan Zhou, Qian Yang, Shiliang Zhang, Zhijie Yan, Chang Zhou, and"}, {"category_id": 15, "poly": [323.0, 979.0, 1402.0, 979.0, 1402.0, 1011.0, 323.0, 1011.0], "score": 0.99, "text": "Jingren Zhou. Qwen-Audio: Advancing universal audio understanding via unified large-scale"}, {"category_id": 15, "poly": [326.0, 1008.0, 935.0, 1008.0, 935.0, 1040.0, 326.0, 1040.0], "score": 1.0, "text": "audio-language models. CoRR, abs/2311.07919, 2023."}, {"category_id": 15, "poly": [298.0, 1056.0, 1402.0, 1056.0, 1402.0, 1086.0, 298.0, 1086.0], "score": 0.99, "text": "Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and"}, {"category_id": 15, "poly": [321.0, 1082.0, 1407.0, 1086.0, 1407.0, 1125.0, 321.0, 1121.0], "score": 0.99, "text": " Oyvind Tafjord. Think you have solved question answering? Try ARC, the AI2 reasoning challenge."}, {"category_id": 15, "poly": [326.0, 1118.0, 658.0, 1118.0, 658.0, 1148.0, 326.0, 1148.0], "score": 1.0, "text": "CoRR, abs/1803.05457, 2018."}, {"category_id": 15, "poly": [296.0, 1164.0, 1402.0, 1166.0, 1402.0, 1199.0, 296.0, 1196.0], "score": 0.99, "text": "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,"}, {"category_id": 15, "poly": [321.0, 1194.0, 1402.0, 1196.0, 1402.0, 1228.0, 321.0, 1226.0], "score": 1.0, "text": " Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John"}, {"category_id": 15, "poly": [326.0, 1228.0, 1326.0, 1228.0, 1326.0, 1260.0, 326.0, 1260.0], "score": 0.99, "text": "Schulman. Training verifiers to solve math word problems. CoRR, abs/2110.14168, 2021."}, {"category_id": 15, "poly": [293.0, 1270.0, 1404.0, 1272.0, 1404.0, 1311.0, 293.0, 1309.0], "score": 0.98, "text": " Damai Dai, Chengqi Deng, Chenggang Zhao, R. X. Xu, Huazuo Gao, Deli Chen, Jiashi Li, Wangding"}, {"category_id": 15, "poly": [323.0, 1306.0, 1402.0, 1306.0, 1402.0, 1338.0, 323.0, 1338.0], "score": 1.0, "text": "Zeng, Xingkai Yu, Y. Wu, Zhenda Xie, Y. K. Li, Panpan Huang, Fuli Luo, Chong Ruan, Zhifang Sui,"}, {"category_id": 15, "poly": [321.0, 1331.0, 1404.0, 1334.0, 1404.0, 1373.0, 321.0, 1370.0], "score": 0.99, "text": " and Wenfeng Liang. DeepSeekMoE: Towards ultimate expert specialization in mixture-of-experts"}, {"category_id": 15, "poly": [326.0, 1368.0, 866.0, 1368.0, 866.0, 1400.0, 326.0, 1400.0], "score": 0.99, "text": "language models. CoRR, abs/2401.06066, 2024."}, {"category_id": 15, "poly": [300.0, 1416.0, 1402.0, 1416.0, 1402.0, 1448.0, 300.0, 1448.0], "score": 0.98, "text": "Yann N. Dauphin, Angela Fan, Michael Auli, and David Grangier. Language modeling with gated"}, {"category_id": 15, "poly": [323.0, 1441.0, 1407.0, 1444.0, 1407.0, 1483.0, 323.0, 1480.0], "score": 0.99, "text": "convolutional networks. In ICML, volume 70 of Proceedings of Machine Learning Research, pp."}, {"category_id": 15, "poly": [326.0, 1478.0, 591.0, 1478.0, 591.0, 1508.0, 326.0, 1508.0], "score": 0.99, "text": "933-941. PMLR, 2017."}, {"category_id": 15, "poly": [300.0, 1526.0, 1402.0, 1526.0, 1402.0, 1558.0, 300.0, 1558.0], "score": 0.98, "text": "Guanting Dong, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang,"}, {"category_id": 15, "poly": [321.0, 1551.0, 1404.0, 1554.0, 1404.0, 1593.0, 321.0, 1590.0], "score": 0.98, "text": " Zheng Yuan, Chang Zhou, and Jingren Zhou. How abilities in large language models are affected"}, {"category_id": 15, "poly": [321.0, 1584.0, 1159.0, 1581.0, 1160.0, 1620.0, 321.0, 1623.0], "score": 1.0, "text": "by supervised fine-tuning data composition. CoRR, abs/2310.05492, 2023."}, {"category_id": 15, "poly": [300.0, 1636.0, 1402.0, 1636.0, 1402.0, 1668.0, 300.0, 1668.0], "score": 0.99, "text": "Guanting Dong, Keming Lu, Chengpeng Li, Tingyu Xia, Bowen Yu, Chang Zhou, and Jingren Zhou."}, {"category_id": 15, "poly": [323.0, 1664.0, 1402.0, 1668.0, 1402.0, 1700.0, 323.0, 1696.0], "score": 0.99, "text": " Self-play with execution feedback: Improving instruction-following capabilities of large language"}, {"category_id": 15, "poly": [326.0, 1696.0, 760.0, 1696.0, 760.0, 1726.0, 326.0, 1726.0], "score": 1.0, "text": "models. CoRR, abs/2406.13542, 2024."}, {"category_id": 15, "poly": [293.0, 1739.0, 1407.0, 1742.0, 1407.0, 1781.0, 293.0, 1778.0], "score": 0.99, "text": " Alena Fenogenova, Artem Chervyakov, Nikita Martynov, Anastasia Kozlova, Maria Tikhonova, Al-"}, {"category_id": 15, "poly": [326.0, 1776.0, 1402.0, 1776.0, 1402.0, 1808.0, 326.0, 1808.0], "score": 1.0, "text": "bina Akhmetgareeva, Anton A. Emelyanov, Denis Shevelev, Pavel Lebedev, Leonid Sinev, Ulyana"}, {"category_id": 15, "poly": [328.0, 1806.0, 1404.0, 1806.0, 1404.0, 1838.0, 328.0, 1838.0], "score": 1.0, "text": "Isaeva, Katerina Kolomeytseva, Daniil Moskovskiy, Elizaveta Goncharova, Nikita Savushkin,"}, {"category_id": 15, "poly": [326.0, 1836.0, 1404.0, 1836.0, 1404.0, 1868.0, 326.0, 1868.0], "score": 0.99, "text": "Polina Mikhailova, Denis Dimitrov, Alexander Panchenko, and Sergey Markov. MERA: A com-"}, {"category_id": 15, "poly": [321.0, 1865.0, 1097.0, 1863.0, 1097.0, 1897.0, 321.0, 1900.0], "score": 0.99, "text": " prehensive LLM evaluation in russian. CoRR, abs/2401.04531, 2024."}, {"category_id": 15, "poly": [298.0, 1916.0, 1402.0, 1916.0, 1402.0, 1948.0, 298.0, 1948.0], "score": 1.0, "text": "Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen, Guillaume Wenzek, Da Ju, Sanjana"}, {"category_id": 15, "poly": [326.0, 1946.0, 1400.0, 1946.0, 1400.0, 1978.0, 326.0, 1978.0], "score": 0.99, "text": "Krishnan, Marc'Aurelio Ranzato, Francisco Guzman, and Angela Fan. The Flores-101 evalua-"}, {"category_id": 15, "poly": [326.0, 1975.0, 1402.0, 1978.0, 1402.0, 2010.0, 326.0, 2007.0], "score": 0.99, "text": "tion benchmark for low-resource and multilingual machine translation. Trans. Assoc. Comput."}, {"category_id": 15, "poly": [326.0, 2008.0, 668.0, 2008.0, 668.0, 2037.0, 326.0, 2037.0], "score": 1.0, "text": "Linguistics,10:522-538,2022."}, {"category_id": 15, "poly": [296.0, 1054.0, 1402.0, 1054.0, 1402.0, 1086.0, 296.0, 1086.0], "score": 0.99, "text": "Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and"}, {"category_id": 15, "poly": [321.0, 1084.0, 1402.0, 1089.0, 1402.0, 1121.0, 321.0, 1116.0], "score": 0.97, "text": " Oyvind Tafjord. Think you have solved question answering? Try ARC, the AI2 reasoning challenge."}, {"category_id": 15, "poly": [326.0, 1116.0, 661.0, 1116.0, 661.0, 1146.0, 326.0, 1146.0], "score": 0.98, "text": "CoRR, abs/1803.05457, 2018."}, {"category_id": 15, "poly": [293.0, 1162.0, 1402.0, 1164.0, 1402.0, 1196.0, 293.0, 1194.0], "score": 0.99, "text": " Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,"}, {"category_id": 15, "poly": [323.0, 1196.0, 1404.0, 1196.0, 1404.0, 1226.0, 323.0, 1226.0], "score": 0.99, "text": "Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John"}, {"category_id": 15, "poly": [326.0, 1226.0, 1330.0, 1226.0, 1330.0, 1258.0, 326.0, 1258.0], "score": 0.99, "text": "Schulman. Training verifiers to solve math word problems. CoRR, abs/2110.14168, 2021."}, {"category_id": 15, "poly": [293.0, 1267.0, 1404.0, 1272.0, 1404.0, 1311.0, 293.0, 1306.0], "score": 0.99, "text": " Damai Dai, Chengqi Deng, Chenggang Zhao, R. X. Xu, Huazuo Gao, Deli Chen, Jiashi Li, Wangding"}, {"category_id": 15, "poly": [321.0, 1306.0, 1402.0, 1306.0, 1402.0, 1338.0, 321.0, 1338.0], "score": 0.98, "text": " Zeng, Xingkai Yu, Y. Wu, Zhenda Xie, Y. K. Li, Panpan Huang, Fuli Luo, Chong Ruan, Zhifang Sui,"}, {"category_id": 15, "poly": [326.0, 1336.0, 1402.0, 1336.0, 1402.0, 1368.0, 326.0, 1368.0], "score": 0.99, "text": "and Wenfeng Liang. DeepSeekMoE: Towards ultimate expert specialization in mixture-of-experts"}, {"category_id": 15, "poly": [323.0, 1364.0, 862.0, 1364.0, 862.0, 1396.0, 323.0, 1396.0], "score": 0.99, "text": "language models. CoRR, abs/2401.06066, 2024."}], "page_info": {"page_no": 20, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 2, "poly": [834.9259643554688, 2088.591796875, 865.712158203125, 2088.591796875, 865.712158203125, 2113.001708984375, 834.9259643554688, 2113.001708984375], "score": 0.9966014623641968}, {"category_id": 1, "poly": [296.1600036621094, 1020.4118041992188, 1405.87060546875, 1020.4118041992188, 1405.87060546875, 1085.64453125, 296.1600036621094, 1085.64453125], "score": 0.9383645057678223}, {"category_id": 1, "poly": [299.749755859375, 675.5972900390625, 1406.5693359375, 675.5972900390625, 1406.5693359375, 801.8588256835938, 299.749755859375, 801.8588256835938], "score": 0.8876067996025085}, {"category_id": 1, "poly": [287.7336120605469, 213.2496795654297, 1413.602783203125, 213.2496795654297, 1413.602783203125, 2046.28515625, 287.7336120605469, 2046.28515625], "score": 0.866904616355896}, {"category_id": 1, "poly": [301.5555725097656, 815.7545776367188, 1406.943603515625, 815.7545776367188, 1406.943603515625, 1003.2977905273438, 301.5555725097656, 1003.2977905273438], "score": 0.8661991357803345}, {"category_id": 1, "poly": [294.0732727050781, 1102.0841064453125, 1409.158203125, 1102.0841064453125, 1409.158203125, 1165.9578857421875, 294.0732727050781, 1165.9578857421875], "score": 0.812579870223999}, {"category_id": 1, "poly": [297.3699645996094, 1181.5283203125, 1408.6693115234375, 1181.5283203125, 1408.6693115234375, 1279.51806640625, 297.3699645996094, 1279.51806640625], "score": 0.7005175948143005}, {"category_id": 1, "poly": [297.472900390625, 563.7633666992188, 1405.512451171875, 563.7633666992188, 1405.512451171875, 659.9409790039062, 297.472900390625, 659.9409790039062], "score": 0.6844541430473328}, {"category_id": 1, "poly": [298.2298278808594, 1292.838623046875, 1407.150146484375, 1292.838623046875, 1407.150146484375, 1390.795166015625, 298.2298278808594, 1390.795166015625], "score": 0.5384101867675781}, {"category_id": 1, "poly": [300.604248046875, 454.127685546875, 1405.8072509765625, 454.127685546875, 1405.8072509765625, 548.5308227539062, 300.604248046875, 548.5308227539062], "score": 0.45660316944122314}, {"category_id": 1, "poly": [299.1377258300781, 230.2644805908203, 1404.671142578125, 230.2644805908203, 1404.671142578125, 325.4410095214844, 299.1377258300781, 325.4410095214844], "score": 0.32242047786712646}, {"category_id": 1, "poly": [302.05999755859375, 340.87164306640625, 1405.1514892578125, 340.87164306640625, 1405.1514892578125, 436.227294921875, 302.05999755859375, 436.227294921875], "score": 0.29892534017562866}, {"category_id": 1, "poly": [298.34033203125, 1404.2191162109375, 1406.8138427734375, 1404.2191162109375, 1406.8138427734375, 1501.4547119140625, 298.34033203125, 1501.4547119140625], "score": 0.2960136830806732}, {"category_id": 15, "poly": [832.0, 2083.0, 871.0, 2083.0, 871.0, 2131.0, 832.0, 2131.0], "score": 1.0, "text": "22"}, {"category_id": 15, "poly": [296.0, 1020.0, 1402.0, 1022.0, 1402.0, 1054.0, 296.0, 1052.0], "score": 1.0, "text": "Zixuan Jiang, Jiaqi Gu, Hanqing Zhu, and David Z. Pan. Pre-RMSNorm and Pre-CRMSNorm"}, {"category_id": 15, "poly": [321.0, 1054.0, 1356.0, 1054.0, 1356.0, 1086.0, 321.0, 1086.0], "score": 0.99, "text": "Transformers: Equivalent and efficient pre-LN Transformers. CoRR, abs/2305.14858, 2023b."}, {"category_id": 15, "poly": [296.0, 676.0, 1404.0, 678.0, 1404.0, 710.0, 296.0, 708.0], "score": 1.0, "text": "Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot,"}, {"category_id": 15, "poly": [326.0, 710.0, 1404.0, 710.0, 1404.0, 740.0, 326.0, 740.0], "score": 0.99, "text": "Diego de Las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier,"}, {"category_id": 15, "poly": [326.0, 740.0, 1402.0, 740.0, 1402.0, 770.0, 326.0, 770.0], "score": 0.99, "text": "Llio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas"}, {"category_id": 15, "poly": [326.0, 770.0, 1358.0, 770.0, 1358.0, 802.0, 326.0, 802.0], "score": 0.99, "text": "Wang, Timothe Lacroix, and William E1 Sayed. Mistral 7B. CoRR, abs/2310.06825, 2023a."}, {"category_id": 15, "poly": [296.0, 231.0, 1402.0, 234.0, 1402.0, 266.0, 296.0, 264.0], "score": 0.99, "text": "Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob"}, {"category_id": 15, "poly": [321.0, 261.0, 1404.0, 264.0, 1404.0, 303.0, 321.0, 300.0], "score": 0.98, "text": " Steinhardt. Measuring massive multitask language understanding. In ICLR. OpenReview.net,"}, {"category_id": 15, "poly": [323.0, 296.0, 404.0, 296.0, 404.0, 328.0, 323.0, 328.0], "score": 1.0, "text": "2021a."}, {"category_id": 15, "poly": [296.0, 344.0, 1402.0, 346.0, 1402.0, 378.0, 296.0, 376.0], "score": 0.99, "text": "Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song,"}, {"category_id": 15, "poly": [323.0, 371.0, 1404.0, 374.0, 1404.0, 413.0, 323.0, 410.0], "score": 0.99, "text": "and Jacob Steinhardt. Measuring mathematical problem solving with the MATH dataset. In"}, {"category_id": 15, "poly": [323.0, 403.0, 808.0, 406.0, 808.0, 438.0, 323.0, 435.0], "score": 0.99, "text": "NeurIPS Datasets and Benchmarks, 2021b."}, {"category_id": 15, "poly": [300.0, 458.0, 1402.0, 458.0, 1402.0, 490.0, 300.0, 490.0], "score": 1.0, "text": "Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu,"}, {"category_id": 15, "poly": [328.0, 488.0, 1404.0, 488.0, 1404.0, 520.0, 328.0, 520.0], "score": 1.0, "text": "Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, and Junxian He. C-Eval: A"}, {"category_id": 15, "poly": [326.0, 518.0, 1370.0, 516.0, 1370.0, 548.0, 326.0, 550.0], "score": 0.98, "text": "multi-level multi-discipline chinese evaluation suite for foundation models. In NeurIPS, 2023."}, {"category_id": 15, "poly": [298.0, 568.0, 1400.0, 568.0, 1400.0, 600.0, 298.0, 600.0], "score": 0.99, "text": "Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando"}, {"category_id": 15, "poly": [326.0, 598.0, 1402.0, 600.0, 1402.0, 633.0, 326.0, 630.0], "score": 0.99, "text": "Solar-Lezama, Koushik Sen, and Ion Stoica. LiveCodeBench: Holistic and contamination free"}, {"category_id": 15, "poly": [326.0, 628.0, 1178.0, 628.0, 1178.0, 667.0, 326.0, 667.0], "score": 0.99, "text": "evaluation of large language models for code. CoRR, abs/2403.07974, 2024."}, {"category_id": 15, "poly": [300.0, 681.0, 1402.0, 681.0, 1402.0, 713.0, 300.0, 713.0], "score": 1.0, "text": "Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot,"}, {"category_id": 15, "poly": [328.0, 713.0, 1402.0, 713.0, 1402.0, 742.0, 328.0, 742.0], "score": 0.99, "text": "Diego de Las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier,"}, {"category_id": 15, "poly": [328.0, 740.0, 1402.0, 740.0, 1402.0, 772.0, 328.0, 772.0], "score": 0.99, "text": "Llio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas"}, {"category_id": 15, "poly": [326.0, 772.0, 1354.0, 772.0, 1354.0, 802.0, 326.0, 802.0], "score": 0.99, "text": "Wang, Timothe Lacroix, and William El Sayed. Mistral 7B. CoRR, abs/2310.06825, 2023a."}, {"category_id": 15, "poly": [298.0, 818.0, 1400.0, 820.0, 1400.0, 853.0, 298.0, 850.0], "score": 0.99, "text": "Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris"}, {"category_id": 15, "poly": [323.0, 850.0, 1402.0, 853.0, 1402.0, 885.0, 323.0, 882.0], "score": 0.99, "text": "Bamford, Devendra Singh Chaplot, Diego de Las Casas, Emma Bou Hanna, Florian Bressand,"}, {"category_id": 15, "poly": [326.0, 880.0, 1402.0, 882.0, 1402.0, 914.0, 326.0, 912.0], "score": 0.99, "text": "Gianna Lengyel, Guillaume Bour, Guillaume Lample, Llio Renard Lavaud, Lucile Saulnier, Marie-"}, {"category_id": 15, "poly": [328.0, 914.0, 1402.0, 914.0, 1402.0, 946.0, 328.0, 946.0], "score": 0.99, "text": "Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le"}, {"category_id": 15, "poly": [326.0, 944.0, 1404.0, 944.0, 1404.0, 976.0, 326.0, 976.0], "score": 0.98, "text": "Scao, Thophile Gervet, Thibaut Lavril, Thomas Wang, Timothe Lacroix, and William El Sayed."}, {"category_id": 15, "poly": [323.0, 972.0, 878.0, 974.0, 878.0, 1006.0, 323.0, 1004.0], "score": 0.99, "text": "Mixtral of experts. CoRR, abs/2401.04088, 2024."}, {"category_id": 15, "poly": [296.0, 1022.0, 1402.0, 1024.0, 1402.0, 1056.0, 296.0, 1054.0], "score": 1.0, "text": "Zixuan Jiang, Jiaqi Gu, Hanqing Zhu, and David Z. Pan. Pre-RMSNorm and Pre-CRMSNorm"}, {"category_id": 15, "poly": [328.0, 1056.0, 1358.0, 1056.0, 1358.0, 1089.0, 328.0, 1089.0], "score": 0.99, "text": "Transformers: Equivalent and efficient pre-LN Transformers. CoRR, abs/2305.14858, 2023b."}, {"category_id": 15, "poly": [300.0, 1105.0, 1407.0, 1105.0, 1407.0, 1137.0, 300.0, 1137.0], "score": 0.99, "text": "Gregory Kamradt. Needle in a haystack - pressure testing LLMs, 2023. URL ht tps : / / github ."}, {"category_id": 15, "poly": [323.0, 1134.0, 968.0, 1137.0, 968.0, 1169.0, 323.0, 1166.0], "score": 0.98, "text": "Com/ gkamradt /LLMTest_NeedleInAHaystack."}, {"category_id": 15, "poly": [300.0, 1187.0, 1402.0, 1187.0, 1402.0, 1219.0, 300.0, 1219.0], "score": 0.99, "text": "Aran Komatsuzaki, Joan Puigcerver, James Lee-Thorp, Carlos Riquelme Ruiz, Basil Mustafa, Joshua"}, {"category_id": 15, "poly": [321.0, 1210.0, 1404.0, 1215.0, 1404.0, 1254.0, 321.0, 1249.0], "score": 0.99, "text": "Ainslie, Yi Tay, Mostafa Dehghani, and Neil Houlsby. Sparse upcycling: Training mixture-of-"}, {"category_id": 15, "poly": [326.0, 1249.0, 1056.0, 1247.0, 1056.0, 1279.0, 326.0, 1281.0], "score": 0.99, "text": "experts from dense checkpoints. In ICLR. OpenReview.net, 2023."}, {"category_id": 15, "poly": [298.0, 1297.0, 1402.0, 1297.0, 1402.0, 1329.0, 298.0, 1329.0], "score": 1.0, "text": "Fajri Koto, Nurul Aisyah, Haonan Li, and Timothy Baldwin. Large language models only pass"}, {"category_id": 15, "poly": [323.0, 1325.0, 1407.0, 1327.0, 1407.0, 1366.0, 323.0, 1364.0], "score": 0.99, "text": "primary school exams in Indonesia: A comprehensive test on IndoMMLU. In EMNLP, pPp."}, {"category_id": 15, "poly": [323.0, 1357.0, 1039.0, 1359.0, 1039.0, 1391.0, 323.0, 1389.0], "score": 0.99, "text": "12359-12374. Association for Computational Linguistics, 2023."}, {"category_id": 15, "poly": [298.0, 1409.0, 1400.0, 1409.0, 1400.0, 1441.0, 298.0, 1441.0], "score": 1.0, "text": "Haonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang, Hai Zhao, Yeyun Gong, Nan Duan, and Timothy"}, {"category_id": 15, "poly": [321.0, 1435.0, 1404.0, 1437.0, 1404.0, 1476.0, 321.0, 1474.0], "score": 0.99, "text": " Baldwin. CMMLU: Measuring massive multitask language understanding in Chinese. CoRR,"}, {"category_id": 15, "poly": [326.0, 1471.0, 580.0, 1471.0, 580.0, 1501.0, 326.0, 1501.0], "score": 1.0, "text": "abs/2306.09212, 2023."}, {"category_id": 15, "poly": [296.0, 1517.0, 1402.0, 1519.0, 1402.0, 1551.0, 296.0, 1549.0], "score": 0.99, "text": "Tianle Li, Wei-Lin Chiang, Evan Frick, Lisa Dunlap, Tianhao Wu, Banghua Zhu, Joseph E. Gon-"}, {"category_id": 15, "poly": [328.0, 1554.0, 1402.0, 1554.0, 1402.0, 1584.0, 328.0, 1584.0], "score": 1.0, "text": "zalez, and Ion Stoica. From crowdsourced data to high-quality benchmarks: Arena-Hard and"}, {"category_id": 15, "poly": [321.0, 1577.0, 931.0, 1579.0, 931.0, 1618.0, 321.0, 1616.0], "score": 0.98, "text": " BenchBuilder pipeline. CoRR, abs/2406.11939, 2024."}, {"category_id": 15, "poly": [300.0, 1632.0, 1402.0, 1632.0, 1402.0, 1664.0, 300.0, 1664.0], "score": 1.0, "text": "Opher Lieber, Barak Lenz, Hofit Bata, Gal Cohen, Jhonathan Osin, Itay Dalmedigos, Erez Safahi,"}, {"category_id": 15, "poly": [328.0, 1664.0, 1402.0, 1664.0, 1402.0, 1694.0, 328.0, 1694.0], "score": 0.98, "text": "Shaked Meirom, Yonatan Belinkov, Shai Shalev-Shwartz, Omri Abend, Raz Alon, Tomer Asida,"}, {"category_id": 15, "poly": [328.0, 1694.0, 1402.0, 1694.0, 1402.0, 1726.0, 328.0, 1726.0], "score": 1.0, "text": "Amir Bergman, Roman Glozman, Michael Gokhman, Avashalom Manevich, Nir Ratner, Noam"}, {"category_id": 15, "poly": [326.0, 1726.0, 1402.0, 1726.0, 1402.0, 1755.0, 326.0, 1755.0], "score": 1.0, "text": "Rozen, Erez Shwartz, Mor Zusman, and Yoav Shoham. Jamba: A hybrid Transformer-Mamba"}, {"category_id": 15, "poly": [326.0, 1755.0, 852.0, 1755.0, 852.0, 1787.0, 326.0, 1787.0], "score": 0.99, "text": "language model. CoRR, abs/2403.19887, 2024."}, {"category_id": 15, "poly": [300.0, 1804.0, 1402.0, 1804.0, 1402.0, 1836.0, 300.0, 1836.0], "score": 0.98, "text": "Stephanie Lin, Jacob Hilton, and Owain Evans. TruthfulQA: Measuring how models mimic human"}, {"category_id": 15, "poly": [321.0, 1829.0, 1337.0, 1831.0, 1337.0, 1870.0, 321.0, 1868.0], "score": 0.99, "text": "falsehoods. In ACL (1), pp. 3214-3252. Association for Computational Linguistics, 2022a."}, {"category_id": 15, "poly": [296.0, 1881.0, 1402.0, 1884.0, 1402.0, 1916.0, 296.0, 1914.0], "score": 1.0, "text": "Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott,"}, {"category_id": 15, "poly": [323.0, 1914.0, 1402.0, 1916.0, 1402.0, 1948.0, 323.0, 1946.0], "score": 0.98, "text": "Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura,"}, {"category_id": 15, "poly": [326.0, 1946.0, 1402.0, 1946.0, 1402.0, 1978.0, 326.0, 1978.0], "score": 0.99, "text": "Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona T."}, {"category_id": 15, "poly": [323.0, 1973.0, 1404.0, 1975.0, 1404.0, 2014.0, 323.0, 2012.0], "score": 0.99, "text": "Diab, Veselin Stoyanov, and Xian Li. Few-shot learning with multilingual generative language"}, {"category_id": 15, "poly": [328.0, 2008.0, 1296.0, 2008.0, 1296.0, 2040.0, 328.0, 2040.0], "score": 0.99, "text": "models. In EMNLP, pp. 9019-9052. Association for Computational Linguistics, 2022b"}, {"category_id": 15, "poly": [298.0, 820.0, 1402.0, 820.0, 1402.0, 852.0, 298.0, 852.0], "score": 0.99, "text": "Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris"}, {"category_id": 15, "poly": [323.0, 852.0, 1402.0, 852.0, 1402.0, 885.0, 323.0, 885.0], "score": 1.0, "text": "Bamford, Devendra Singh Chaplot, Diego de Las Casas, Emma Bou Hanna, Florian Bressand,"}, {"category_id": 15, "poly": [328.0, 882.0, 1407.0, 882.0, 1407.0, 914.0, 328.0, 914.0], "score": 0.99, "text": "Gianna Lengyel, Guillaume Bour, Guillaume Lample, Llio Renard Lavaud, Lucile Saulnier, Marie-"}, {"category_id": 15, "poly": [326.0, 912.0, 1402.0, 912.0, 1402.0, 944.0, 326.0, 944.0], "score": 0.99, "text": "Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le"}, {"category_id": 15, "poly": [323.0, 942.0, 1402.0, 942.0, 1402.0, 974.0, 323.0, 974.0], "score": 0.99, "text": "Scao, Thophile Gervet, Thibaut Lavril, Thomas Wang, Timothe Lacroix, and William El Sayed."}, {"category_id": 15, "poly": [326.0, 974.0, 878.0, 974.0, 878.0, 1006.0, 326.0, 1006.0], "score": 0.99, "text": "Mixtral of experts. CoRR, abs/2401.04088, 2024."}, {"category_id": 15, "poly": [298.0, 1105.0, 1407.0, 1105.0, 1407.0, 1137.0, 298.0, 1137.0], "score": 0.98, "text": "Gregory Kamradt. Needle in a haystack - pressure testing LLMs, 2023. URL ht tps : / / github ."}, {"category_id": 15, "poly": [323.0, 1137.0, 965.0, 1137.0, 965.0, 1169.0, 323.0, 1169.0], "score": 0.99, "text": "Com/gkamradt /LLMTest_NeedleInAHaystack."}, {"category_id": 15, "poly": [298.0, 1185.0, 1402.0, 1185.0, 1402.0, 1217.0, 298.0, 1217.0], "score": 1.0, "text": "Aran Komatsuzaki, Joan Puigcerver, James Lee-Thorp, Carlos Riquelme Ruiz, Basil Mustafa, Joshua"}, {"category_id": 15, "poly": [321.0, 1217.0, 1402.0, 1217.0, 1402.0, 1249.0, 321.0, 1249.0], "score": 0.99, "text": "Ainslie, Yi Tay, Mostafa Dehghani, and Neil Houlsby. Sparse upcycling: Training mixture-of-"}, {"category_id": 15, "poly": [321.0, 1244.0, 1058.0, 1242.0, 1058.0, 1281.0, 321.0, 1283.0], "score": 0.99, "text": "experts from dense checkpoints. In ICLR. OpenReview.net, 2023."}, {"category_id": 15, "poly": [296.0, 568.0, 1402.0, 568.0, 1402.0, 600.0, 296.0, 600.0], "score": 1.0, "text": "Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando"}, {"category_id": 15, "poly": [326.0, 598.0, 1404.0, 598.0, 1404.0, 630.0, 326.0, 630.0], "score": 0.99, "text": "Solar-Lezama, Koushik Sen, and Ion Stoica. LiveCodeBench: Holistic and contamination free"}, {"category_id": 15, "poly": [326.0, 630.0, 1176.0, 630.0, 1176.0, 662.0, 326.0, 662.0], "score": 1.0, "text": "evaluation of large language models for code. CoRR, abs/2403.07974, 2024."}, {"category_id": 15, "poly": [296.0, 1297.0, 1402.0, 1297.0, 1402.0, 1327.0, 296.0, 1327.0], "score": 1.0, "text": "Fajri Koto, Nurul Aisyah, Haonan Li, and Timothy Baldwin. Large language models only pass"}, {"category_id": 15, "poly": [319.0, 1318.0, 1411.0, 1322.0, 1411.0, 1368.0, 319.0, 1363.0], "score": 0.99, "text": "primary school exams in Indonesia: A comprehensive test on IndoMMLU. In EMNLP, p."}, {"category_id": 15, "poly": [326.0, 1354.0, 1039.0, 1357.0, 1039.0, 1389.0, 326.0, 1386.0], "score": 0.99, "text": "12359-12374. Association for Computational Linguistics, 2023."}, {"category_id": 15, "poly": [298.0, 456.0, 1404.0, 456.0, 1404.0, 488.0, 298.0, 488.0], "score": 0.99, "text": "Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu,"}, {"category_id": 15, "poly": [323.0, 484.0, 1407.0, 484.0, 1407.0, 522.0, 323.0, 522.0], "score": 0.99, "text": "Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, and Junxian He. C-Eval: A"}, {"category_id": 15, "poly": [323.0, 518.0, 1372.0, 518.0, 1372.0, 550.0, 323.0, 550.0], "score": 0.98, "text": "multi-level multi-discipline chinese evaluation suite for foundation models. In NeurIPS, 2023."}, {"category_id": 15, "poly": [296.0, 231.0, 1402.0, 231.0, 1402.0, 264.0, 296.0, 264.0], "score": 0.99, "text": "Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob"}, {"category_id": 15, "poly": [319.0, 259.0, 1404.0, 261.0, 1404.0, 300.0, 319.0, 298.0], "score": 0.99, "text": " Steinhardt. Measuring massive multitask language understanding. In ICLR. OpenReview.net,"}, {"category_id": 15, "poly": [323.0, 288.0, 405.0, 294.0, 402.0, 328.0, 320.0, 322.0], "score": 0.99, "text": "2021a."}, {"category_id": 15, "poly": [293.0, 341.0, 1402.0, 344.0, 1402.0, 376.0, 293.0, 374.0], "score": 0.98, "text": " Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song,"}, {"category_id": 15, "poly": [323.0, 376.0, 1402.0, 376.0, 1402.0, 408.0, 323.0, 408.0], "score": 0.99, "text": "and Jacob Steinhardt. Measuring mathematical problem solving with the MATH dataset. In"}, {"category_id": 15, "poly": [323.0, 406.0, 808.0, 406.0, 808.0, 438.0, 323.0, 438.0], "score": 0.96, "text": "NeurIPS Datasets andBenchmarks,2021b."}, {"category_id": 15, "poly": [293.0, 1405.0, 1402.0, 1407.0, 1402.0, 1439.0, 293.0, 1437.0], "score": 0.99, "text": " Haonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang, Hai Zhao, Yeyun Gong, Nan Duan, and Timothy"}, {"category_id": 15, "poly": [323.0, 1439.0, 1402.0, 1439.0, 1402.0, 1471.0, 323.0, 1471.0], "score": 0.99, "text": "Baldwin. CMMLU: Measuring massive multitask language understanding in Chinese. CoRR,"}, {"category_id": 15, "poly": [323.0, 1467.0, 582.0, 1467.0, 582.0, 1499.0, 323.0, 1499.0], "score": 1.0, "text": "abs/2306.09212,2023."}], "page_info": {"page_no": 21, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [299.1482238769531, 648.1664428710938, 1403.348388671875, 648.1664428710938, 1403.348388671875, 741.1943969726562, 299.1482238769531, 741.1943969726562], "score": 0.9998149871826172}, {"category_id": 1, "poly": [298.00933837890625, 760.6260375976562, 1404.3377685546875, 760.6260375976562, 1404.3377685546875, 1371.3890380859375, 298.00933837890625, 1371.3890380859375], "score": 0.9997955560684204}, {"category_id": 1, "poly": [296.9804992675781, 1389.9150390625, 1404.7012939453125, 1389.9150390625, 1404.7012939453125, 1545.9307861328125, 296.9804992675781, 1545.9307861328125], "score": 0.9997012615203857}, {"category_id": 1, "poly": [294.6149597167969, 1942.1168212890625, 1404.56640625, 1942.1168212890625, 1404.56640625, 2036.10107421875, 294.6149597167969, 2036.10107421875], "score": 0.9996122121810913}, {"category_id": 2, "poly": [834.7783203125, 2086.9404296875, 865.4984741210938, 2086.9404296875, 865.4984741210938, 2113.490478515625, 834.7783203125, 2113.490478515625], "score": 0.9995092749595642}, {"category_id": 1, "poly": [298.4970703125, 1563.2403564453125, 1404.176513671875, 1563.2403564453125, 1404.176513671875, 1655.5059814453125, 298.4970703125, 1655.5059814453125], "score": 0.9994048476219177}, {"category_id": 1, "poly": [295.2882385253906, 1859.0528564453125, 1404.120849609375, 1859.0528564453125, 1404.120849609375, 1923.751708984375, 295.2882385253906, 1923.751708984375], "score": 0.9993945956230164}, {"category_id": 1, "poly": [295.2219543457031, 1776.6517333984375, 1407.3760986328125, 1776.6517333984375, 1407.3760986328125, 1841.851318359375, 295.2219543457031, 1841.851318359375], "score": 0.998157262802124}, {"category_id": 1, "poly": [297.0544128417969, 230.7419891357422, 1403.119140625, 230.7419891357422, 1403.119140625, 324.5641174316406, 297.0544128417969, 324.5641174316406], "score": 0.9980616569519043}, {"category_id": 1, "poly": [297.81414794921875, 566.7015380859375, 1404.6783447265625, 566.7015380859375, 1404.6783447265625, 631.71923828125, 297.81414794921875, 631.71923828125], "score": 0.9974533319473267}, {"category_id": 1, "poly": [297.33935546875, 485.5320739746094, 1403.067626953125, 485.5320739746094, 1403.067626953125, 549.8895263671875, 297.33935546875, 549.8895263671875], "score": 0.9775978922843933}, {"category_id": 1, "poly": [299.91363525390625, 342.2215270996094, 1404.47900390625, 342.2215270996094, 1404.47900390625, 469.30938720703125, 299.91363525390625, 469.30938720703125], "score": 0.8532602190971375}, {"category_id": 1, "poly": [296.26513671875, 1726.0450439453125, 1357.348876953125, 1726.0450439453125, 1357.348876953125, 1760.3499755859375, 296.26513671875, 1760.3499755859375], "score": 0.7039998769760132}, {"category_id": 9, "poly": [295.897705078125, 1674.5189208984375, 1355.6614990234375, 1674.5189208984375, 1355.6614990234375, 1708.4012451171875, 295.897705078125, 1708.4012451171875], "score": 0.5790212154388428}, {"category_id": 9, "poly": [296.3540954589844, 1725.984130859375, 1357.520263671875, 1725.984130859375, 1357.520263671875, 1760.3602294921875, 296.3540954589844, 1760.3602294921875], "score": 0.3790787160396576}, {"category_id": 1, "poly": [295.897705078125, 1674.5189208984375, 1355.6614990234375, 1674.5189208984375, 1355.6614990234375, 1708.4012451171875, 295.897705078125, 1708.4012451171875], "score": 0.31955331563949585}, {"category_id": 15, "poly": [293.0, 649.0, 1397.0, 649.0, 1397.0, 681.0, 293.0, 681.0], "score": 0.99, "text": " Keming Lu, Hongyi Yuan, Zheng Yuan, Runji Lin, Junyang Lin, Chuanqi Tan, Chang Zhou, and"}, {"category_id": 15, "poly": [319.0, 678.0, 1404.0, 681.0, 1404.0, 720.0, 319.0, 717.0], "score": 0.99, "text": " Jingren Zhou. #InsTag: Instruction tagging for analyzing supervised fine-tuning of large language"}, {"category_id": 15, "poly": [326.0, 713.0, 799.0, 713.0, 799.0, 745.0, 326.0, 745.0], "score": 1.0, "text": "models. In ICLR. OpenReview.net, 2024c."}, {"category_id": 15, "poly": [298.0, 763.0, 1402.0, 763.0, 1402.0, 795.0, 298.0, 795.0], "score": 0.99, "text": "Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre,"}, {"category_id": 15, "poly": [319.0, 788.0, 1407.0, 791.0, 1407.0, 830.0, 319.0, 827.0], "score": 0.98, "text": " Morgane Riviere, Mihir Sanjay Kale, Juliette Love, Pouya Tafti, Lonard Hussenot, Pier Giuseppe"}, {"category_id": 15, "poly": [323.0, 823.0, 1407.0, 823.0, 1407.0, 855.0, 323.0, 855.0], "score": 0.99, "text": "Sessa, Aakanksha Chowdhery, Adam Roberts, Aditya Barua, Alex Botev, Alex Castro-Ros,"}, {"category_id": 15, "poly": [326.0, 855.0, 1404.0, 855.0, 1404.0, 885.0, 326.0, 885.0], "score": 0.99, "text": "Ambrose Slone, Amelie Hliou, Andrea Tacchetti, Anna Bulanova, Antonia Paterson, Beth Tsai,"}, {"category_id": 15, "poly": [323.0, 885.0, 1404.0, 885.0, 1404.0, 917.0, 323.0, 917.0], "score": 0.99, "text": "Bobak Shahriari, Charline Le Lan, Christopher A. Choquette-Choo, Clment Crepy, Daniel Cer,"}, {"category_id": 15, "poly": [321.0, 914.0, 1404.0, 917.0, 1404.0, 949.0, 321.0, 946.0], "score": 0.99, "text": "Daphne Ippolito, David Reid, Elena Buchatskaya, Eric Ni, Eric Noland, Geng Yan, George"}, {"category_id": 15, "poly": [321.0, 940.0, 1407.0, 942.0, 1407.0, 981.0, 321.0, 979.0], "score": 0.99, "text": "Tucker, George-Christian Muraru, Grigory Rozhdestvenskiy, Henryk Michalewski, Ian Tenney,"}, {"category_id": 15, "poly": [323.0, 976.0, 1404.0, 976.0, 1404.0, 1008.0, 323.0, 1008.0], "score": 1.0, "text": "Ivan Grishchenko, Jacob Austin, James Keeling, Jane Labanowski, Jean-Baptiste Lespiau, Jeff"}, {"category_id": 15, "poly": [323.0, 1006.0, 1404.0, 1006.0, 1404.0, 1038.0, 323.0, 1038.0], "score": 0.99, "text": "Stanway, Jenny Brennan, Jeremy Chen, Johan Ferret, Justin Chiu, Justin Mao-Jones, Katherine"}, {"category_id": 15, "poly": [326.0, 1036.0, 1402.0, 1036.0, 1402.0, 1068.0, 326.0, 1068.0], "score": 0.99, "text": "Lee, Kathy Yu, Katie Millican, Lars Lowe Sjoesund, Lisa Lee, Lucas Dixon, Machel Reid, Maciej"}, {"category_id": 15, "poly": [323.0, 1066.0, 1404.0, 1068.0, 1404.0, 1100.0, 323.0, 1098.0], "score": 0.99, "text": "Mikula, Mateo Wirth, Michael Sharman, Nikolai Chinaev, Nithum Thain, Olivier Bachem, Oscar"}, {"category_id": 15, "poly": [326.0, 1098.0, 1404.0, 1098.0, 1404.0, 1130.0, 326.0, 1130.0], "score": 1.0, "text": "Chang, Oscar Wahltinez, Paige Bailey, Paul Michel, Petko Yotov, Rahma Chaabouni, Ramona"}, {"category_id": 15, "poly": [326.0, 1128.0, 1404.0, 1128.0, 1404.0, 1160.0, 326.0, 1160.0], "score": 0.97, "text": "Comanescu, Reena Jana, Rohan Anil, Ross Mcllroy, Ruibo Liu, Ryan Mullins, Samuel L Smith,"}, {"category_id": 15, "poly": [319.0, 1153.0, 1407.0, 1155.0, 1407.0, 1194.0, 319.0, 1192.0], "score": 0.99, "text": " Sebastian Borgeaud, Sertan Girgin, Sholto Douglas, Shree Pandya, Siamak Shakeri, Soham De,"}, {"category_id": 15, "poly": [326.0, 1189.0, 1404.0, 1189.0, 1404.0, 1221.0, 326.0, 1221.0], "score": 0.99, "text": "Ted Klimenko, Tom Hennigan, Vlad Feinberg, Wojciech Stokowiec, Yu hui Chen, Zafarali Ahmed,"}, {"category_id": 15, "poly": [326.0, 1219.0, 1404.0, 1219.0, 1404.0, 1251.0, 326.0, 1251.0], "score": 0.99, "text": "Zhitao Gong, Tris Warkentin, Ludovic Peran, Minh Giang, Clment Farabet, Oriol Vinyals, Jeff"}, {"category_id": 15, "poly": [326.0, 1251.0, 1404.0, 1251.0, 1404.0, 1283.0, 326.0, 1283.0], "score": 0.99, "text": "Dean, Koray Kavukcuoglu, Demis Hassabis, Zoubin Ghahramani, Douglas Eck, Joelle Barral,"}, {"category_id": 15, "poly": [326.0, 1281.0, 1402.0, 1281.0, 1402.0, 1311.0, 326.0, 1311.0], "score": 0.99, "text": "Fernando Pereira, Eli Collins, Armand Joulin, Noah Fiedel, Evan Senter, Alek Andreev, and"}, {"category_id": 15, "poly": [323.0, 1309.0, 1407.0, 1311.0, 1407.0, 1343.0, 323.0, 1341.0], "score": 1.0, "text": "Kathleen Kenealy. Gemma: Open models based on Gemini research and technology. CoRR,"}, {"category_id": 15, "poly": [323.0, 1341.0, 580.0, 1341.0, 580.0, 1370.0, 323.0, 1370.0], "score": 0.99, "text": "abs/2403.08295,2024."}, {"category_id": 15, "poly": [296.0, 1393.0, 1402.0, 1393.0, 1402.0, 1425.0, 296.0, 1425.0], "score": 0.99, "text": "Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le"}, {"category_id": 15, "poly": [323.0, 1423.0, 1404.0, 1423.0, 1404.0, 1455.0, 323.0, 1455.0], "score": 0.99, "text": "Scao, M. Saiful Bari, Sheng Shen, Zheng Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir"}, {"category_id": 15, "poly": [323.0, 1453.0, 1407.0, 1453.0, 1407.0, 1485.0, 323.0, 1485.0], "score": 0.99, "text": "Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson,"}, {"category_id": 15, "poly": [323.0, 1483.0, 1402.0, 1483.0, 1402.0, 1515.0, 323.0, 1515.0], "score": 0.99, "text": "Edward Raff, and Colin Raffel. Crosslingual generalization through multitask finetuning. In ACL"}, {"category_id": 15, "poly": [323.0, 1515.0, 1129.0, 1515.0, 1129.0, 1547.0, 323.0, 1547.0], "score": 0.99, "text": "(1), pp. 15991-16111. Association for Computational Linguistics, 2023."}, {"category_id": 15, "poly": [298.0, 1946.0, 1402.0, 1946.0, 1402.0, 1978.0, 298.0, 1978.0], "score": 0.99, "text": "Edoardo Maria Ponti, Goran Glavas, Olga Majewska, Qianchu Liu, Ivan Vulic, and Anna Korhonen."}, {"category_id": 15, "poly": [326.0, 1975.0, 1402.0, 1975.0, 1402.0, 2008.0, 326.0, 2008.0], "score": 0.99, "text": "XCOPA: A multilingual dataset for causal commonsense reasoning. In EMNLP (1), pp. 2362-2376."}, {"category_id": 15, "poly": [326.0, 2005.0, 873.0, 2003.0, 873.0, 2035.0, 326.0, 2037.0], "score": 0.99, "text": "Association for Computational Linguistics, 2020."}, {"category_id": 15, "poly": [832.0, 2083.0, 871.0, 2083.0, 871.0, 2131.0, 832.0, 2131.0], "score": 1.0, "text": "23"}, {"category_id": 15, "poly": [291.0, 1561.0, 1404.0, 1563.0, 1404.0, 1602.0, 291.0, 1600.0], "score": 0.98, "text": " Jinjie Ni, Fuzhao Xue, Xiang Yue, Yuntian Deng, Mahir Shah, Kabir Jain, Graham Neubig, and"}, {"category_id": 15, "poly": [323.0, 1597.0, 1407.0, 1597.0, 1407.0, 1629.0, 323.0, 1629.0], "score": 0.99, "text": "Yang You. MixEval: Deriving wisdom of the crowd from LLM benchmark mixtures. CoRR,"}, {"category_id": 15, "poly": [323.0, 1627.0, 582.0, 1627.0, 582.0, 1657.0, 323.0, 1657.0], "score": 0.99, "text": "abs/2406.06565,2024."}, {"category_id": 15, "poly": [298.0, 1863.0, 1402.0, 1863.0, 1402.0, 1895.0, 298.0, 1895.0], "score": 0.99, "text": "Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole. YaRN: Efficient context window"}, {"category_id": 15, "poly": [323.0, 1895.0, 1069.0, 1895.0, 1069.0, 1927.0, 323.0, 1927.0], "score": 0.99, "text": "extension of large language models. CoRR, abs/2309.00071, 2023."}, {"category_id": 15, "poly": [298.0, 1783.0, 1404.0, 1783.0, 1404.0, 1813.0, 298.0, 1813.0], "score": 0.99, "text": "OpenCompass Contributors. OpenCompass: A universal evaluation platform for foundation models,"}, {"category_id": 15, "poly": [321.0, 1810.0, 1187.0, 1815.0, 1187.0, 1847.0, 321.0, 1842.0], "score": 0.99, "text": "2023. URL https: / /github.com/open-compass /opencompass."}, {"category_id": 15, "poly": [293.0, 227.0, 1402.0, 229.0, 1402.0, 268.0, 293.0, 266.0], "score": 0.99, "text": " Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. Is your code generated by"}, {"category_id": 15, "poly": [319.0, 259.0, 1404.0, 261.0, 1404.0, 300.0, 319.0, 298.0], "score": 0.99, "text": " ChatGPT really correct? Rigorous evaluation of large language models for code generation. In"}, {"category_id": 15, "poly": [323.0, 296.0, 510.0, 296.0, 510.0, 325.0, 323.0, 325.0], "score": 0.97, "text": "NeurIPS,2023a."}, {"category_id": 15, "poly": [296.0, 568.0, 1400.0, 571.0, 1400.0, 603.0, 296.0, 600.0], "score": 0.99, "text": "Keming Lu, Bowen Yu, Chang Zhou, and Jingren Zhou. Large language models are superpositions"}, {"category_id": 15, "poly": [319.0, 598.0, 1404.0, 596.0, 1404.0, 635.0, 319.0, 637.0], "score": 0.98, "text": " of all characters: Attaining arbitrary role-play via self-alignment. CoRR, abs/2401.12474, 2024b."}, {"category_id": 15, "poly": [298.0, 488.0, 1404.0, 488.0, 1404.0, 520.0, 298.0, 520.0], "score": 1.0, "text": "Keming Lu, Bowen Yu, Fei Huang, Yang Fan, Runji Lin, and Chang Zhou. Online merging optimizers"}, {"category_id": 15, "poly": [323.0, 520.0, 1270.0, 520.0, 1270.0, 550.0, 323.0, 550.0], "score": 0.99, "text": "for boosting rewards and mitigating tax in alignment. CoRR, abs/2405.17931, 2024a."}, {"category_id": 15, "poly": [293.0, 341.0, 1404.0, 341.0, 1404.0, 380.0, 293.0, 380.0], "score": 0.98, "text": " Xiao Liu, Xuanyu Lei, Shengyuan Wang, Yue Huang, Zhuoer Feng, Bosi Wen, Jiale Cheng, Pei Ke,"}, {"category_id": 15, "poly": [326.0, 376.0, 1402.0, 376.0, 1402.0, 408.0, 326.0, 408.0], "score": 0.99, "text": "Yifan Xu, Weng Lam Tam, Xiaohan Zhang, Lichao Sun, Hongning Wang, Jing Zhang, Minlie"}, {"category_id": 15, "poly": [326.0, 408.0, 1402.0, 408.0, 1402.0, 440.0, 326.0, 440.0], "score": 0.99, "text": "Huang, Yuxiao Dong, and Jie Tang. AlignBench: Benchmarking Chinese alignment of large"}, {"category_id": 15, "poly": [326.0, 438.0, 875.0, 438.0, 875.0, 470.0, 326.0, 470.0], "score": 0.99, "text": "language models. CoRR, abs/2311.18743, 2023b."}, {"category_id": 15, "poly": [300.0, 1730.0, 1349.0, 1730.0, 1349.0, 1762.0, 300.0, 1762.0], "score": 0.97, "text": "OpenAI. Hello GPT-4o, 2024. URL https : / /openai . com/index/hello-gpt-4o/."}, {"category_id": 15, "poly": [298.0, 1677.0, 1349.0, 1680.0, 1349.0, 1712.0, 298.0, 1710.0], "score": 0.98, "text": "OpenAI. Introducing ChatGPT, 2022. URL https : / /openai . com/ index/chatgpt /."}], "page_info": {"page_no": 22, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [297.06512451171875, 729.4949340820312, 1405.5321044921875, 729.4949340820312, 1405.5321044921875, 823.1972045898438, 297.06512451171875, 823.1972045898438], "score": 0.9952849745750427}, {"category_id": 1, "poly": [295.83905029296875, 842.2959594726562, 1406.7042236328125, 842.2959594726562, 1406.7042236328125, 906.2612915039062, 295.83905029296875, 906.2612915039062], "score": 0.9929972887039185}, {"category_id": 1, "poly": [299.2759094238281, 585.7001342773438, 1407.3123779296875, 585.7001342773438, 1407.3123779296875, 713.2571411132812, 299.2759094238281, 713.2571411132812], "score": 0.9917716383934021}, {"category_id": 2, "poly": [833.2122802734375, 2086.33203125, 868.3477783203125, 2086.33203125, 868.3477783203125, 2113.771240234375, 833.2122802734375, 2113.771240234375], "score": 0.9858416318893433}, {"category_id": 1, "poly": [296.3788757324219, 1083.6895751953125, 1409.194091796875, 1083.6895751953125, 1409.194091796875, 1213.8609619140625, 296.3788757324219, 1213.8609619140625], "score": 0.984761655330658}, {"category_id": 1, "poly": [296.88446044921875, 922.3929443359375, 1407.058837890625, 922.3929443359375, 1407.058837890625, 988.4291381835938, 296.88446044921875, 988.4291381835938], "score": 0.9794067144393921}, {"category_id": 1, "poly": [296.2732238769531, 1227.9703369140625, 1406.4786376953125, 1227.9703369140625, 1406.4786376953125, 1354.5556640625, 296.2732238769531, 1354.5556640625], "score": 0.9654560089111328}, {"category_id": 2, "poly": [295.75701904296875, 230.27578735351562, 1406.263671875, 230.27578735351562, 1406.263671875, 295.44091796875, 295.75701904296875, 295.44091796875], "score": 0.953589677810669}, {"category_id": 1, "poly": [293.73541259765625, 1002.546630859375, 1408.3326416015625, 1002.546630859375, 1408.3326416015625, 1072.4033203125, 293.73541259765625, 1072.4033203125], "score": 0.9388309717178345}, {"category_id": 1, "poly": [294.58209228515625, 1369.3818359375, 1407.5274658203125, 1369.3818359375, 1407.5274658203125, 1439.454345703125, 294.58209228515625, 1439.454345703125], "score": 0.916853129863739}, {"category_id": 1, "poly": [296.20794677734375, 311.46710205078125, 1407.9501953125, 311.46710205078125, 1407.9501953125, 377.8498840332031, 296.20794677734375, 377.8498840332031], "score": 0.8726212382316589}, {"category_id": 1, "poly": [298.7018737792969, 473.2330017089844, 1405.925048828125, 473.2330017089844, 1405.925048828125, 569.4074096679688, 298.7018737792969, 569.4074096679688], "score": 0.8503658771514893}, {"category_id": 1, "poly": [296.2014465332031, 1451.103271484375, 1407.616455078125, 1451.103271484375, 1407.616455078125, 1581.2850341796875, 296.2014465332031, 1581.2850341796875], "score": 0.8307908773422241}, {"category_id": 1, "poly": [295.1370544433594, 390.66705322265625, 1407.65576171875, 390.66705322265625, 1407.65576171875, 460.6175231933594, 295.1370544433594, 460.6175231933594], "score": 0.8066614866256714}, {"category_id": 1, "poly": [297.77593994140625, 1880.4921875, 1406.7108154296875, 1880.4921875, 1406.7108154296875, 2037.4083251953125, 297.77593994140625, 2037.4083251953125], "score": 0.6236922740936279}, {"category_id": 1, "poly": [289.7188720703125, 224.51756286621094, 1412.1005859375, 224.51756286621094, 1412.1005859375, 2056.87890625, 289.7188720703125, 2056.87890625], "score": 0.4539214074611664}, {"category_id": 1, "poly": [297.6217956542969, 1595.6951904296875, 1406.9102783203125, 1595.6951904296875, 1406.9102783203125, 1750.541748046875, 297.6217956542969, 1750.541748046875], "score": 0.43000537157058716}, {"category_id": 1, "poly": [297.5210876464844, 1769.2196044921875, 1404.6856689453125, 1769.2196044921875, 1404.6856689453125, 1863.896728515625, 297.5210876464844, 1863.896728515625], "score": 0.414745032787323}, {"category_id": 13, "poly": [739, 313, 819, 313, 819, 341, 739, 341], "score": 0.8, "latex": "100\\mathbf{B}+"}, {"category_id": 13, "poly": [999, 927, 1025, 927, 1025, 951, 999, 951], "score": 0.76, "latex": "="}, {"category_id": 13, "poly": [920, 927, 943, 927, 943, 951, 920, 951], "score": 0.55, "latex": "+"}, {"category_id": 15, "poly": [296.0, 733.0, 1400.0, 733.0, 1400.0, 765.0, 296.0, 765.0], "score": 1.0, "text": "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien"}, {"category_id": 15, "poly": [326.0, 763.0, 1402.0, 763.0, 1402.0, 795.0, 326.0, 795.0], "score": 1.0, "text": "Dirani, Julian Michael, and Samuel R. Bowman. GPQA: A graduate-level Google-proof Q&A"}, {"category_id": 15, "poly": [323.0, 791.0, 802.0, 793.0, 801.0, 825.0, 323.0, 823.0], "score": 0.99, "text": "benchmark. CoRR, abs/2311.12022, 2023."}, {"category_id": 15, "poly": [298.0, 846.0, 1402.0, 846.0, 1402.0, 878.0, 298.0, 878.0], "score": 0.99, "text": "Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. WinoGrande: An"}, {"category_id": 15, "poly": [321.0, 875.0, 1280.0, 873.0, 1280.0, 905.0, 321.0, 908.0], "score": 0.99, "text": " adversarial winograd schema challenge at scale. Commun. ACM, 64(9):99-106, 2021."}, {"category_id": 15, "poly": [296.0, 591.0, 1402.0, 591.0, 1402.0, 623.0, 296.0, 623.0], "score": 1.0, "text": "Samyam Rajbhandari, Conglong Li, Zhewei Yao, Minjia Zhang, Reza Yazdani Aminabadi, Am-"}, {"category_id": 15, "poly": [321.0, 619.0, 1402.0, 621.0, 1402.0, 653.0, 321.0, 651.0], "score": 0.99, "text": " mar Ahmad Awan, Jeff Rasley, and Yuxiong He. DeepSpeed-MoE: Advancing mixture-of-experts"}, {"category_id": 15, "poly": [328.0, 651.0, 1404.0, 651.0, 1404.0, 683.0, 328.0, 683.0], "score": 0.99, "text": "inference and training to power next-generation AI scale. In ICML, volume 162 of Proceedings of"}, {"category_id": 15, "poly": [326.0, 683.0, 1014.0, 683.0, 1014.0, 715.0, 326.0, 715.0], "score": 0.98, "text": "Machine Learning Research,pp. 18332-18346.PMLR, 2022."}, {"category_id": 15, "poly": [829.0, 2083.0, 871.0, 2083.0, 871.0, 2131.0, 829.0, 2131.0], "score": 1.0, "text": "24"}, {"category_id": 15, "poly": [293.0, 1086.0, 1402.0, 1091.0, 1402.0, 1123.0, 293.0, 1118.0], "score": 0.99, "text": " Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung,"}, {"category_id": 15, "poly": [319.0, 1116.0, 1407.0, 1114.0, 1407.0, 1153.0, 319.0, 1155.0], "score": 0.99, "text": " Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, and Jason Wei. Challenging BIG-"}, {"category_id": 15, "poly": [326.0, 1150.0, 1404.0, 1150.0, 1404.0, 1182.0, 326.0, 1182.0], "score": 0.99, "text": "Bench tasks and whether chain-of-thought can solve them. In ACL (Findings), pp. 13003-13051."}, {"category_id": 15, "poly": [326.0, 1182.0, 873.0, 1182.0, 873.0, 1215.0, 326.0, 1215.0], "score": 0.99, "text": "Association for Computational Linguistics, 2023."}, {"category_id": 15, "poly": [321.0, 956.0, 966.0, 958.0, 965.0, 990.0, 321.0, 988.0], "score": 1.0, "text": "URL https://spaces.ac.cn/archives/9577."}, {"category_id": 15, "poly": [1026.0, 926.0, 1402.0, 926.0, 1402.0, 958.0, 1026.0, 958.0], "score": 0.99, "text": "better length extrapolation, 2023."}, {"category_id": 15, "poly": [298.0, 926.0, 919.0, 926.0, 919.0, 958.0, 298.0, 958.0], "score": 1.0, "text": "Jianlin Su. The magical effect of the Bias term: RoPE"}, {"category_id": 15, "poly": [944.0, 926.0, 998.0, 926.0, 998.0, 958.0, 944.0, 958.0], "score": 1.0, "text": "Bias"}, {"category_id": 15, "poly": [296.0, 1233.0, 1402.0, 1233.0, 1402.0, 1263.0, 296.0, 1263.0], "score": 0.99, "text": "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothe"}, {"category_id": 15, "poly": [323.0, 1263.0, 1402.0, 1263.0, 1402.0, 1295.0, 323.0, 1295.0], "score": 0.99, "text": "Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurlien Rodriguez, Armand"}, {"category_id": 15, "poly": [323.0, 1288.0, 1404.0, 1290.0, 1404.0, 1329.0, 323.0, 1327.0], "score": 1.0, "text": "Joulin, Edouard Grave, and Guillaume Lample. LLaMA: Open and efficient foundation language"}, {"category_id": 15, "poly": [323.0, 1325.0, 760.0, 1325.0, 760.0, 1354.0, 323.0, 1354.0], "score": 0.96, "text": "m0dels. CoRR, abs/2302.13971, 2023."}, {"category_id": 15, "poly": [296.0, 229.0, 1404.0, 229.0, 1404.0, 268.0, 296.0, 268.0], "score": 0.98, "text": "Qwen Team. Introducing Qwenl.5, 2024a. URL https: //qwenlm.github.io/blog/"}, {"category_id": 15, "poly": [321.0, 266.0, 468.0, 261.0, 469.0, 293.0, 322.0, 298.0], "score": 0.98, "text": "qwen1.5/."}, {"category_id": 15, "poly": [296.0, 1008.0, 1407.0, 1008.0, 1407.0, 1040.0, 296.0, 1040.0], "score": 0.99, "text": "Jianlin Su, Murtadha H. M. Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu. Roformer:"}, {"category_id": 15, "poly": [326.0, 1038.0, 1363.0, 1038.0, 1363.0, 1070.0, 326.0, 1070.0], "score": 1.0, "text": "Enhanced Transformer with rotary position embedding. Neurocomputing, 568:127063, 2024."}, {"category_id": 15, "poly": [298.0, 1370.0, 1404.0, 1373.0, 1404.0, 1405.0, 298.0, 1402.0], "score": 0.99, "text": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz"}, {"category_id": 15, "poly": [323.0, 1405.0, 1287.0, 1405.0, 1287.0, 1437.0, 323.0, 1437.0], "score": 0.99, "text": "Kaiser, and Mlia Polosukhin. Attention is all you need. In NIPS, pp. 5998-6008, 2017."}, {"category_id": 15, "poly": [321.0, 348.0, 952.0, 348.0, 952.0, 378.0, 321.0, 378.0], "score": 0.97, "text": "//qwenlm.github.io/blog/qwenl.5-110b/."}, {"category_id": 15, "poly": [296.0, 314.0, 738.0, 316.0, 738.0, 348.0, 296.0, 346.0], "score": 0.97, "text": "Qwen Team. Qwen1.5-110B: The first"}, {"category_id": 15, "poly": [820.0, 314.0, 1407.0, 316.0, 1407.0, 348.0, 820.0, 346.0], "score": 0.99, "text": "model of the Qwen1.5 series, 2024b. URL https :"}, {"category_id": 15, "poly": [296.0, 474.0, 1397.0, 479.0, 1397.0, 511.0, 296.0, 506.0], "score": 0.99, "text": "Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D. Manning, Stefano Ermon, and Chelsea"}, {"category_id": 15, "poly": [323.0, 509.0, 1402.0, 509.0, 1402.0, 541.0, 323.0, 541.0], "score": 0.98, "text": "Finn. Direct preference optimization: Your language model is secretly a reward model. In NeurlPS,"}, {"category_id": 15, "poly": [323.0, 539.0, 393.0, 539.0, 393.0, 571.0, 323.0, 571.0], "score": 1.0, "text": "2023."}, {"category_id": 15, "poly": [296.0, 1453.0, 1404.0, 1453.0, 1404.0, 1492.0, 296.0, 1492.0], "score": 0.99, "text": "Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming"}, {"category_id": 15, "poly": [323.0, 1487.0, 1402.0, 1487.0, 1402.0, 1519.0, 323.0, 1519.0], "score": 0.99, "text": "Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai Wang, Alex Zhuang, Rongqi"}, {"category_id": 15, "poly": [326.0, 1517.0, 1402.0, 1517.0, 1402.0, 1549.0, 326.0, 1549.0], "score": 0.99, "text": "Fan, Xiang Yue, and Wenhu Chen. MMLU-Pro: A more robust and challenging multi-task"}, {"category_id": 15, "poly": [323.0, 1547.0, 1069.0, 1545.0, 1069.0, 1577.0, 323.0, 1579.0], "score": 0.99, "text": "language understanding benchmark. CoRR, abs/2406.01574, 2024."}, {"category_id": 15, "poly": [298.0, 396.0, 1402.0, 396.0, 1402.0, 429.0, 298.0, 429.0], "score": 0.99, "text": "Qwen Team. Qwen1.5-MoE: Matching 7B model performance with 1/3 activated parameters, 2024c."}, {"category_id": 15, "poly": [323.0, 429.0, 1049.0, 429.0, 1049.0, 461.0, 323.0, 461.0], "score": 0.99, "text": "URL https: / /qwenlm.github.io/blog/qwen-moe/."}, {"category_id": 15, "poly": [298.0, 1884.0, 1402.0, 1884.0, 1402.0, 1916.0, 298.0, 1916.0], "score": 0.99, "text": "Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang, Guanwei Zhang, Heng Li, Jiangcheng"}, {"category_id": 15, "poly": [321.0, 1911.0, 1404.0, 1916.0, 1404.0, 1948.0, 321.0, 1943.0], "score": 0.99, "text": " Zhu, Jianqun Chen, Jing Chang, Kaidong Yu, Peng Liu, Qiang Liu, Shawn Yue, Senbin Yang,"}, {"category_id": 15, "poly": [328.0, 1946.0, 1402.0, 1946.0, 1402.0, 1978.0, 328.0, 1978.0], "score": 0.99, "text": "Shiming Yang, Tao Yu, Wen Xie, Wenhao Huang, Xiaohui Hu, Xiaoyi Ren, Xinyao Niu, Pengcheng"}, {"category_id": 15, "poly": [328.0, 1975.0, 1402.0, 1975.0, 1402.0, 2008.0, 328.0, 2008.0], "score": 0.98, "text": "Nie, Yuchi Xu, Yudong Liu, Yue Wang, Yuxuan Cai, Zhenyu Gu, Zhiyuan Liu, and Zonghong Dai."}, {"category_id": 15, "poly": [326.0, 2005.0, 1095.0, 2005.0, 1095.0, 2037.0, 326.0, 2037.0], "score": 0.99, "text": "Yi: Open foundation models by 01.AI. CoRR, abs/2403.04652, 2024."}, {"category_id": 15, "poly": [296.0, 229.0, 1402.0, 231.0, 1402.0, 270.0, 296.0, 268.0], "score": 0.98, "text": "Qwen Team. Introducing Qwenl.5, 2024a. URL https: / /qwenlm.github.io/blog/"}, {"category_id": 15, "poly": [323.0, 268.0, 468.0, 263.0, 469.0, 293.0, 324.0, 298.0], "score": 0.98, "text": "qwen1.5/."}, {"category_id": 15, "poly": [326.0, 348.0, 952.0, 348.0, 952.0, 380.0, 326.0, 380.0], "score": 0.98, "text": "//qwenlm.github.io/blog/qwen1.5-110b/."}, {"category_id": 15, "poly": [300.0, 396.0, 1402.0, 396.0, 1402.0, 429.0, 300.0, 429.0], "score": 0.99, "text": "Qwen Team. Qwen1.5-MoE: Matching 7B model performance with 1/3 activated parameters, 2024c."}, {"category_id": 15, "poly": [324.0, 426.0, 1049.0, 431.0, 1049.0, 463.0, 323.0, 458.0], "score": 0.98, "text": "URL https: / /qwenlm.github.io/blog/qwen-moe/."}, {"category_id": 15, "poly": [293.0, 474.0, 1400.0, 477.0, 1400.0, 516.0, 293.0, 513.0], "score": 0.98, "text": " Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D. Manning, Stefano Ermon, and Chelsea"}, {"category_id": 15, "poly": [328.0, 541.0, 393.0, 541.0, 393.0, 571.0, 328.0, 571.0], "score": 1.0, "text": "2023."}, {"category_id": 15, "poly": [298.0, 591.0, 1402.0, 591.0, 1402.0, 623.0, 298.0, 623.0], "score": 0.99, "text": "Samyam Rajbhandari, Conglong Li, Zhewei Yao, Minjia Zhang, Reza Yazdani Aminabadi, Am-"}, {"category_id": 15, "poly": [326.0, 623.0, 1402.0, 623.0, 1402.0, 653.0, 326.0, 653.0], "score": 1.0, "text": "mar Ahmad Awan, Jeff Rasley, and Yuxiong He. DeepSpeed-MoE: Advancing mixture-of-experts"}, {"category_id": 15, "poly": [326.0, 651.0, 1402.0, 651.0, 1402.0, 683.0, 326.0, 683.0], "score": 0.99, "text": "inference and training to power next-generation AI scale. In ICML, volume 162 of Proceedings of"}, {"category_id": 15, "poly": [323.0, 681.0, 1009.0, 681.0, 1009.0, 713.0, 323.0, 713.0], "score": 0.97, "text": "Machine Learning Research,pp. 18332-18346. PMLR, 2022."}, {"category_id": 15, "poly": [293.0, 729.0, 1402.0, 731.0, 1402.0, 770.0, 293.0, 768.0], "score": 0.99, "text": " David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien"}, {"category_id": 15, "poly": [328.0, 765.0, 1402.0, 765.0, 1402.0, 798.0, 328.0, 798.0], "score": 0.99, "text": "Dirani, Julian Michael, and Samuel R. Bowman. GPQA: A graduate-level Google-proof Q&A"}, {"category_id": 15, "poly": [326.0, 795.0, 801.0, 795.0, 801.0, 825.0, 326.0, 825.0], "score": 1.0, "text": "benchmark. CoRR, abs/2311.12022, 2023."}, {"category_id": 15, "poly": [298.0, 843.0, 1404.0, 843.0, 1404.0, 882.0, 298.0, 882.0], "score": 0.99, "text": "Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. WinoGrande: An"}, {"category_id": 15, "poly": [326.0, 878.0, 1280.0, 878.0, 1280.0, 910.0, 326.0, 910.0], "score": 0.99, "text": "adversarial winograd schema challenge at scale. Commun. ACM, 64(9):99-106, 2021."}, {"category_id": 15, "poly": [323.0, 956.0, 966.0, 958.0, 965.0, 990.0, 323.0, 988.0], "score": 0.97, "text": "URL https: / /spaces.ac.cn/archives/9577."}, {"category_id": 15, "poly": [296.0, 1006.0, 1407.0, 1008.0, 1407.0, 1040.0, 296.0, 1038.0], "score": 1.0, "text": "Jianlin Su, Murtadha H. M. Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu. Roformer:"}, {"category_id": 15, "poly": [328.0, 1040.0, 1358.0, 1040.0, 1358.0, 1072.0, 328.0, 1072.0], "score": 0.99, "text": "Enhanced Transformer with rotary position embedding. Neurocomputing, 568:127063, 2024."}, {"category_id": 15, "poly": [300.0, 1091.0, 1400.0, 1091.0, 1400.0, 1123.0, 300.0, 1123.0], "score": 1.0, "text": "Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung."}, {"category_id": 15, "poly": [326.0, 1121.0, 1402.0, 1118.0, 1402.0, 1150.0, 326.0, 1153.0], "score": 0.99, "text": "Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, and Jason Wei. Challenging BIG-"}, {"category_id": 15, "poly": [328.0, 1153.0, 1404.0, 1153.0, 1404.0, 1185.0, 328.0, 1185.0], "score": 0.99, "text": "Bench tasks and whether chain-of-thought can solve them. In ACL (Findings), pp. 13003-13051."}, {"category_id": 15, "poly": [323.0, 1182.0, 871.0, 1182.0, 871.0, 1212.0, 323.0, 1212.0], "score": 1.0, "text": "Association for Computational Linguistics, 2023."}, {"category_id": 15, "poly": [298.0, 1233.0, 1402.0, 1233.0, 1402.0, 1263.0, 298.0, 1263.0], "score": 1.0, "text": "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothe"}, {"category_id": 15, "poly": [326.0, 1265.0, 1402.0, 1265.0, 1402.0, 1295.0, 326.0, 1295.0], "score": 0.99, "text": "Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurlien Rodriguez, Armand"}, {"category_id": 15, "poly": [326.0, 1295.0, 1402.0, 1295.0, 1402.0, 1327.0, 326.0, 1327.0], "score": 0.99, "text": "Joulin, Edouard Grave, and Guillaume Lample. LLaMA: Open and efficient foundation language"}, {"category_id": 15, "poly": [326.0, 1325.0, 755.0, 1325.0, 755.0, 1354.0, 326.0, 1354.0], "score": 1.0, "text": "models. CoRR, abs/2302.13971, 2023."}, {"category_id": 15, "poly": [300.0, 1375.0, 1404.0, 1375.0, 1404.0, 1405.0, 300.0, 1405.0], "score": 0.99, "text": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz"}, {"category_id": 15, "poly": [326.0, 1407.0, 1284.0, 1407.0, 1284.0, 1439.0, 326.0, 1439.0], "score": 0.97, "text": "Kaiser, and Illia Polosukhin. Attention is all you need. In NIPS, pp. 5998-6008, 2017."}, {"category_id": 15, "poly": [296.0, 1451.0, 1402.0, 1453.0, 1402.0, 1492.0, 296.0, 1490.0], "score": 0.99, "text": "Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming"}, {"category_id": 15, "poly": [319.0, 1483.0, 1402.0, 1485.0, 1402.0, 1524.0, 319.0, 1522.0], "score": 0.98, "text": " Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai Wang, Alex Zhuang, Rongqi"}, {"category_id": 15, "poly": [326.0, 1519.0, 1402.0, 1519.0, 1402.0, 1551.0, 326.0, 1551.0], "score": 0.99, "text": "Fan, Xiang Yue, and Wenhu Chen. MMLU-Pro: A more robust and challenging multi-task"}, {"category_id": 15, "poly": [326.0, 1549.0, 1069.0, 1549.0, 1069.0, 1581.0, 326.0, 1581.0], "score": 1.0, "text": "language understanding benchmark. CoRR, abs/2406.01574, 2024."}, {"category_id": 15, "poly": [300.0, 1600.0, 1402.0, 1600.0, 1402.0, 1632.0, 300.0, 1632.0], "score": 1.0, "text": "Wenhan Xiong, Jingyu Liu, Igor Molybog, Hejia Zhang, Prajwal Bhargava, Rui Hou, Louis Martin,"}, {"category_id": 15, "poly": [326.0, 1632.0, 1402.0, 1632.0, 1402.0, 1661.0, 326.0, 1661.0], "score": 0.99, "text": "Rashi Rungta, Karthik Abinav Sankararaman, Barlas Oguz, Madian Khabsa, Han Fang, Yashar"}, {"category_id": 15, "poly": [328.0, 1661.0, 1402.0, 1661.0, 1402.0, 1694.0, 328.0, 1694.0], "score": 0.99, "text": "Mehdad, Sharan Narang, Kshitiz Malik, Angela Fan, Shruti Bhosale, Sergey Edunov, Mike"}, {"category_id": 15, "poly": [323.0, 1689.0, 1404.0, 1691.0, 1404.0, 1723.0, 323.0, 1721.0], "score": 1.0, "text": "Lewis, Sinong Wang, and Hao Ma. Effective long-context scaling of foundation models. CoRR,"}, {"category_id": 15, "poly": [326.0, 1721.0, 577.0, 1721.0, 577.0, 1751.0, 326.0, 1751.0], "score": 1.0, "text": "abs/2309.16039, 2023."}, {"category_id": 15, "poly": [296.0, 1767.0, 1402.0, 1769.0, 1402.0, 1808.0, 296.0, 1806.0], "score": 0.99, "text": "Yinfei Yang, Yuan Zhang, Chris Tar, and Jason Baldridge. PAWS-X: A cross-lingual adversarial"}, {"category_id": 15, "poly": [326.0, 1801.0, 1404.0, 1801.0, 1404.0, 1840.0, 326.0, 1840.0], "score": 0.97, "text": "dataset for paraphrase identification. In EMNLP/IJCNLP (1), pp. 3685-3690. Association for"}, {"category_id": 15, "poly": [326.0, 1836.0, 698.0, 1836.0, 698.0, 1865.0, 326.0, 1865.0], "score": 1.0, "text": "Computational Linguistics, 2019."}, {"category_id": 15, "poly": [298.0, 1886.0, 1400.0, 1886.0, 1400.0, 1918.0, 298.0, 1918.0], "score": 0.99, "text": "Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang, Guanwei Zhang, Heng Li, Jiangcheng"}, {"category_id": 15, "poly": [323.0, 1916.0, 1400.0, 1916.0, 1400.0, 1948.0, 323.0, 1948.0], "score": 0.99, "text": "Zhu, Jianqun Chen, Jing Chang, Kaidong Yu, Peng Liu, Qiang Liu, Shawn Yue, Senbin Yang"}, {"category_id": 15, "poly": [323.0, 1941.0, 1404.0, 1943.0, 1404.0, 1982.0, 323.0, 1980.0], "score": 0.99, "text": "Shiming Yang, Tao Yu, Wen Xie, Wenhao Huang, Xiaohui Hu, Xiaoyi Ren, Xinyao Niu, Pengcheng"}, {"category_id": 15, "poly": [328.0, 1978.0, 1402.0, 1978.0, 1402.0, 2010.0, 328.0, 2010.0], "score": 0.98, "text": "Nie, Yuchi Xu, Yudong Liu, Yue Wang, Yuxuan Cai, Zhenyu Gu, Zhiyuan Liu, and Zonghong Dai."}, {"category_id": 15, "poly": [326.0, 2008.0, 1095.0, 2008.0, 1095.0, 2037.0, 326.0, 2037.0], "score": 0.99, "text": "Yi: Open foundation models by 01.AI. CoRR, abs/2403.04652, 2024."}, {"category_id": 15, "poly": [298.0, 314.0, 738.0, 316.0, 738.0, 348.0, 298.0, 346.0], "score": 0.99, "text": "Qwen Team. Qwen1.5-110B: The first"}, {"category_id": 15, "poly": [820.0, 314.0, 1404.0, 316.0, 1404.0, 348.0, 820.0, 346.0], "score": 1.0, "text": "model of the Qwen1.5 series, 2024b. URL https :"}, {"category_id": 15, "poly": [1026.0, 921.0, 1407.0, 924.0, 1407.0, 963.0, 1026.0, 960.0], "score": 0.99, "text": "better length extrapolation, 2023."}, {"category_id": 15, "poly": [296.0, 921.0, 919.0, 924.0, 919.0, 963.0, 296.0, 960.0], "score": 0.96, "text": "Jianlin Su. The magical effect of the Bias term: RoPE"}, {"category_id": 15, "poly": [944.0, 921.0, 998.0, 924.0, 998.0, 963.0, 944.0, 960.0], "score": 1.0, "text": "Bias"}, {"category_id": 15, "poly": [296.0, 1600.0, 1404.0, 1600.0, 1404.0, 1632.0, 296.0, 1632.0], "score": 1.0, "text": "Wenhan Xiong, Jingyu Liu, Igor Molybog, Hejia Zhang, Prajwal Bhargava, Rui Hou, Louis Martin,"}, {"category_id": 15, "poly": [323.0, 1629.0, 1404.0, 1629.0, 1404.0, 1661.0, 323.0, 1661.0], "score": 1.0, "text": "Rashi Rungta, Karthik Abinav Sankararaman, Barlas Oguz, Madian Khabsa, Han Fang, Yashar"}, {"category_id": 15, "poly": [323.0, 1657.0, 1404.0, 1657.0, 1404.0, 1696.0, 323.0, 1696.0], "score": 0.99, "text": "Mehdad, Sharan Narang, Kshitiz Malik, Angela Fan, Shruti Bhosale, Sergey Edunov, Mike"}, {"category_id": 15, "poly": [319.0, 1684.0, 1407.0, 1687.0, 1407.0, 1726.0, 319.0, 1723.0], "score": 0.98, "text": " Lewis, Sinong Wang, and Hao Ma. Effective long-context scaling of foundation models. CoRR,"}, {"category_id": 15, "poly": [323.0, 1719.0, 580.0, 1719.0, 580.0, 1749.0, 323.0, 1749.0], "score": 1.0, "text": "abs/2309.16039,2023."}, {"category_id": 15, "poly": [298.0, 1771.0, 1402.0, 1771.0, 1402.0, 1804.0, 298.0, 1804.0], "score": 0.99, "text": "Yinfei Yang, Yuan Zhang, Chris Tar, and Jason Baldridge. PAWS-X: A cross-lingual adversarial"}, {"category_id": 15, "poly": [321.0, 1799.0, 1404.0, 1799.0, 1404.0, 1838.0, 321.0, 1838.0], "score": 0.99, "text": "dataset for paraphrase identification. In EMNLP/IJCNLP (1), pp. 3685-3690. Association for"}, {"category_id": 15, "poly": [326.0, 1833.0, 700.0, 1833.0, 700.0, 1865.0, 326.0, 1865.0], "score": 1.0, "text": "Computational Linguistics, 2019."}], "page_info": {"page_no": 23, "height": 2200, "width": 1700}}, {"layout_dets": [{"category_id": 1, "poly": [292.4490966796875, 223.0609130859375, 1411.40380859375, 223.0609130859375, 1411.40380859375, 1193.6619873046875, 292.4490966796875, 1193.6619873046875], "score": 0.9969119429588318}, {"category_id": 2, "poly": [835.7548217773438, 2088.005859375, 864.22802734375, 2088.005859375, 864.22802734375, 2112.45947265625, 835.7548217773438, 2112.45947265625], "score": 0.9916963577270508}, {"category_id": 15, "poly": [296.0, 234.0, 1402.0, 234.0, 1402.0, 266.0, 296.0, 266.0], "score": 0.99, "text": "Tao Yuan, Xuefei Ning, Dong Zhou, Zhijie Yang, Shiyao Li, Minghui Zhuang, Zheyue Tan, Zhuyu"}, {"category_id": 15, "poly": [321.0, 261.0, 1404.0, 261.0, 1404.0, 300.0, 321.0, 300.0], "score": 1.0, "text": "Yao, Dahua Lin, Boxun Li, Guohao Dai, Shengen Yan, and Yu Wang. LV-Eval: A balanced"}, {"category_id": 15, "poly": [326.0, 296.0, 1300.0, 296.0, 1300.0, 325.0, 326.0, 325.0], "score": 0.99, "text": "long-context benchmark with 5 length levels up to 256K. CoRR, abs/2402.05136, 2024."}, {"category_id": 15, "poly": [296.0, 348.0, 1402.0, 348.0, 1402.0, 380.0, 296.0, 380.0], "score": 0.99, "text": "Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Chuanqi Tan, and Chang Zhou. Scaling re-"}, {"category_id": 15, "poly": [321.0, 376.0, 1407.0, 376.0, 1407.0, 415.0, 321.0, 415.0], "score": 0.99, "text": "lationship on learning mathematical reasoning with large language models. CoRR, abs/2308.01825,"}, {"category_id": 15, "poly": [323.0, 406.0, 395.0, 406.0, 395.0, 438.0, 323.0, 438.0], "score": 1.0, "text": "2023."}, {"category_id": 15, "poly": [296.0, 461.0, 1402.0, 461.0, 1402.0, 493.0, 296.0, 493.0], "score": 0.99, "text": "Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. Hellaswag: Can a machine"}, {"category_id": 15, "poly": [323.0, 490.0, 1404.0, 490.0, 1404.0, 522.0, 323.0, 522.0], "score": 0.99, "text": "really finish your sentence? In ACL (1), pp. 4791-4800. Association for Computational Linguistics,"}, {"category_id": 15, "poly": [323.0, 520.0, 393.0, 520.0, 393.0, 552.0, 323.0, 552.0], "score": 1.0, "text": "2019."}, {"category_id": 15, "poly": [296.0, 571.0, 1402.0, 573.0, 1402.0, 605.0, 296.0, 603.0], "score": 1.0, "text": "Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanlin"}, {"category_id": 15, "poly": [321.0, 603.0, 1400.0, 603.0, 1400.0, 635.0, 321.0, 635.0], "score": 0.99, "text": " Zhao, Hanyu Lai, Hao Yu, Hongning Wang, Jiadai Sun, Jiajie Zhang, Jiale Cheng, Jiayi Gui, Jie"}, {"category_id": 15, "poly": [326.0, 635.0, 1404.0, 635.0, 1404.0, 667.0, 326.0, 667.0], "score": 0.99, "text": "Tang, Jing Zhang, Juanzi Li, Lei Zhao, Lindong Wu, Lucen Zhong, Mingdao Liu, Minlie Huang,"}, {"category_id": 15, "poly": [323.0, 662.0, 1404.0, 667.0, 1404.0, 699.0, 323.0, 694.0], "score": 0.99, "text": "Peng Zhang, Qinkai Zheng, Rui Lu, Shuaiqi Duan, Shudan Zhang, Shulin Cao, Shuxun Yang,"}, {"category_id": 15, "poly": [323.0, 692.0, 1404.0, 697.0, 1404.0, 729.0, 323.0, 724.0], "score": 0.99, "text": "Weng Lam Tam, Wenyi Zhao, Xiao Liu, Xiao Xia, Xiaohan Zhang, Xiaotao Gu, Xin Lv, Xinghan"}, {"category_id": 15, "poly": [326.0, 726.0, 1404.0, 726.0, 1404.0, 759.0, 326.0, 759.0], "score": 0.99, "text": "Liu, Xinyi Liu, Xinyue Yang, Xixuan Song, Xunkai Zhang, Yifan An, Yifan Xu, Yilin Niu, Yuantao"}, {"category_id": 15, "poly": [326.0, 756.0, 1402.0, 756.0, 1402.0, 788.0, 326.0, 788.0], "score": 0.99, "text": "Yang, Yueyan Li, Yushi Bai, Yuxiao Dong, Zehan Qi, Zhaoyu Wang, Zhen Yang, Zhengxiao Du,"}, {"category_id": 15, "poly": [321.0, 786.0, 1407.0, 786.0, 1407.0, 825.0, 321.0, 825.0], "score": 0.98, "text": " Zhenyu Hou, and Zihan Wang. ChatGLM: A family of large language models from GLM-130B to"}, {"category_id": 15, "poly": [326.0, 818.0, 857.0, 818.0, 857.0, 848.0, 326.0, 848.0], "score": 0.98, "text": "GLM-4 all t0ols. CoRR, abs/2406.12793, 2024."}, {"category_id": 15, "poly": [300.0, 871.0, 1402.0, 871.0, 1402.0, 903.0, 300.0, 903.0], "score": 0.98, "text": "Yingxiu Zhao, Bowen Yu, Binyuan Hui, Haiyang Yu, Minghao Li, Fei Huang, Nevin L. Zhang, and"}, {"category_id": 15, "poly": [321.0, 896.0, 1404.0, 901.0, 1404.0, 937.0, 321.0, 933.0], "score": 0.99, "text": " Yongbin Li. Tree-Instruct: A preliminary study of the intrinsic relationship between complexity"}, {"category_id": 15, "poly": [323.0, 930.0, 1196.0, 930.0, 1196.0, 962.0, 323.0, 962.0], "score": 0.99, "text": "and alignment. In LREC/COLING, pp. 16776-16789. ELRA and ICCL, 2024."}, {"category_id": 15, "poly": [296.0, 979.0, 1404.0, 981.0, 1404.0, 1020.0, 296.0, 1017.0], "score": 0.99, "text": "Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,"}, {"category_id": 15, "poly": [321.0, 1008.0, 1407.0, 1011.0, 1407.0, 1050.0, 321.0, 1047.0], "score": 0.99, "text": "Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica."}, {"category_id": 15, "poly": [326.0, 1045.0, 1222.0, 1045.0, 1222.0, 1077.0, 326.0, 1077.0], "score": 0.99, "text": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena. In NeurIPS, 2023."}, {"category_id": 15, "poly": [291.0, 1091.0, 1404.0, 1093.0, 1404.0, 1132.0, 291.0, 1130.0], "score": 0.99, "text": " Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi Luan, Denny Zhou,"}, {"category_id": 15, "poly": [326.0, 1128.0, 1404.0, 1128.0, 1404.0, 1160.0, 326.0, 1160.0], "score": 0.99, "text": "and Le Hou. Instruction-following evaluation for large language models. CoRR, abs/2311.07911,"}, {"category_id": 15, "poly": [326.0, 1160.0, 393.0, 1160.0, 393.0, 1185.0, 326.0, 1185.0], "score": 1.0, "text": "2023."}, {"category_id": 15, "poly": [832.0, 2083.0, 871.0, 2083.0, 871.0, 2131.0, 832.0, 2131.0], "score": 1.0, "text": "25"}], "page_info": {"page_no": 24, "height": 2200, "width": 1700}}]